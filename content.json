{"meta":{"title":"但行好事，莫问前程","subtitle":"CV工程师，了解面向Google编程的基本原理，有三年使用Google经验，在通往程序员的道路上艰难的爬行着。","description":"不想当架构师的程序员不是好厨师 ，不认为PHP是世界上最好的编程语言的Python开发者不是一个好的Javaer。","author":"fengbo","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"","slug":"一些知识点的链接","date":"3017-08-16T14:01:40.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"3017/08/16/一些知识点的链接/","link":"","permalink":"http://yoursite.com/3017/08/16/一些知识点的链接/","excerpt":"","text":"后端架构师技术图谱 | 正则表达式入门 | NIO教程大数据简介 | Spark中文文档 | Flink中文文档 | Spring MVC中文文档 | Vert.x中文文档Docker入门 | Docsify字符编码","categories":[],"tags":[]},{"title":"加密算法基础","slug":"基础之加密算法","date":"2020-11-14T11:38:05.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/11/14/基础之加密算法/","link":"","permalink":"http://yoursite.com/2020/11/14/基础之加密算法/","excerpt":"基础加密技术 对称密码(AES)：加密和解密使用同一把密匙的加密算法。 ECB模式：直接切割明文然后加密成密文，简单、快速、不安全。 CBC模式：TLS/SSL使用该模式，推荐使用。 CFB模式、OFB模式和CTR模式都是安全的模式，不太能分清优缺点。 公钥密码(RSA)：使用公匙加密，私匙解密的加密算法。","text":"基础加密技术 对称密码(AES)：加密和解密使用同一把密匙的加密算法。 ECB模式：直接切割明文然后加密成密文，简单、快速、不安全。 CBC模式：TLS/SSL使用该模式，推荐使用。 CFB模式、OFB模式和CTR模式都是安全的模式，不太能分清优缺点。 公钥密码(RSA)：使用公匙加密，私匙解密的加密算法。 认证 单向散列函数：通过计算数据的Hash值来保证文件或数据的完整性。具体算法包括MD5和SHA-3等。 消息认证码(HMAC)：一种与密匙相关联的单向散列函数。不仅可以保证数据的完整性，确认消息是否被篡改。而且可以确认消息是否来自所期待的对象。 消息认证码的输入包括任意长度的消息和一个发送者和接收者之间共享的密钥，输出为固定长度的数据，这个数据称为MAC值。 要计算MAC必须持有密钥，没有密钥就无法计算MAC，该特性保证了消息来自期待的对象。 数字签名：不但可以保证数据的完整性和确认消息是否来自期待的对象。而且可以保证消息的不可否认性。 消息认证码无法防止否认是因为消息的发送者和接收者共享同一个密钥。两者都可以用该密钥构建出MAC。 而数字签名是使用签名密钥来生成签名，使用验证密钥来验证签名是否期待的对象签发，验证密钥无法生成签名。和非对称加密类似。但是是使用私钥加密、公钥解密。 公钥证书：对公钥添加数字签名后就得到了公钥证书。 CA是证书的签发机构，是负责签发证书、认证证书、管理已颁发证书的机关。如果一个用户想鉴别另一个证书的真伪，可以用CA的公钥对那个证书上的签字进行验证，一旦验证通过，该证书就被认为是有效的。 数字签名实现 通常是先对数据进行一次Hash摘要(SHA1/SHA256/SHA512等)，然后再使用非对称加密算法(RSA/ECC等)对这个摘要进行加密，这样得到的结果就是原始数据的一个签名。 用户在验证数据时，只需要使用公钥解密出Hash摘要，然后自己再对数据进行一次同样的摘要，对比两个摘要是否相同即可。 SSH-RSA工作原理 生成一对密钥，一把专用密钥和一把公用密钥。公用密钥用于对消息进行加密，只有拥有专用密钥的人才能对该消息进行解密。 把公用密钥拷贝到远程服务器的文件(~/.ssh/authorized_keys)里。 本地输入ssh drobbins@remotebox登录到远程。 服务端的sshd会生成一个伪随机数，并用我们先前拷贝过去的公用密钥对这个随机数进行加密。然后，sshd把加密了的随机数发回给客户端的ssh。 客户端对这个随机数进行解密后，再把它发回给服务端。 服务端允许客户端登录。 OpenVPN消息发送流程 客户端将自己的公钥发送给服务端。 服务端通过CA证书验证公钥是自己签发的，并将密匙通过客户端公钥加密后发送给客户端。 客户端使用私钥解密获取对称加密的密钥。 客户端通过对称加密的密匙加密消息并发送给服务端，服务端通过该密钥解密。 服务端发送消息给客户端同理。 JWT实现方式 HS256(HMAC-SHA256)：使用同一个secret_key进行签名与验证(对称加密)。一旦secret_key泄漏，就毫无安全性可言了。因此HS256只适合集中式认证，签名和验证都必须由可信方进行。 RS256(RSA-SHA256)：使用RSA私钥进行签名，使用RSA公钥进行验证。公钥即使泄漏也毫无影响，只要确保私钥安全就行。RS256可以将公钥给第三方应用，让第三方应用也可以验证登录信息(微信登录原理)。 ES256(ECDSA-SHA256)： 和RS256一样，都使用私钥签名，公钥验证。算法速度上差距也不大，但是它的签名长度相对短很多(省流量)，并且算法强度和RS256差不多。 SSL/TLS协议运行机制的概述","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"Linux文件操作","slug":"基础之Linux文件操作","date":"2020-10-18T02:13:20.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/10/18/基础之Linux文件操作/","link":"","permalink":"http://yoursite.com/2020/10/18/基础之Linux文件操作/","excerpt":"通用I/O基础的系统调用 open()和close(): 打开和关闭文件。 write()和read(): 读写打开的文件。 lseek(): 设置打开的文件的偏移量。 ioctl(): 对IO设备的非通用属性进行操作。 fcntl(): 获取和设置打开文件的熟悉，O_NONBLOCK等。 dup()和dup2(): 复制文件描述符，2&gt;&amp;1==dup2(1, 2)。 pwrite()和pread(): 在给定的偏移量上进行读写操作。 truncate()和ftruncate(): 将文件设置未指定的大小。如果文件大于指定的size，大于的部分丢失。小于则形成文件空洞。","text":"通用I/O基础的系统调用 open()和close(): 打开和关闭文件。 write()和read(): 读写打开的文件。 lseek(): 设置打开的文件的偏移量。 ioctl(): 对IO设备的非通用属性进行操作。 fcntl(): 获取和设置打开文件的熟悉，O_NONBLOCK等。 dup()和dup2(): 复制文件描述符，2&gt;&amp;1==dup2(1, 2)。 pwrite()和pread(): 在给定的偏移量上进行读写操作。 truncate()和ftruncate(): 将文件设置未指定的大小。如果文件大于指定的size，大于的部分丢失。小于则形成文件空洞。 数据同步的系统调用 fsync()和fdatasync(): 强制刷新缓存数据到文件中。fdatasync只会刷新对read()有影响的元数据，如文件大小；fsync()会刷新所有的元数据，即使对数据读取没有影响，如文件的修改时间。 sync(void): 强制内核缓冲区中包含的所有更新过的文件信息都刷新到磁盘中。一个永久的内核线程会每隔30秒刷新一次缓存到磁盘。 打开文件时添加O_SYNC标记: 让写操作自动的刷新文件数据和元数据(fsync)到磁盘中。O_DSYNC标记则类比(fdatasync)。IO数据同步","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"Python基础","slug":"Python基础","date":"2020-08-13T14:24:35.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2020/08/13/Python基础/","link":"","permalink":"http://yoursite.com/2020/08/13/Python基础/","excerpt":"Python数据模型 Python的特殊方法，如len等。Python类实现这些方法，那么在调用len等函数的时候，Python解释器会自动调用这些方法。 collections.namedtuple用来构建一个带字段名的元组和一个有名字的类，即构建只有少数属性但是没有方法的对象，比如数据库条目。","text":"Python数据模型 Python的特殊方法，如len等。Python类实现这些方法，那么在调用len等函数的时候，Python解释器会自动调用这些方法。 collections.namedtuple用来构建一个带字段名的元组和一个有名字的类，即构建只有少数属性但是没有方法的对象，比如数据库条目。 数据结构列表推导和生成器：1234567symbols = \"abcdef\"codes = [ord(symbol) for symbol in symbols]# == list(filter(lambda c: c &gt; 127, map(ord, symbols)))beyand = [ord(symbol) for symbol in symbols if ord(symbol) &gt; 100]colors = ['black', 'white']sizes = ['S', 'M', 'L']tshirts = [(color, size) for size in sizes for color in colors]","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Docker基础","slug":"其它之Docker基础","date":"2020-07-11T07:33:52.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2020/07/11/其它之Docker基础/","link":"","permalink":"http://yoursite.com/2020/07/11/其它之Docker基础/","excerpt":"基本命令 docker info: 查看Docker服务是否正常。 docker images: 查看所有镜像。 docker ps -a: 查看当前系统中存在的容器。-a表示无论是否在运行中，都会被查找到。 docker start/stop name: 启动或停止容器。 docker rm name: 删除容器。运行中的容器是无法直接删除的，需要先停止容器运行后才能将其删除。 docker rmi name: 删除Image。 docker logs -f -t name: 查看容器日志。-f表示用于监控容器的日志，功能类似于tail -f。-t用来添加时间戳。 docker exec -it name /bin/bash: 在容器内运行进程。 docker build -t weather:v1.0 ./: 构建一个镜像。 docker run -d -p 80:8080 –name weather weather:v1.0: 运行镜像。 docker tag weather:v1.0 fengbo4213/test:v1.0: 给镜像打标签。 docker push fengbo4213/test:v1.0: 推送到DockerHub。 docker cp weather:/app ./: 将未启动容器中的内容拷贝出来，方便查看。 docker inspect name: 查看容器详细信息。","text":"基本命令 docker info: 查看Docker服务是否正常。 docker images: 查看所有镜像。 docker ps -a: 查看当前系统中存在的容器。-a表示无论是否在运行中，都会被查找到。 docker start/stop name: 启动或停止容器。 docker rm name: 删除容器。运行中的容器是无法直接删除的，需要先停止容器运行后才能将其删除。 docker rmi name: 删除Image。 docker logs -f -t name: 查看容器日志。-f表示用于监控容器的日志，功能类似于tail -f。-t用来添加时间戳。 docker exec -it name /bin/bash: 在容器内运行进程。 docker build -t weather:v1.0 ./: 构建一个镜像。 docker run -d -p 80:8080 –name weather weather:v1.0: 运行镜像。 docker tag weather:v1.0 fengbo4213/test:v1.0: 给镜像打标签。 docker push fengbo4213/test:v1.0: 推送到DockerHub。 docker cp weather:/app ./: 将未启动容器中的内容拷贝出来，方便查看。 docker inspect name: 查看容器详细信息。 Docker安装phpmyadmin 下载phpmyadmin镜像: docker pull phpmyadmin/phpmyadmin 使用该镜像启动容器: docker run -d –name myadmin -e PMA_HOST=192.168.206.132 -e PMA_PORT=3307 -p 8283:80 phpmyadmin/phpmyadmin Docker安装Jupyter-Lab docker pull jupyter/all-spark-notebook docker run -p 8888:8888 -p 4040:4040 –name jupyter -e JUPYTER_ENABLE_LAB=yes -v /usr/local/jupyter:/home/jovyan/work/ jupyter/all-spark-notebook","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"HG255D刷OpenWRT","slug":"路由器之HG255D刷OpenWRT","date":"2020-06-21T10:16:28.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/06/21/路由器之HG255D刷OpenWRT/","link":"","permalink":"http://yoursite.com/2020/06/21/路由器之HG255D刷OpenWRT/","excerpt":"路由器就是开发板 | HG255D电信原版刷机实战整理 | Ubuntu使用USB转TTL","text":"路由器就是开发板 | HG255D电信原版刷机实战整理 | Ubuntu使用USB转TTL 接TTL线如下图接线： Ubuntu安装配置minicom 安装：sudo apt-get install minicom 查看USB转串口接入状态： lsmod | grep usbserial dmesg | grep ttyUSB0 配置minicom 输入命令：sudo minicom -s 选择“Serial port setup”，出现串口配置菜单 输入A，修改serial device，由/dev/tty0修改为/dev/ttyUSB0，波特率改为57600 选择 Save setup as dfl，接着选择Exit退出。","categories":[],"tags":[{"name":"硬件","slug":"硬件","permalink":"http://yoursite.com/tags/硬件/"}]},{"title":"分布式原理","slug":"分布式之分布式原理","date":"2020-03-13T12:59:16.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/03/13/分布式之分布式原理/","link":"","permalink":"http://yoursite.com/2020/03/13/分布式之分布式原理/","excerpt":"单机存储引擎存储系统的基本功能包括:增、删、读、改,其中,读取操作又分为随机读取和顺序扫描。 哈希存储引擎是哈希表的持久化实现,支持增、删、改,以及随机读取操作,但不支持顺序扫描,对应的存储系统为键值(Key-Value)存储系统。 B树(B-Tree)存储引擎是B树的持久化实现,不仅支持单条记录的增、删、读、改操作,还支持顺序扫描,对应的存储系统是关系数据库。 LSM树存储引擎通过将数据的修改增量保存在内存中，读取时需要合并磁盘中的历史数据和内存中的操作记录。支持增、删、改、随机读取以及顺序扫描。","text":"单机存储引擎存储系统的基本功能包括:增、删、读、改,其中,读取操作又分为随机读取和顺序扫描。 哈希存储引擎是哈希表的持久化实现,支持增、删、改,以及随机读取操作,但不支持顺序扫描,对应的存储系统为键值(Key-Value)存储系统。 B树(B-Tree)存储引擎是B树的持久化实现,不仅支持单条记录的增、删、读、改操作,还支持顺序扫描,对应的存储系统是关系数据库。 LSM树存储引擎通过将数据的修改增量保存在内存中，读取时需要合并磁盘中的历史数据和内存中的操作记录。支持增、删、改、随机读取以及顺序扫描。 分布式系统数据复制客户端将数据写入主副本，主副本将操作日志同步到备副本，备副本回放操作日志，完成后通知主副本。 分布式协议基础 CAP理论：一个分布式系统不可能同时满足一致性(C:Consistency)、可用性(A:Availability)和分区容错性(P:Partition tolerance)这三个基本要求,最多只能同时满足其中的两项。 一致性 (Consistency)：一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据。所有节点访问同一份最新的数据。 可用性 (Availability)：对数据更新具备高可用性，请求能够及时处理，不会一直等待，即使出现节点失效。 分区容错性 (Partition tolerance)：能容忍网络分区，在网络断开的情况下，被分隔的节点仍能正常对外提供服务。 BASE理论：对CAP中一致性和可用性权衡的结果，其核心思想是即使无法做到强一致性(Strongconsistency),但每个应用都可以根据自身的业务特点,采用适当的方式来使系统达到最终一致性(Eventualconsistency)。 基本可用：基本可用是指分布式系统在出现不可预知故障的时候,允许损失部分可用性。响应时间上的损失:正常情况下,一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果,但由于出现故障(比如系统部分机房发生断电或断网故障),查询结果的响应时间增加到了1~2秒；功能上的损失:正常情况下,在一个电子商务网站上进行购物,消费者儿乎能够顺利地完成每一笔订单,但是在一些节日大促购物高峰的时候,由于消费者的购物行为激增,为了保护购物系统的稳定性,部分消费者可能会被引导到一个降级页面。 弱状态也称为软状态,和硬状态相对,是指允许系统中的数据存在中间状态,并认为该中间状态的存在不会影响系统的整体可用性,即允许系统在不同节点的数据副本之间进行数据吟步的过程存在延时。 最终一致性强调的是系统中所有的数据副本,在经过一段时间的同步后,最终能够达到一个一致的状态。因此,最终一致性的本质是需要系统保证最终数据能够达到一致,而不需要实时保证系统数据的强一致性。 两阶段提交大部分的关系型数据库都是采用二阶段提交协议来完成分布式事务处理的,利用该协议能够非常方便地完成所有分布式事务参与者的协调,统一决定事务的提交或回漫,从而能够有效地保证分布式数据一致性。阶段一:提交事务请求 事务询问。协调者向所有的参与者发送事务内容,询问是否可以执行事务提交操作,并开始等待各参与者的响应。 执行事务。各参与者节点执行事务操作,并将Undo和Redo信息记人事务日志中。 各参与者向协调者反馈事务询问的响应。如果参与者成务执行了事务操作,那么就反馈给协调者Yes响应,表示事务可以执行;如果参与者没有成功执行事务,那么就反馈给协调者No响应,表示事务不可以执行。 阶段二:假如协调者从所有的参与者获得的反馈都是Yes响应,那么就会执行事务提交。 发送提交请求。协调者向所有参与者节点发出Commit请求。 事务提交。参与者接收到Commit请求后,会正式执行事务提交操作,并在完成提交之后释放在整个事务执行期间占用的事务资源。 反馈事务提交结果。参与者在完成事务提交之后,向协调者发送Ack消息。 阶段二:假如任何一个参与者向协调者反馈了No响应,或者在等待超时之后,协调者尚无法接收到所有参与者的反馈响应,那么就会中断事务。 发送回滚请求。协调者向所有参与者节点发出Rollback请求。 事务回滚。参与者接收到Rollback请求后,会利用其在阶段一中记录的Undo信息来执行事务回滚操作,并在完成回滚之后释放在整个事务执行期间占用的资源。 反馈事务回滚结果。参与者在完成事务回滚之后,向协调者发送Ack消息。 中断事务。协调者接收到所有参与者反馈的Ack消息后,完成事务中断。 两阶段提交的问题 同步阻塞:二阶段提交协议存在的最朋显也是最大的一分布式系统的性能。在二阶段提交的执行过于阻塞状态,也就是说,各个参与者在等待具他任何操作。个问题就是同步阻塞,这会极大地限制程中,所有参与该事务操作的逻辑都处其他参与者响应的过程中,将无法进行其他任何操作。 单点问题:协调者的角色在整个二阶段提交协议中起到了非常重要的作用。一旦协调者出现问题,那么整个二阶段提交流程将无法运转,更为严重的是,如果协调者是在阶段二中出现问题的话,那么其它参与者将会一直处于锁定事务资源的状态中,而无法继续完成事务操作。 数据不一致:在二阶段提交协议的阶段二,即执行事务提交的时候,当协调者向所有的参与者发送Commit请求之后,发生了局部网络异常或者是协调者在尚未发送完Commit请求之前自身发生了崩澎,导致最终只有部分参与者收到了Commit请求。于是,这部分收到了Commit请求的参与者就会进行事务的提交,而其他没有收到Commit请求的参与者则无法进行事务提交,于是整个分布式系统便出现了数据不一致性现象。 太过保守:如果在协调者指示参与者进行事务提交询问的过程中,参与者出现故障而导致协调者始终无法获取到所有参与者的响应信息的话,这时协调者只能依靠其自身的超时机制来判断是否需要中断事务,这样的策略显得比较保守。换句话说,二阶段提交协议没有设计较为完善的容错机制,任意一个节点的失败都会导致整个事务的失败。 Paxos协议Raft协议基本概念 主从备份主要有两种方法： 状态转移(State Transfer)：主服务器将完整的状态内容都传输给备份服务器。即将主节点的当前所有数据进行镜像备份，适合冷备份。 备份状态机(Replicated State Machine)：将需要备份的服务器视为一个确定性状态机——主备以相同的状态启动，以相同顺序导入相同的输入，最后它们就会进入相同的状态、给出相同的输出。 Write-Ahead Logging：对数据文件的修改必须发生在这些修改已经记录到日志之后，也就是先写日志落盘然后写数据。这样就不需要每次提交事务的时候把数据块刷回磁盘，因为出现奔溃的情况下可以用日志来恢复数据。 Redis实现分布式锁ZooKeeper的典型应用场景ZooKeeper简介ZooKeeper是一个高可用的分布式数据管理与协调框架。基于对ZAB算法的实现,该框架能够很好地保证分布式环境中数据的一致性。也正是基于这样的特性，使得ZooKeeper成为了解决分布式一致性问题的利器。 数据的发布/订阅 即所谓的配置中心,顾名思义就是发布者将数据发布到ZooKeeper的一个或一系列节点上,供订阅者进行数据订阅,进而达到动态获取数据的目的,实现配置信息的集中式管理和数据的动态更新。 客户端向服务端注册自己需要关注的节点,一旦该节点的数据发生变更,那么服务端就会向相应的客户端发送Wateher事件通知,客户端接收到这个消息通知之后,需要主动到服务端获取最新的数据。 命名服务(Name Service)在分布式系统中，被命名的实体通常可以是集群中的机器、提供的服务地址或远程对象等一一这些我们都可以统称它们为名字(Name),其中较为常见的就是一些分布式服务框架(如RPC、RMI)中的服务地址列表,通过使用命名服务,客户端应用能够根据指定名字来获取资源的实体、服务地址和提供者的信息等。命名服务器的作用主要有两个，一个是收集提供请求处理的服务器的地址信息;另外一个是提供这些地址信息给请求发起方。当然,名称服务只是起到了一个地址交换的作用,在发起请求的机器上,需要根据从名称服务得到的地址迹行负载均衡的工作。 集群管理与负载均衡ZooKeeper具有以下两大特性。 客户端如果对ZooKeeper的一个数据节点注册Wateher监听,那么当该数据节点的内容或是其子节点列表发生变更时,ZooKeeper服务器就会向订阅的客户端发送变更通知。 对在ZooKeeper上创建的临时节点,一旦客户端与服务器之间的会话失效,那么该临时节点也就被自动清除。利用ZooKeeper的这两大特性,就可以实现集群机器存活性监控系统。监控系统在/cuserServers节点上注册一个Watcher监听,那么但凡进行动态添加机器的操作,就会在/clusterServers节点下创建一个临时节点:/cliisterServers/[HostName]。这样一来,监控系统就能够实时检测到机器的变动情况。同时集群上的服务器可以在监听到Watcher事件时，去ZooKeeper拉取集群上所有服务器的基础信息，然后以这些信息为基础进行软负载均衡。 Master选举 在分布式系统中,Master往往用来协调集群中其他系统单元,具有对分布式系统状态变更的决定权。例如,在一些读写分离的应用场景中,客户端的写请求往往是由Master来处理的;而在另一些场景中,Master则常常负责处理一些复杂的逻辑,些将处理结果同步给集群中其他系统单元。 ZooKeeper能够很好地保证在分布式高并发情况下节点的创建一定能够保证全局唯一性,即ZooKeeper将会保证客户端无法重复创建一个已经存在的数据节点。也就是说,如果同时有多个客户端请求创建同一个节点,那么最终一定只有一个客户端请求能够创建成功。利用这个特性,就能很容易地在分布式环境中进行Master选举了。 即所有客户端都去向ZooKeeper请求创建一个临时节点,例如/maser_efecrion/2013-09-20/binding。在这个过程中,只有一个客户端能够成功创建这个节点,那么这个客户端所在的机器就成为了Master。同时,其他没有在ZooKeeper上成功创建节点的客户端,都会在节点/maser_elecrion/2013-09-20上注册一个子节点变更的Watcher,用于监控当前的Master机器是否存活,一旦发现当前的Master挂了,那么其余的客户端将会重新进行Master选举。 分布式锁 获取锁：在需要获取排他锁时,所有的客户端都会试图通过调用create()接口,在/exclusive_lock节点下创建临时子节点/exclusive_lock/lock。ZooKeeper会保证在所有的客户端中,最终只有一个客户端能够创建成功,那么就可以认为该客户端获取了锁。同时,所有没有获取到锁的客户端谐需要到/excliusive_lock节点上注册一个子节点变更的Watcher监听,以便实时监听到lock节点的变更情况。 释放锁：/exelsive_lock/lock是一个临时节点,因此在以下两种情况下,都有可能释放锁。 当前获取锁的客户端机器发生宕机,那么ZooKeeper上的这个临时节点就会被移除。 正常执行完业务逻辑后,客户端就会主动将自已创建的临时节点删除。无论在什么情况下移除了lock节点,ZooKeeper都会通知所有在/exclusive_lock节点上注册了子节点变更Wateher监听的客户端。这些客户端在接收到通知后,再次重新发起分布式锁获取,即重复获取锁过程。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"}]},{"title":"网络管理和优化","slug":"树莓派之网络管理和优化","date":"2020-02-08T03:59:16.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/02/08/树莓派之网络管理和优化/","link":"","permalink":"http://yoursite.com/2020/02/08/树莓派之网络管理和优化/","excerpt":"","text":"网络管理 使用nmap进行网络扫描 1sudo nmap -sP 192.168.0.* 查看流量是从哪些端口发送出去的 1iftop -P TX：发送流量RX：接收流量TOTAL：总流量Cumm：运行iftop到目前时间的总流量peak：流量峰值rates：分别表示过去 2s 10s 40s 的平均流量","categories":[],"tags":[{"name":"硬件","slug":"硬件","permalink":"http://yoursite.com/tags/硬件/"}]},{"title":"利用VNC远程控制树莓派","slug":"树莓派之利用VNC远程控制树莓派","date":"2020-01-29T10:44:51.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/01/29/树莓派之利用VNC远程控制树莓派/","link":"","permalink":"http://yoursite.com/2020/01/29/树莓派之利用VNC远程控制树莓派/","excerpt":"设置树莓派启动方式1sudo raspi-config","text":"设置树莓派启动方式1sudo raspi-config OpenVPNOpenVPN客户端和服务器端安装 | OpenVPN配置详解VPC软件服务端 服务端安装并运行VNC12sudo apt install tightvncservertightvncserver 然后设置密码，输入控制密码，选择性输入查看密码，查看密码只能用来查看桌面，而控制密码才能对桌面进行操作。每个用户可以启动多个VNCSERVER远程桌面，它们用ip加端口号：ip:1、ip:2、ip:3 来标识、区分，使用同一端口会使另外登录的用户自动退出。 停止VNC窗口12345vncserver -kill:1# 修改密码vncpasswd# 重启服务service vncserver restart 客户端 Windows10可以直接安装TightVNC Viewer。 安卓手机可以安装RealVNC Viewer。","categories":[],"tags":[{"name":"硬件","slug":"硬件","permalink":"http://yoursite.com/tags/硬件/"}]},{"title":"树莓派实现NAS家庭服务器","slug":"树莓派之实现NAS家庭服务器","date":"2020-01-28T07:25:35.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/01/28/树莓派之实现NAS家庭服务器/","link":"","permalink":"http://yoursite.com/2020/01/28/树莓派之实现NAS家庭服务器/","excerpt":"挂载移动硬盘 插上硬盘，查看状态 1sudo fdisk -l 挂载 1sudo mount /dev/sda5 /home/pi/samba","text":"挂载移动硬盘 插上硬盘，查看状态 1sudo fdisk -l 挂载 1sudo mount /dev/sda5 /home/pi/samba 安装DLNA实现流媒体服务器 安装minidlna。 12sudo apt-get updatesudo apt-get install minidlna 设置/etc/minidlna.conf文件，在文件尾部添加如下内容： 12345678# A表示这个目录是存放音乐的，当minidlna读到配置文件时，它会自动加载这个目录下的音乐文件media_dir=A,/home/pi/samba/DLNA/Musicmedia_dir=P,/home/pi/samba/DLNA/Picturemedia_dir=V,/home/pi/samba/DLNA/Video# 配置minidlna的数库数据的存放目录db_dir=/home/pi/samba/DLNA/db# 配置日志目录log_dir=/home/pi/samba/DLNA/log 在相应位置建立以上文件夹，并设置好权限为。 重启minidlna。 1sudo service minidlna restart 电脑上可以使用VLC播放器，View &gt; Playlist[CTRL + L] &gt; Local Network。 手机可以使用MoliPlayer或者VLC。 安装aria2实现下载机功能 安装 1234567sudo apt-get install aria2sudo mkdir /etc/aria2 sudo touch /etc/aria2/aria2.session sudo chmod 777 /etc/aria2/aria2.session sudo chgrp -R pi /home/pi/samba/DLNA/Videosudo chown -R pi /home/pi/samba/DLNA/Videosudo vi /etc/aria2/aria2.conf aria2.conf文件配置 123456789101112131415161718192021222324252627282930dir=/home/pi/samba/DLNA/Videodisable-ipv6=true#打开rpc的目的是为了给web管理端用enable-rpc=truerpc-allow-origin-all=truerpc-listen-all=true#rpc-listen-port=6800#断点续传continue=trueinput-file=/etc/aria2/aria2.sessionsave-session=/etc/aria2/aria2.session#最大同时下载任务数max-concurrent-downloads=20save-session-interval=120# Http/FTP 相关connect-timeout=120#lowest-speed-limit=10K#同服务器连接数max-connection-per-server=10#max-file-not-found=2#最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要min-split-size=10M#单文件最大线程数, 路由建议值: 5split=10check-certificate=false#http-no-cache=true 启动 1sudo aria2c --conf-path=/etc/aria2/aria2.conf 如果没有提示错误，按ctrl+c停止运行命令，转为后台运行：1sudo aria2c --conf-path=/etc/aria2/aria2.conf -D 参数使用使用 aria2 下载文件，只需在命令后附加地址即可。注意：命令是aria2c。比如我们下载ubuntu如：1aria2c http://www.mirror.tw/pub/ubuntu/releases/jaunty/ubuntu-9.04-desktop-i386.iso 分段下载利用aria2的分段下载功能可以加快文件的下载速度，对于下载大文件时特别有用，为了使用aria2的分段下载功能，你需要在命令中指定s选项，使用c选项可以断点续传文件。如：1aria2c -c -s10 -x10 http://www.mirror.tw/pub/ubuntu/releases/jaunty/ubuntu-9.04-desktop-i386.iso 下载torrent文件你也可以使用aria2下载BitTorrent文件。如：1aria2c -o gutsy.torrent http://cdimage.ubuntu.com/daily-live/current/gutsy-desktop-i386.iso.torrent aria2安装Web界面 下载yaaw 将下载下来的静态文件放到HTTP服务器的工作目录中。 使用浏览器访问该服务器并点击右上角的扳手按钮配置aria2。","categories":[],"tags":[{"name":"硬件","slug":"硬件","permalink":"http://yoursite.com/tags/硬件/"}]},{"title":"树莓派系统和相关软件安装","slug":"树莓派之系统安装","date":"2020-01-27T13:05:51.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2020/01/27/树莓派之系统安装/","link":"","permalink":"http://yoursite.com/2020/01/27/树莓派之系统安装/","excerpt":"官方系统安装 安装SDFormatter4，选好要用的TF卡盘符，然后点击格式化。 安装Win32DiskImager，点击文件夹图标，选择准备好的img文件，然后点击Write按钮。 进度条走完之后会弹出两个框，一个是询问是否格式化磁盘，选取消。","text":"官方系统安装 安装SDFormatter4，选好要用的TF卡盘符，然后点击格式化。 安装Win32DiskImager，点击文件夹图标，选择准备好的img文件，然后点击Write按钮。 进度条走完之后会弹出两个框，一个是询问是否格式化磁盘，选取消。 将树莓派用做无线路由器 安装hostapd。并修改/etc/default/hostapd和/etc/hostapd/hostapd.conf。 1234567891011121314151617181920212223242526272829303132333435# 使用如下命令sudo apt remove --purge hostapd sudo apt update sudo apt upgradesudo apt install hostapd# 在/etc/default/hostapd中添加DAEMON_CONF=&quot;/etc/hostapd/hostapd.conf&quot;# 在hostapd.conf中添加# 把无线网卡wlan0作为接入点interface=wlan0# 使用nl80211驱动#driver=nl80211# a 5G g 2.4Ghw_mode=g# 无线网卡选用11信道，如果hw_mode为a可以选择165channel=11ieee80211n=1ieee80211ac=1wmm_enabled=1# WPA2 onlywpa=2# 1=wpa 2=wep 3=bothauth_algs=3# 认证方式为WPA-PSK加密方式为CCMPwpa_key_mgmt=WPA-PSKwpa_pairwise=CCMPrsn_pairwise=CCMP# Wifi名称ssid=wifi123# Wifi密码wpa_passphrase=feng4213 安装dnsmasq。并修改/etc/dnsmasq.conf。 123# 在dnsmasq.conf中添加interface=wlan0dhcp-range=192.168.202.10,192.168.202.150,255.255.255.0,24h 修改/etc/rc.local文件。 12345678910# 在exit 0之前添加sudo ifconfig wlan0 downsudo ifconfig wlan0 192.168.202.1 netmask 255.255.255.0 up# 关闭无线网络的电源管理sudo iw dev wlan0 set power_save offsudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADEsudo iptables -A FORWARD -i eth0 -o wlan0 -m state --state RELATED,ESTABLISHED -j ACCEPTsudo iptables -A FORWARD -i wlan0 -o eth0 -j ACCEPTsudo service hostapd restartsudo service dnsmasq restart 利用ssh反向代理及autossh实现内网穿透 内网和外网机器安装autossh。 内网机器配置免密登录。 12ssh-keygenssh-copy-id -i .ssh/id_rsa.pub root@外网地址 在内网机器上启动autossh。 1234567# -f：是指autossh后台运行，不会阻塞shell继续向下执行；# -N：是指建立的ssh连接只用于转发数据，不解析命令； # -R：是指建立反向隧道，一般我们ssh某个服务器是正向隧道； # 8888：是公网服务器上的代理端口；# localhost:22：是指代理到本机时需要访问的ip和端口，即内网机器A的ip地址+端口；# -p 40022：是外网机器B的ssh端口；autossh -fNR 8888:localhost:22 -p 22 root@外网地址 在外网上查看8888端口是否打开。 在外网主机上连接内网主机。1ssh -p 8888 localhost -l pi 设置autossh自动启动 新建/etc/systemd/system/remote-autossh.service文件。并添加如下内容： 1234567891011121314[Unit]Description=AutoSSHAfter=network-online.target[Service]User=piExecStart=/usr/bin/autossh -fNR 8888:localhost:22 -p 22 root@118.31.167.239ExecReload=/bin/kill -HUP $MAINPIDExecStop=/bin/kill -TERM $MAINPIDKillMode=processRestart=no[Install]WantedBy=multi-user.target 使用systemctl daemon-reload命令刷新systemctl服务。 使用systemctl start remote-autossh立即启动服务，或者systemctl enable remote-autossh启动服务并设置为开机启动。","categories":[],"tags":[{"name":"硬件","slug":"硬件","permalink":"http://yoursite.com/tags/硬件/"}]},{"title":"RocketMQ基础","slug":"其它之RocketMQ基础","date":"2019-11-13T04:29:51.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/11/13/其它之RocketMQ基础/","link":"","permalink":"http://yoursite.com/2019/11/13/其它之RocketMQ基础/","excerpt":"MQ作用在一个企业级的架构应用中，MQ的主要作用为业务解耦、事件消息广播、消息流控处理。其中，对于业务解耦是作为消息队列，要解决的一个首要问题。所谓业务解耦，就是说在一个业务流程处理上，只关注具体的流程，尽到通知的责任即可，不必等待消息处理的结果。总得来看，企业级系统模块通信的方式通常情况下，无非两种。同步方式：REST、RPC方式实现；异步方式：消息中间件（消息队列）方式实现。","text":"MQ作用在一个企业级的架构应用中，MQ的主要作用为业务解耦、事件消息广播、消息流控处理。其中，对于业务解耦是作为消息队列，要解决的一个首要问题。所谓业务解耦，就是说在一个业务流程处理上，只关注具体的流程，尽到通知的责任即可，不必等待消息处理的结果。总得来看，企业级系统模块通信的方式通常情况下，无非两种。同步方式：REST、RPC方式实现；异步方式：消息中间件（消息队列）方式实现。 RocketMQ基础组件 NameServer：相当于注册中心。是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 维护了一份Broker的地址列表。Broker在启动的时候会去NameServer进行注册，并发送心跳来维护Broker的存活状态。 维护了一份Topic和Topic对应队列的地址列表，Broker每次发送心跳过来的时候都会把Topic信息带上。 接收客户端（Producer和Consumer）的请求根据某个Topic获取所有到Broker的路由信息。 Broker：负责存储和分发消息。 Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。 每隔30秒（此时间无法更改）向所有NameServer发送心跳，心跳包含了自身的Topic配置信息。 NameServer每隔10秒钟（此时间无法更改），扫描所有还存活的Broker连接，若某个连接2分钟内（当前时间与最后更新时间差值超过2分钟，此时间无法更改）没有发送心跳数据，则断开连接。 Producer：消息生产者。与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的所有Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer：消息消费者。与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的所有Master和Slave建立长连接，且定时向Master和Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。 RocketMQ部署方式 单个Master：只适合测试环境。 多Master模式 优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢失（异步刷盘丢失少量消息，同步刷盘一条不丢）。性能最高。 缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 多Master多Slave模式，异步复制 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为Master 宕机后，消费者仍然可以从Slave消费，此过程对应用透明。不需要人工干预。性能同多Master模式几乎一样。 缺点：Master宕机，磁盘损坏情况，会丢失少量消息。 多Master多Slave模式，同步双写 优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高。 缺点：性能比异步复制模式略低，大约低10%左右，发送单个消息的RT会略高。目前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能。 RocketMQ实现功能 消息存储：消息中间件的一个核心实现是消息的存储对消息存储一般有如下两个维度的考量: 消息堆积能力和消息存储性能。RocketMQ追求消息存储的高性能，引人内存映射机制，所有主题的消息顺序存储在同一个文件中。同时为了避免消息无限在消息存储服务器中累积，引入了消息文件过期机制与文件存储空间报警机制。 消息高可用性：通常影响消息可靠性的有以下几种情况。1.Broker正常关机。2.Broker异常Crash。3.OS Crash。4.机器断电，但是能立即恢复供电情况。5.机器无法开机(可能是CPU、主板、内存等关键设备损坏)。6.磁盘设备损坏。针对上述情况，情况1~4的RocketMQ在同步刷盘机制下可以确保不丢失消息，在异步刷盘模式下，会丢失少量消息。情况5-6属于单点故障，一旦发生，该节点上的消息全部丢失，如果开启了异步复制机制，RoketMQ能保证只丢失少量消息，如果使用Master Slave双写机制，可以保证不丢失消息，从而满足消息可靠性要求极高的场合。 消费低延迟：RocketMQ在消息不发生消息堆积时，以长轮询模式实现准实时的消息推送模式。 确保消息必须被消费一次：RocketMQ通过消息消费确认机制(ACK)来确保消息至少被消费一次，但由于ACK消息有可能丢失等其他原因，RocketMQ无法做到消息只被消费一次，有重复消费的可能。 回溯消息：回溯消息是指消息消费端已经消费成功的消息，由于业务要求需要重新消费消息。RocketMQ支持按时间回溯消息，时间维度可精确到毫秒，可以向前或向后回溯。 消息堆积：消息中间件的主要功能是异步解耦，必须具备应对前端的数据洪峰，提高后端系统的可用性，必然要求消息中间件具备一定的消息堆积能力。RocketMQ消息存储使用磁盘文件(内存映射机制)，并且在物理布局上为多个大小相等的文件组成逻辑文件组，可以无限循环使用。RocketMQ消息存储文件并不是永久存储在消息服务器端，而是提供了过期机制，默认保留3天。 定时消息：定时消息是指消息发送到Broker后，不能被消息消费端立即消费，要到特定的时间点或者等待特定的时间后才能被消费。如果要支持任意精度的定时消息消费，必须在消息服务端对消息进行排序，势必带来很大的性能损耗，故RocketMQ不支持任意进度的定时消息，而只支持特定延迟级别。 消息重试机制：消息重试是指消息在消费时，如果发送异常，消息中间件需要支持消息重新投递，RocketMQ支持消息重试机制。 RocketMQ路由查找 Topic路由信息创建 手动创建Topic路由信息：可以根据该Topic消息的实际需求，分配合适的Broker数量和消息队列数量。一般来说，生产环境的服务都推荐以这种方式进行。 打开自动创建Topic功能：配置BrokerConfig#autoCreateTopicEnable，这样就会在发送第一个消息时，动态的创建该topic的路由信息。 路由选择 轮训所有队列，通过LatencyFaultTolerance找到可用队列。 如果未找到任何可用队列，通过LatencyFaultTolerance存储的信息，按照三个纬度的可用性排序（当前可用与否&gt;上次使用该节点时的调用耗时&gt;预估的下次可使用时间），选出最可能可用的队列。 如果上述两个步骤都没有选出队列，则按照最简单的轮训找到下一个队列。 RocketMQ消息存储RocketMQ主要存储的文件包括CommitLog文件、ConsumeQueue文件、IndexFile文件。 CommitLog：消息存放的物理文件。CommitLog的消息存储单元长度不固定，文件顺序写，随机读。 ConsumeQueue：是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。 IndexFile：索引文件，引入了Hash索引机制为消息建立索引，对CommitLog进行数据索引。 RocketMQ应用系统I/O和虚拟内存设置12345678910111213141516171819202122232425262728# 内存分配策略# 可选值：0、1、2# 0：表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。即内核计算NR_FILE_PAGES总量+SWAP总量+slab中可以释放的内存总量，如果申请空间超过此数值，则将此数值与空闲内存总量减掉totalreserve_pages的总量相加。如果申请空间依然超过此数值，则分配失败。# 1：表示内核允许分配所有的物理内存，而不管当前的内存状态如何。# 2：表示内核允许分配超过所有物理内存和交换空间总和的内存。echo &apos;vm.overcommit_memory=1&apos; &gt;&gt; /etc/sysctl.conf# 表示强制Linux VM最低保留多少空闲内存（Kbytes）。当可用内存低于这个参数时，系统开始回收cache内存，以释放内存，直到可用内存大于这个值。RocketMQ需要大量使用页缓存，故需要适当小的设置该值。echo &apos;vm.min_free_kbytes=5000000&apos; &gt;&gt; /etc/sysctl.confecho &apos;vm.drop_caches=1&apos; &gt;&gt; /etc/sysctl.conf# 在申请内存时，内核在当前zone(内存页)内没有足够内存可用的情况下，会根据zone_reclaim_mode的设置来决策是从下一个zone找空闲内存还是在zone内部进行回收。# 0：意味着关闭zone_reclaim模式，可以从其他zone或NUMA节点回收内存。# 1：表示打开zone_reclaim模式，这样内存回收只会发生在本地节点内。# 2：在本地回收内存时，可以将cache中的脏数据写回硬盘，以回收内存。# 3：可以用swap方式回收内存。echo &apos;vm.zone_reclaim_mode=0&apos; &gt;&gt; /etc/sysctl.conf# 一个进程可以拥有的VMA(虚拟内存区域)的数量。虚拟内存区域是一个连续的虚拟地址空间区域。echo &apos;vm.max_map_count=655360&apos; &gt;&gt; /etc/sysctl.conf# 指定了当文件系统缓存脏页数量达到系统内存百分之多少时(如5%)就会触发pdflush/flush/kdmflush等后台回写进程运行，将一定缓存的脏页异步地刷入磁盘。echo &apos;vm.dirty_background_ratio=50&apos; &gt;&gt; /etc/sysctl.conf# 指定了当文件系统缓存脏页数量达到系统内存百分之多少时(如10%)，新的IO请求将会被阻挡，直到脏数据被写进磁盘。这是造成IO卡顿的重要原因，但这也是保证内存中不会存在过量脏数据的保护机制。echo &apos;vm.dirty_ratio=50&apos; &gt;&gt; /etc/sysctl.conf# 用来控制从swap空间换入数据的时候，一次连续读取的页数，这相当于对交换空间的预读。echo &apos;vm.page-cluster=3&apos; &gt;&gt; /etc/sysctl.conf# 指定多长时间pdflush/flush/kdmflush这些进程会唤醒一次，然后检查是否有缓存需要清理。echo &apos;vm.dirty_writeback_centisecs=360000&apos; &gt;&gt; /etc/sysctl.conf# swappiness=0的时候表示最大限度使用物理内存，然后才是swap空间，swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面。Linux的基本默认设置为60。echo &apos;vm.swappiness=10&apos; &gt;&gt; /etc/sysctl.conf 系统文件句柄设置1234# 可以打开最大文件描述符的数量。echo &apos;ulimit -n 1000000&apos; &gt;&gt; /etc/profile# admin用户可用的最大进程数量(硬限制)。echo &apos;admin hard nofile 1000000&apos; &gt;&gt; /etc/security/limits.conf","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"HTTP协议","slug":"基础之HTTP协议","date":"2019-10-10T02:22:43.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2019/10/10/基础之HTTP协议/","link":"","permalink":"http://yoursite.com/2019/10/10/基础之HTTP协议/","excerpt":"RFC文档","text":"RFC文档 HTTP请求消息的解析解析HTTP消息的一般流程是先将起始行读入到一个构造体中，将所有头字段读入到一个哈希表中（以字段的名称作为键）直到遇到空行，然后使用以上解析得到的信息来决定是否需要消息体。如果消息头表明消息带有消息体，那么将消息体以流的方式读入，直到已读字节数等于消息体的长度或者连接已被关闭为止。 HTTP状态码 1xx(Informational)：这是一个过渡响应，用于在完成所请求的动作以及发送一个最终响应之前传递连接状态或请求进展。 2xx(Successful)：客户端的请求已经被成功接收、理解和接受。 3xx (Redirection)：需要用户代理采取进一步的动作才能实现这个请求。如果提供了一个 Location头字段，用户代理可以自动重定向它的请求到Location的字段值所指定的URI引用，即使它不理解具体的状态码。 301：在请求的URL已被移除时使用。响应的Location首部中应该包含资源现在所处的URL。 302：与301状态码类似，但是，客户端应该使用Location首部给出的URL来临时定位资源，将来的请求仍然使用老的URL。 304：如果客户端发送了一个带条件的GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个304状态码。 4xx(Client Error)状态码种类表明客户端貌似有错误。 5xx(Server Error)状态码种类表明服务器意识到它有错误或者它无法执行所请求的方法。 HTTP首部通用首部：客户端和服务器都可以使用 Cache-Control：指定缓存的工作机制。 Connection： Connection: 不再转发的首部字段名 – 指明那些首部不会被转发，即这些首部为逐跳hop-by-hop首部。 Connection: keep-alive – 在HTTP1.0中表明该连接时长连接。 Connection: close – 在HTTP1.1中表示关闭该连接。 Transfer-Encoding：告诉接收端为了保证报文的可靠传输，对报文采用什么编码方式。该首部是一个逐跳传输消息首部，即仅应用于两个节点之间的消息传递，而不是所请求的资源本身。 Transfer-Encoding: chunked – 表明报文时分块传输的。 Date：表明创建HTTP报文的日期和时间。 Via：显示报文经过的中间节点（代理、网关）。 请求首部：请求报文特有 Host：告知服务器，请求的资源所处的互联网主机名和端口号。虚拟主机运行在同一个IP上，因此使用首部字段Host加以区分。Host头字段的内容是一个关键信息，所以用户代理应该将Host作为头部的第一个字段，紧随于请求行之后。 Referer：使服务器知道客户端是从哪里获得其请求的URL。 User-Agent：创建请求的浏览器和用户代理名称等信息传达给服务器。 Cookie：客户端用它向服务器传递一个令牌。 Accept：相当于（Accept-type），用来通知服务器用户代理能够处理的媒体类型及媒体类型的相对优先级。例如accept: application/json, text/javascript, /; q=0.01。权重值q的范围是0~1（可精确到小数点后3位），且1为最大值。不指定权重q值时，默认权重为q=1.0。 Accept-Charset：来通知服务器用户代理支持的字符集及字符集的相对优先顺序。 Accept-Encoding：段用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序 Accept-Language：用来告知服务器用户代理能够处理的自然语言集。例如Accept-Language: zh-cn,zh;q=0.7,en-us,en;q=0.3。 响应首部：响应报文特有 Age：从最初创建开始的响应持续时间。 Location：对于201(Created)响应，Location的值引用的是由于这个请求而创建的主要资源。对于3xx(Redirection)响应，Location的值引用的是重定向的目标。 Allow：列出了声明目标资源所支持的一系列方法。这个字段的目的是确切通知给接收端这个资源有哪些有效的请求方法。 Server：告诉客户端当前服务器上安装的HTTP服务器应用程序信息。 实体首部：用于说明实体的属性 Allow：用于通知客户端能够支持Request-URI指定资源的所有HTTP方法。例如Allow: GET, HEAD。 Content-Encoding：告知客户端服务器对实体的主体部分选用的内容编码方式。例如Content-Encoding: gzip。 Content-Language：告知客户端，实体主体使用的自然语言（指中文或英文等语言）。例如Content-Language: zh-CN。 Content-Length：表明了实体主体部分的大小（单位是字节）。例如Content-Length: 15000。 Content-Type：说明了实体主体内对象的媒体类型。例如Content-Type: text/html; charset=UTF-8。 常用的Content-Type类型 application/json：目前的最常用的Content-Type类型，即传递JSON数据。 application/octet-stream：Postman中的raw模式使用该类型，只可以上传二进制数据。 application/x-www-form-urlencoded：浏览器使用表单提交数据时默认的编码格式，会将参数转换成key=value&amp;key=value格式，并对数据进行URLEncoder编码，即将键值对的参数用&amp;连接起来，如果有空格，将空格转换为+加号；有特殊符号，将特殊符号转换为ASCII HEX值。对于Get请求，是将参数放在?后面，即?key=value&amp;key=value格式，Post请求则是将key=value&amp;key=value放在请求体（Form Data）中。 multipart/form-data：一般格式为multipart/form-data; boundary=————————–138759662723671253948031。boundary的值用来分隔每个参数。该类型即可以上传键值对，也可以上传文件，相当于2和3的混合体。 HTTP性能瓶颈 TCP连接建立握手和TCP慢启动拥塞控制：慢启动是指TCP连接会随着时间进行自我调谐，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。 用于捎带确认的TCP延迟确认算法: TCP协议为了确保数据的可靠传输实现了自己的确认机制。每个 TCP 段都有一个序列号和数据完整性校验和。每个段的接收者收到完好的段时，都会向发送者回送小的确认分组。如果发送者没有在指定的窗口时间内收到确认信息，发送者就认为分组已被破坏或损毁，并重发数据。 由于确认报文很小，所以TCP允许在发往相同方向的输出数据分组中对其进行捎带。TCP将返回的确认信息与输出的数据分组结合在一起，可以更有效地利用网络。为了增加确认报文找到同向传输数据分组的可能性，很多TCP栈都实现了一种延迟确认算法。延迟确认算法会在一个特定的窗口时间（通常是100～200毫秒）内将输出确认存放在缓冲区中，以寻找能够捎带它的输出数据分组。如果在那个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送。 但是，HTTP具有双峰特征的请求，应答行为降低了捎带信息的可能。当希望有相反方向回传分组的时候，偏偏没有那么多。通常，延迟确认算法会引入相当大的时延。根据所使用操作系统的不同，可以调整或禁止延迟确认算法。 数据聚集的Nagle算法: Nagle算法是指在发送的数据在未被确认前，如果有新的小数据生成，那就把小数据收集起来，等凑足一个MSS或者收到确认后再发送。 Nagle算法会引发几种HTTP性能问题。首先，小的HTTP报文可能无法填满一个分组，可能会因为等待那些永远不会到来的额外数据而产生时延。其次，Nagle算法与延迟确认之间的交互存在问题——Nagle算法会阻止数据的发送，直到有确认分组抵达为止，但确认分组自身会被延迟确认算法延迟100～200毫秒。 HTTP应用程序常常会在自己的栈中设置参数TCP_NODELAY，禁用Nagle算法，提高性能。如果要这么做的话，一定要确保会向TCP写入大块的数据，这样就不会产生一堆小分组了。 TIME_WAIT时延和端口耗尽：当某个TCP端点关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近所关闭连接的IP地址和端口号。这类信息只会维持一小段时间，通常是所估计的最大分段试用期的两倍（称为2MSL,通常为2分钟）左右，以确保在这段时间内不会创建具有相同地址和端口号的新连接。实际上，这个算法可以防止在2分钟内创建、关闭并重新创建2个相同IP地址和端口号的连接。2MSL的连接关闭延迟通常只有在进行性能基准测试时才有可能出现问题。 HTTP长连接为了解决TCP连接建立握手和TCP慢启动拥塞控制所带来的网络时延问题，在HTTP/1.0和HTTP/1.1中都引入了长连接的概念。不过长连接需要注意以下几点： 长连接必须有Content-Length首部或分块传输编码方式编码的连接。 HTTP/1.0和HTTP/1.1的长连接方式不同。HTTP/1.1的代理服务器不应该与HTTP/1.0客户端建立持久连接。 Content-Length字段必须真实反映实体长度，通常如果Content-Length比实际长度短，会造成内容被截断；如果比实体内容长，会造成等待。 Content-Length的问题 实际应用中，有些时候实体长度并没那么好获得，例如实体来自于网络文件，或者由动态语言生成。这时候要想准确获取长度，只能开一个足够大的Buffer，等内容全部生成好再计算。但这样做一方面需要更大的内存开销，另一方面也会让客户端等更久。 所以可以使用分块编码(chunked)的方式来传输。在头部加入Transfer-Encoding: chunked之后，就代表这个报文采用了分块编码。这时，报文中的实体需要改为用一系列分块来传输。每个分块包含十六进制的长度值和数据，长度值独占一行，长度不包括它结尾的CRLF(\\r\\n)，也不包括分块数据结尾的CRLF。最后一个分块长度值必须为0，对应的分块数据为CRLF，表示实体结束。 HTTPSHTTP加上加密处理和认证以及完整性保护后即是HTTPS。 对称加密和非对称加密 加密和解密同用一个密钥的方式称为对称加密。对称加密进行加密时必须将密钥也发给对方。如果通信被监听那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。 非对称加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。 HTTPS加密方式非对称加密处理起来更为复杂效率更低，所以HTTPS使用非对称加密的方式传递对称加密的密匙，再使用对称加密的方式来进行通信。 HTTPS通信过程 客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件列表(所使用的加密算法及密钥长度等)。 服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。 之后服务器发送Certificate报文。报文中包含公开密钥证书。 最后服务器发送Server Hello Done报文通知客户端，SSL第一次握手结束。 客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串(对称加密的密钥)。 接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密。 客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 服务器同样发送Change Cipher Spec报文和Finished报文。 服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。 应用层协议通信，即发送HTTP响应。 证明公开密钥正确性的证书公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了。为了解决上述问题，可以使用由数字证书认证机构（CA，Certificate Authority）和其相关机关颁发的公开密钥证书。 服务器的运营人员向数字证书认证机构提出公开密钥的申请。数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起。 服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称为证书。 接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确服务器的公开密钥是值得信赖的。 多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。 HTTP2.0HTTP2.0优势 基于二进制分帧的多路复用，解决了HTTP1.X的对头阻塞(Head-Of-Line Blocking)问题。 可以定义请求的优先级。 使用了首部压缩技术，压缩算法使用HPACK。 使用首部表来跟踪和存储之前发送的键-值对。首部表在连接过程中始终存在，新增的键-值对会更新到表尾，不需要每次通信都需要再携带首部。 增加了服务端推送功能，服务端可以根据客户端的请求，提前返回多个响应，推送额外的资源给客户端。 HTTP2.0协商 基于ALPN的协商过程：客户端在TLS握手Client Hello阶段表明自身支持HTTP2.0。服务端收到后，响应Server Hello，表示自己也支持HTTP2.0。双方开始HTTP 2.0通信。 基于HTTP的协商过程：客户端也可以使用HTTP Upgrade机制来使用HTTP2.0。客户端和服务端都可以使用Upgrade请求头来携带升级的协议。 HTTP3.0 - 队头阻塞HTTP2.0无法解决TCP队首阻塞问题。因为TCP使用滑动窗口机制来保证数据传输的可靠性，所以当出现一个数据包丢失时，当前连接就需要等待丢失的数据包重新传输，会将所有的HTTP请求都阻塞掉。HTTP3.0通过是使用QUIC协议替换TCP协议来解决该问题。QUIC底层使用UDP协议实现数据传输，所以该数据包看你被运营商丢弃。","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"网络编程模型","slug":"基础之网络编程模型","date":"2019-10-10T02:22:43.000Z","updated":"2021-07-09T13:15:37.137Z","comments":true,"path":"2019/10/10/基础之网络编程模型/","link":"","permalink":"http://yoursite.com/2019/10/10/基础之网络编程模型/","excerpt":"线程驱动和事件驱动 线程驱动：当收到一个请求的时候，将会为该请求开一个新的线程来处理请求。一般存在一个线程池，线程池中有空闲的线程，会从线程池中拿取线程来进行处理，如果线程池中没有空闲的线程，新来的请求将会进入队列排队，直到线程池中空闲线程。 事件驱动：当进来一个新的请求的时，请求将会被压入队列中，然后通过一个循环来检测队列中的事件状态变化，如果检测到有状态变化的事件，那么就执行该事件对应的处理代码，一般都是回调函数。对于事件驱动编程来说，如果某个时间的回调函数是计算密集型，或者是阻塞I/O,那么这个回调函数将会阻塞后面所有事件回调函数的执行。","text":"线程驱动和事件驱动 线程驱动：当收到一个请求的时候，将会为该请求开一个新的线程来处理请求。一般存在一个线程池，线程池中有空闲的线程，会从线程池中拿取线程来进行处理，如果线程池中没有空闲的线程，新来的请求将会进入队列排队，直到线程池中空闲线程。 事件驱动：当进来一个新的请求的时，请求将会被压入队列中，然后通过一个循环来检测队列中的事件状态变化，如果检测到有状态变化的事件，那么就执行该事件对应的处理代码，一般都是回调函数。对于事件驱动编程来说，如果某个时间的回调函数是计算密集型，或者是阻塞I/O,那么这个回调函数将会阻塞后面所有事件回调函数的执行。 五种I/O模型对于Unix的一次I/O访问（以read为例），数据会先被拷贝到操作系统的缓冲区中，然后才会从操作系统的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生的时候，会经历两个阶段： 等待数据准备 (Waiting for the data to be ready)。 将数据从内核中拷贝到进程中（Copying the data from the kernel to the process）。 基本概念 文件描述符：是一个用于表述指向文件的引用的抽象化概念。文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。 缓存I/O：又称标准I/O，大多数文件系统中默认I/O都是缓存I/O。在Linux的缓存I/O机制中，操作系统会将I/O的数据缓存在文件系统的页缓存中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的CPU以及内存开销是非常大的。 阻塞式I/O模型在Linux中，默认情况下所有的Socket都是阻塞的。当用户进程调用了recvfrom这个系统调用，内核就开始了IO的第一个阶段：准备数据。对于网络IO来说，很多时候数据一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候内核就要等待足够的数据到来。而在用户进程这边，整个进程就会被阻塞（是进程自己选择的阻塞）。当内核的数据准备好了，用户进程才解除阻塞的状态并将数据从内核拷贝到用户内存。 阻塞I/O的特点是在I/O执行的两个阶段都被阻塞了。 非阻塞式I/O模型Linux中也可以设置Socket使其变成非阻塞。即当用户发出read操作时，如果内核中数据还没有准备好，那么它并不会阻塞用户进程，而是立即返回一个错误。从用户进程的角度讲，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备好了，并且又再次收到了用户进程的系统调用，那么用户进程就可以就将数据拷贝到了用户内存。 非阻塞I/O虽然在第一阶段不会阻塞，但是用户进程需要不断的主动询问内核数据是否准备好了。 I/O复用模型 - select、poll、epoll应用进程调用select函数并阻塞在该系统调用上，而不是阻塞在真正的I/O系统调用上。然后将Socket注册到该函数上，该函数会不断的轮询所负责的所有Socket，当某个Socket有数据到达了，就通知用户进程。然后用户进程调用recvfrom把所读数据报复制到应用进程缓冲区。将数据从内核拷贝到用户进程。 I/O复用优势在于单个进程可以处理多个网络连接，但在单个网络连接上并不显得有什么优势，事实上由于使用select需要两个而不是单个系统调用，I/O复用还稍有劣势。 信号驱动式I/O模型也可以用信号，让内核在描述符就绪时发送SIGIO信号通知用户进程。首先开启套接字的信号驱动式I/O功能并通过sigaction系统调用安装一个信号处理函数。该系统调用将立即返回，用户进程继续工作，也就是说它没有被阻塞。当数据报准备好读取时，内核就为该进程产生一个SIGIO信号。随后既可以在信号处理函数中调用recvfrom读取数据报，并通知主循环数据已准备好待处理，也可以立即通知主循环，让它读取数据报。 模型的优势在于等待数据报到达期间进程不被阻塞。主循环可以继续执行，只要等待来自信号处理函数的通知：既可以是数据已准备好被处理，也可以是数据报已准备好被读取。 异步I/O模型告知内核启动某个操作，并让内核在整个操作（包括将数据从内核复制到我们自己的缓冲区）完成后通知我们。这种模型与信号驱动模型的主要区别在于：信号驱动式I/O是由内核通知我们何时可以启动一个I/O操作，而异步I/O模型是由内核通知我们I/O操作何时完成。 异步I/O的特点是在I/O的两个阶段都不会阻塞。 一般来说，服务端IO主要有两种情况：来着网络的IO和对文件（设备）的IO。Windows的AIO模型能很好的适用于这两种情况。而Linux针对前者提供了epoll模型，针对后者提供了AIO模型。IO复用模型select、poll、epoll都是IO多路复用的机制的实现。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。select模式1int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 当用户进程调用了select函数，那么整个进程会被阻塞，同时，内核被委托会监视所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 select函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间），函数返回。select函数只返回就绪的描述符的数量而不能具体到那个描述符，所以需要遍历fd_set，来找到真正就绪的描述符。 select模式的缺点 每次调用select，都需要把fd集合从用户态拷贝到内核态，同时每次调用select都需要在内核遍历传递进来的所有fd，增加了系统开销。 内核和用户进程都需要遍历fd_set来获取就绪的描述符，所以当文件描述符数量过大后性能会下降。 select支持的文件描述符数量太小了，默认是1024。 poll和select的区别123456int poll(struct pollfd *fds, unsigned int nfds, int timeout);struct pollfd &#123; int fd; /* 文件描述发 */ short events; /* 等待的事件 */ short revents; /* 实际发生的事件 */&#125;; poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构体而不是select的fd_set数组结构。同时，pollfd并没有最大数量限制，但是数量过大后性能也是会下降，因为poll函数返回后，也需要需要轮询pollfd来获取就绪的描述符。 epoll函数介绍123int epoll_create(int size)；int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll_create函数：创建一个epoll_event树的根节点，size用来告诉内核这个epoll可能监听的文件描述符数目，该参数并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下可以通过查看/proc/进程id/fd/查看这个fd，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 epoll_ctl函数：对指定描述符fd执行op操作。 epfd：是epoll_create函数的返回值，即句柄数的根节点。 op：表示op操作，用三个宏来表示，添加EPOLL_CTL_ADD、删除EPOLL_CTL_DEL、修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 fd：是需要监听的fd（文件描述符）。 epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：123456789101112131415161718struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;;typedef union epoll_data_t &#123; void *ptr; int fd; uint32_t u32; uint64_t u64;&#125;// events可以是以下几个宏的集合：EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 epoll_wait函数：等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 水平触发和边缘触发一个管道收到了1kb的数据，epoll会立即返回，此时读了512字节数据，然后再次调用epoll。这时如果是水平触发的，epoll会立即返回，因为有数据准备好了。如果是边缘触发的不会立即返回，因为此时虽然有数据可读但是已经触发了一次通知，在这次通知到现在还没有新的数据到来，直到有新的数据到来epoll才会返回，此时老的数据和新的数据都可以读取到（当然是需要这次你尽可能的多读取）。 零拷贝技术传统的Linux操作系统的标准I/O接口是基于数据拷贝操作的，即I/O操作会导致数据在操作系统内核地址空间的缓冲区和应用程序地址空间定义的缓冲区之间进行传输。这样做最大的好处是可以减少磁盘I/O的操作，因为如果所请求的数据已经存放在操作系统的高速缓冲存储器中，那么就不需要再进行实际的物理磁盘I/O操作。但是数据传输过程中的数据拷贝操作却导致了极大的CPU开销，限制了操作系统有效进行数据传输操作的能力。而零拷贝可以避免在用户态(User-space)与内核态(Kernel-space)之间来回拷贝数据。 缓冲I/O进行数据传输的流程 当应用程序需要访问某块数据的时候，操作系统内核会先检查这块数据是不是因为前一次对相同文件的访问而已经被存放在操作系统内核地址空间的缓冲区内，如果在内核缓冲区中找不到这块数据，Linux操作系统内核会先将这块数据从磁盘读出来放到操作系统内核的缓冲区里去。如果这个数据读取操作是由DMA完成的，那么在DMA进行数据读取的这一过程中，CPU只是需要进行缓冲区管理，以及创建和处理DMA，除此之外，CPU不需要再做更多的事情。 DMA(Direct Memory Access)—直接存储器存取，是单片机的一个外设，它的主要功能是用来搬数据，但是不需要占用CPU，即在传输数据的时候，CPU可以干其他的事情，好像是多线程一样。 DMA执行完数据读取操作之后，会通知操作系统做进一步的处理。Linux操作系统会根据read()系统调用指定的应用程序地址空间的地址，把这块数据存放到请求这块数据的应用程序的地址空间中去。 在接下来的write()系统调用过程中，操作系统需要将数据再一次从用户应用程序地址空间的缓冲区拷贝到与网络堆栈相关的内核缓冲区中去，这个过程也是需要占用CPU的。 数据拷贝操作结束以后，数据会被打包，然后发送到网络接口卡上去。在数据传输的过程中，应用程序可以先返回进而执行其他的操作。 Linux中的零拷贝技术 直接I/O：对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输：这类零拷贝技术针对的是操作系统内核并不需要对数据进行直接处理的情况，数据可以在应用程序地址空间的缓冲区和磁盘之间直接进行传输，完全不需要Linux操作系统内核提供的页缓存的支持。 应用程序在数据进行传输的过程中不需要对数据进行访问时将数据从Linux的页缓存拷贝到用户进程的缓冲区中就可以完全避免，传输的数据在页缓存中就可以得到处理。Linux中提供类似的系统调用主要有mmap()、sendfile()以及splice()。 如果操作系统内核和应用程序都需要堆数据进行处理时需要延续了传统的通信方式，但是对页缓存和用户进程的缓冲区之间的传输过程进行优化。在Linux中，该方法主要利用了写时复制技术。 Netty中的零拷贝Netty的零拷贝完全是在用户态(Java层面)的，它的零拷贝的更多的是偏向于优化数据操作这样的概念。 Netty提供了CompositeByteBuf类，它可以将多个ByteBuf合并为一个逻辑上的ByteBuf，避免了各个ByteBuf之间的拷贝。 通过wrap操作，我们可以将byte[]数组、ByteBuf、ByteBuffer等包装成一个Netty ByteBuf对象，进而避免了拷贝操作。 ByteBuf支持slice操作，因此可以将ByteBuf分解为多个共享同一个存储区域的ByteBuf，避免了内存的拷贝。 通过FileRegion包装的FileChannel.tranferTo实现文件传输，可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。 sendfile()函数 sendfile()系统调用利用DMA引擎将文件中的数据拷贝到操作系统内核缓冲区中后数据被拷贝到与socket相关的内核缓冲区中去。然后网卡的DMA引擎将数据从内核socket缓冲区中拷贝到协议引擎中去。该操作在进行数据传输仍然还需要一次多余的数据拷贝操作。 在Linux2.4中将文件中的数据拷贝到操作系统内核缓冲区中后直接将带有文件位置和长度信息的缓冲区描述符添加到socket缓冲区中去，此过程不需要将数据从操作系统内核缓冲区拷贝到socket缓冲区中，网卡的DMA引擎会将数据直接从内核缓冲区拷贝到协议引擎中去。 相关参考：Linux中的零拷贝技术1 | Linux中的零拷贝技术2","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"一些工具类","slug":"Java基础之一些工具类","date":"2019-09-23T12:56:21.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/09/23/Java基础之一些工具类/","link":"","permalink":"http://yoursite.com/2019/09/23/Java基础之一些工具类/","excerpt":"BigDecimal 基本方法：加（add(BigDecimal)）、减（subtract(BigDecimal)）、乘（multiply(BigDecimal)）、除（divide(BigDecimal)）。 除法时需要传入小数点后的位数和取值方式。 RoundingMode.CEILING：向正无限大方向舍入的舍入模式。 RoundingMode.FLOOR：向负无限大方向舍入的舍入模式。 RoundingMode.DOWN：向零方向舍入的舍入模式。 RoundingMode.UP：远离零方向舍入的舍入模式。 RoundingMode.HALF_DOWN：向最接近数字方向舍入的舍入模式，如果与两个相邻数字的距离相等，则向下舍入。 RoundingMode.HALF_UP：向最接近数字方向舍入的舍入模式，如果与两个相邻数字的距离相等，则向上舍入。 RoundingMode.HALF_EVEN：向最接近数字方向舍入的舍入模式，如果与两个相邻数字的距离相等，则向相邻的偶数舍入。 RoundingMode.UNNECESSARY用于断言请求的操作具有精确结果的舍入模式，因此不需要舍入。 stripTrailingZeros()方法可以去除尾部的0，然后可以用scale()获取小数点的位数。 toString()方法可能是科学计数法所以可以使用toPlainString()方法转换为字符串。 Double转BigDecimal使用BigDecimal.valueOf(Double)而不是new BigDecimal(Double)否则可能会丢失精度。","text":"BigDecimal 基本方法：加（add(BigDecimal)）、减（subtract(BigDecimal)）、乘（multiply(BigDecimal)）、除（divide(BigDecimal)）。 除法时需要传入小数点后的位数和取值方式。 RoundingMode.CEILING：向正无限大方向舍入的舍入模式。 RoundingMode.FLOOR：向负无限大方向舍入的舍入模式。 RoundingMode.DOWN：向零方向舍入的舍入模式。 RoundingMode.UP：远离零方向舍入的舍入模式。 RoundingMode.HALF_DOWN：向最接近数字方向舍入的舍入模式，如果与两个相邻数字的距离相等，则向下舍入。 RoundingMode.HALF_UP：向最接近数字方向舍入的舍入模式，如果与两个相邻数字的距离相等，则向上舍入。 RoundingMode.HALF_EVEN：向最接近数字方向舍入的舍入模式，如果与两个相邻数字的距离相等，则向相邻的偶数舍入。 RoundingMode.UNNECESSARY用于断言请求的操作具有精确结果的舍入模式，因此不需要舍入。 stripTrailingZeros()方法可以去除尾部的0，然后可以用scale()获取小数点的位数。 toString()方法可能是科学计数法所以可以使用toPlainString()方法转换为字符串。 Double转BigDecimal使用BigDecimal.valueOf(Double)而不是new BigDecimal(Double)否则可能会丢失精度。 时间类java.sql.Date java.util.Date java.util.Calendar java.time. LocalDate 只包含日期，比如：2018-09-24 LocalTime 只包含时间，比如：10:32:10 LocalDateTime 包含日期和时间，比如：2018-09-24 10:32:10 时间和字符串之间的相互转换： DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); LocalDateTime now = LocalDateTime.now(); String nowText = now.format(formatter); LocalDateTime datetime = LocalDateTime.parse(nowText, formatter); java.util.concurrent.TimeUnit org.apache.commons.lang3.time. DateUtils DateFormatUtils","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Java设计模式之适配器模式","slug":"Java设计模式之适配器模式","date":"2019-07-15T11:19:54.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/15/Java设计模式之适配器模式/","link":"","permalink":"http://yoursite.com/2019/07/15/Java设计模式之适配器模式/","excerpt":"统中有一套完整的类结构，而我们需要利用其中摸某一个类的功能（即方法），但是我们的客户端只认识另一个和这个类结构不相关的接口，这时候就可以使用适配器模式将这个现有的类与我们的目标接口进行适配，最终获得一个符合需要的接口并包含复用的类的功能的类。本来是火鸡却实现鸭子接口，当你客户需要一个鸭子的时候，就可以假装成鸭子。","text":"统中有一套完整的类结构，而我们需要利用其中摸某一个类的功能（即方法），但是我们的客户端只认识另一个和这个类结构不相关的接口，这时候就可以使用适配器模式将这个现有的类与我们的目标接口进行适配，最终获得一个符合需要的接口并包含复用的类的功能的类。本来是火鸡却实现鸭子接口，当你客户需要一个鸭子的时候，就可以假装成鸭子。12345678910111213141516171819202122232425262728293031323334353637383940414243public interface Duck &#123; void quack(); void fly();&#125;public interface Turkey &#123; void quack(); void fly();&#125;public class TurkeyAdapter implements Duck &#123; private Turkey turkey; private TurkeyAdapter(Turkey turkey) &#123; this.turkey = turkey; &#125; @Override public void quack() &#123; turkey.quack(); &#125; @Override public void fly() &#123; turkey.fly(); &#125; public static void main(String[] args) &#123; Duck duck = new TurkeyAdapter(new Turkey() &#123; @Override public void quack() &#123; System.out.println(\"咯咯叫！\"); &#125; @Override public void fly() &#123; System.out.println(\"火鸡飞不远！\"); &#125; &#125;); duck.fly(); duck.quack(); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Java设计模式之观察者模式","slug":"Java设计模式之观察者模式","date":"2019-07-15T11:16:15.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/15/Java设计模式之观察者模式/","link":"","permalink":"http://yoursite.com/2019/07/15/Java设计模式之观察者模式/","excerpt":"观察者模式（又称发布-订阅模式），即一个目标物体管理所有依赖于他的观察者物体，并且在它本身状态改变时，它的所有依赖者都会收到通知并自动更新。","text":"观察者模式（又称发布-订阅模式），即一个目标物体管理所有依赖于他的观察者物体，并且在它本身状态改变时，它的所有依赖者都会收到通知并自动更新。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface Observer &#123; void update(Observable o);&#125;class ConcreteObserver1 implements Observer &#123; @Override public void update(Observable o) &#123; System.out.println(\"观察者1观察到\" + o.getClass().getSimpleName() + \"发生变化\"); System.out.println(\"观察者1做出相应\"); &#125;&#125;class ConcreteObserver2 implements Observer &#123; @Override public void update(Observable o) &#123; System.out.println(\"观察者1观察到\" + o.getClass().getSimpleName() + \"发生变化\"); System.out.println(\"观察者1做出相应\"); &#125;&#125;/** * 被观察者 * @author fengbo */public class Observable &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); private void addObserver(Observer o) &#123; observers.add(o); &#125; private void changed() &#123; System.out.println(\"我是被观察者，我已经发生变化了\"); // 通知观察自己的所有观察者 notifyObservers(); &#125; private void notifyObservers() &#123; for (Observer observer : observers) &#123; observer.update(this); &#125; &#125; public static void main(String[] args) throws Exception &#123; Observable observable = new Observable(); observable.addObserver(new ConcreteObserver1()); observable.addObserver(new ConcreteObserver2()); observable.changed(); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Java设计模式之代理模式","slug":"Java设计模式之代理模式","date":"2019-07-15T11:09:38.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/15/Java设计模式之代理模式/","link":"","permalink":"http://yoursite.com/2019/07/15/Java设计模式之代理模式/","excerpt":"代理模式一般分为静态代理和动态代理。两种代理从虚拟机加载类的角度来讲，本质上都是一样的，都是在原有类的基础上加入一些其他的逻辑，产生一个新的与原有类接口相同确行为不同的类型。","text":"代理模式一般分为静态代理和动态代理。两种代理从虚拟机加载类的角度来讲，本质上都是一样的，都是在原有类的基础上加入一些其他的逻辑，产生一个新的与原有类接口相同确行为不同的类型。 静态代理12345678910111213141516171819202122232425262728293031public interface Source &#123; /** 被代理的方法 */ void method();&#125;/** * 被装饰的方法 * @author fengbo */public class SourceImpl implements Source &#123; @Override public void method() &#123; System.out.println(\"-----Real Method-----\"); &#125;&#125;public class StaticProxy implements Source &#123; private Source source; public StaticProxy() &#123; source = new SourceImpl(); &#125; @Override public void method() &#123; System.out.println(\"----Proxy Before------\"); source.method(); System.out.println(\"----Proxy After-------\"); &#125;&#125; 动态代理12345678910111213141516171819public class DynamicProxy implements InvocationHandler &#123; private Object proxy; public DynamicProxy(Object proxy) &#123; this.proxy = proxy; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"------proxy: \" + proxy.getClass() + \", method: \" + method); if (args != null) &#123; for (Object arg : args) &#123; System.out.println(\" \" + arg); &#125; &#125; return method.invoke(proxy, args); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Java设计模式之策略模式","slug":"Java设计模式之策略模式","date":"2019-07-15T11:04:33.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/15/Java设计模式之策略模式/","link":"","permalink":"http://yoursite.com/2019/07/15/Java设计模式之策略模式/","excerpt":"策略模式定义和封装了一系列的算法，并将每一个算法封装起来，使他们可以相互替换。策略模式让算法独立于使用它的用户而存在。Java8对策略模式进行了很好的封装。","text":"策略模式定义和封装了一系列的算法，并将每一个算法封装起来，使他们可以相互替换。策略模式让算法独立于使用它的用户而存在。Java8对策略模式进行了很好的封装。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public interface FlyBehavior &#123; /** 飞行方式 */ void fly();&#125;/** * 火箭飞行策略 * @author fengbo */class FlyWithRocket implements FlyBehavior &#123; @Override public void fly() &#123; System.out.println(\"我可以靠着火箭飞！\"); &#125;&#125;/** * 翅膀飞行策略 * @author fengbo */class FlyWithWings implements FlyBehavior &#123; @Override public void fly() &#123; System.out.println(\"我可以靠着翅膀飞！\"); &#125;&#125;public class Duck &#123; private FlyBehavior flyBehavior; private void setFlyBehavior(FlyBehavior flyBehavior) &#123; this.flyBehavior = flyBehavior; &#125; private void performFly() &#123; flyBehavior.fly(); &#125; /** * 行为参数化版策略模式，参考Java8实战，第二章通过行为参数化传递代码 * 可以使用java.util.function包里的接口替换FlyBehavior接口 * @param flyBehavior 具体的飞行策略 */ private void performFly(FlyBehavior flyBehavior) &#123; flyBehavior.fly(); &#125; private void performFly(String str, Consumer&lt;String&gt; consumer) &#123; consumer.accept(str); &#125; public static void main(String[] args) &#123; FlyBehavior flyBehavior = new FlyWithWings(); Duck duck = new Duck(); duck.setFlyBehavior(flyBehavior); duck.performFly(); duck.setFlyBehavior(new FlyWithRocket()); duck.performFly(); // lambda简写策略模式 duck.performFly(() -&gt; System.out.println(\"我可以靠着风筝飞\")); duck.performFly(\"我可以靠着智商飞\", System.out::println); // 等同于下面// duck.performFly(\"我可以靠着智商飞\", (str) -&gt; System.out.println(str)); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Java设计模式之模板方法模式","slug":"Java设计模式之模板方法模式","date":"2019-07-15T10:59:42.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/15/Java设计模式之模板方法模式/","link":"","permalink":"http://yoursite.com/2019/07/15/Java设计模式之模板方法模式/","excerpt":"模板方法模式会在父类的一个方法中定义一个算法骨架，而将一些步骤延迟到子类中，模板方法使得子类可以在不改变算法结果的情况下，重新定义算法中的某些步骤。","text":"模板方法模式会在父类的一个方法中定义一个算法骨架，而将一些步骤延迟到子类中，模板方法使得子类可以在不改变算法结果的情况下，重新定义算法中的某些步骤。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public abstract class AbstractPageBuilder &#123; private StringBuffer stringBuffer = new StringBuffer(); String buildHtml() &#123; // 首先加入doctype,因为都是html页面,所以我们父类不需要推迟给子类实现,直接在父类实现 stringBuffer.append(\"&lt;!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\\"&gt;\"); // 页面下面就是成对的一个HTML标签，我们也在父类加入,不需要给子类实现 stringBuffer.append(\"&lt;html xmlns=\\\"http://www.w3.org/1999/xhtml\\\"&gt;\"); // 下面就应该是head标签里的内容了,这个我们父类做不了主了,推迟到子类实现,所以我们定义一个抽象方法,让子类必须实现 appendHead(stringBuffer); // 下面是body的内容了，我们父类依然无法做主，仍然推迟到子类实现 appendBody(stringBuffer); // html标签的关闭 stringBuffer.append(\"&lt;/html&gt;\"); return stringBuffer.toString(); &#125; /** * 第一个模板方法 * @param stringBuffer 参数 */ protected abstract void appendHead(StringBuffer stringBuffer); /** * 第二个模板方法 * @param stringBuffer 参数 */ protected abstract void appendBody(StringBuffer stringBuffer);&#125;public class MyPageBuilder extends AbstractPageBuilder &#123; @Override protected void appendHead(StringBuffer stringBuffer) &#123; stringBuffer.append(\"&lt;head&gt;&lt;title&gt;你好&lt;/title&gt;&lt;/head&gt;\"); &#125; @Override protected void appendBody(StringBuffer stringBuffer) &#123; stringBuffer.append(\"&lt;body&gt;&lt;h1&gt;你好,世界！&lt;/h1&gt;&lt;/body&gt;\"); &#125; public static void main(String[] args) &#123; AbstractPageBuilder pageBuilder = new MyPageBuilder(); System.out.println(pageBuilder.buildHtml()); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Java设计模式之构建器模式","slug":"Java设计模式之构建器模式","date":"2019-07-15T10:56:53.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/15/Java设计模式之构建器模式/","link":"","permalink":"http://yoursite.com/2019/07/15/Java设计模式之构建器模式/","excerpt":"构建器模式，当某个类有很多参数（4个或更多） 特别是其中部分参数是可选的时应该使用的一种设计模式。","text":"构建器模式，当某个类有很多参数（4个或更多） 特别是其中部分参数是可选的时应该使用的一种设计模式。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class BuilderDemo &#123; private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; public static class Builder &#123; /** 必须参数 */ private final int servingSize; private final int servings; /** 非必须参数 */ private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; public Builder(int servingSize, int servings) &#123; this.servingSize = servingSize; this.servings = servings; &#125; public Builder calories(int val) &#123; calories = val; return this; &#125; public Builder fat(int val) &#123; fat = val; return this; &#125; public Builder sodium(int val) &#123; sodium = val; return this; &#125; public Builder carbohydrate(int val) &#123; carbohydrate = val; return this; &#125; public BuilderDemo build() &#123; return new BuilderDemo(this); &#125; &#125; private BuilderDemo(Builder builder) &#123; servingSize = builder.servingSize; servings = builder.servings; calories = builder.calories; fat = builder.fat; sodium = builder.sodium; carbohydrate = builder.carbohydrate; &#125; public static void main(String[] args) &#123; BuilderDemo demo = new Builder(240, 80) .calories(100) .carbohydrate(100) .build(); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Java设计模式之装饰者模式","slug":"Java设计模式之装饰者模式","date":"2019-07-15T10:52:03.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/15/Java设计模式之装饰者模式/","link":"","permalink":"http://yoursite.com/2019/07/15/Java设计模式之装饰者模式/","excerpt":"装饰者模式在不改变原类文件和使用继承的情况下，动态的扩展一个对象的功能。经典案例：Java I/O包里的类。","text":"装饰者模式在不改变原类文件和使用继承的情况下，动态的扩展一个对象的功能。经典案例：Java I/O包里的类。123456789101112131415public class Decorator implements Source &#123; private Source source; public Decorator(Source source) &#123; this.source = source; &#125; @Override public void method() &#123; System.out.println(\"----Decorator Before-------\"); source.method(); System.out.println(\"----Decorator After--------\"); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Java设计模式之单例模式","slug":"Java设计模式之单例模式","date":"2019-07-14T02:49:07.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/07/14/Java设计模式之单例模式/","link":"","permalink":"http://yoursite.com/2019/07/14/Java设计模式之单例模式/","excerpt":"该模式保证了一个类只有一个对象实例。一般会将构造方法私有化，使其不能在类的外部通过new关键字实例化该类对象。","text":"该模式保证了一个类只有一个对象实例。一般会将构造方法私有化，使其不能在类的外部通过new关键字实例化该类对象。 懒汉式123456789101112public class Single &#123; private Single() &#123;&#125; private static Single single = null; public static Single getInstance() &#123; if (single == null) &#123; single = new Single(); &#125; return single; &#125;&#125; 饿汉式123456789public class Single &#123; private Single() &#123;&#125; private static final Single single = new Single(); public static Single getInstance() &#123; return single; &#125;&#125; 枚举 - Effective Java推荐123public enum Single &#123; INSTANCE&#125; 线程安全的饿汉式123456789101112public class Single &#123; private Single() &#123;&#125; private static class SingleCase &#123; private static Single single = new Single(); &#125; public static Single getInstance() &#123; return SingleCase.single; &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Python实现屏幕截图","slug":"Python实现屏幕截图","date":"2019-05-01T03:24:59.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/05/01/Python实现屏幕截图/","link":"","permalink":"http://yoursite.com/2019/05/01/Python实现屏幕截图/","excerpt":"之前使用Python构建了一个图片转文字小工具，但是使用的是使用系统自带的截图工具然后监听目录变化来实现的。接下来我想直接使用Python来构建一个截图工具，这样就可以结合转换工具使用。","text":"之前使用Python构建了一个图片转文字小工具，但是使用的是使用系统自带的截图工具然后监听目录变化来实现的。接下来我想直接使用Python来构建一个截图工具，这样就可以结合转换工具使用。操作系统：Ubuntu18.04编程语言：Python3.6 构建图形界面本文使用Python自带的GUI库Tkinter来构建图形界面。Tkinter使用手册：http://c.biancheng.net/python/tkinter/。 安装python-tk：sudo apt-get install python-tk。 画一个简单的图形界面，只带一个截图按钮并给该按钮绑定监听。代码如下：123456789101112131415161718192021import tkinterroot = tkinter.Tk()root.title('')#指定窗口的大小root.geometry('100x50+400+300')#不允许改变窗口大小root.resizable(False,False)#开始截图def buttonCaptureClick(): print(\"test\") root.state('normal')buttonCapture = tkinter.Button(root, text='截图', command=buttonCaptureClick)buttonCapture.place(x=10, y=10, width=80, height=30)#启动消息主循环try: root.mainloop()except: root.destroy() 截取整个屏幕 安装python3-pil.imagetk：sudo apt-get python3-pil.imagetk。 安装Python库：pip3 install pyscreenshot。 使用pyscreenshot库截取整个屏幕并生成名为temp.gif的图片。代码如下： 123456import pyscreenshot as ImageGrabfilename ='temp.gif'im = ImageGrab.grab()im.save(filename)im.close() 结合图形界面和截取整个屏幕代码生成截图的底图。代码见码云。 监听鼠标12canvas.bind('&lt;Button-1&gt;', onLeftButtonDown)canvas.bind('&lt;ButtonRelease-1&gt;', onLeftButtonUp) 结合截取屏幕的代码见码云。 参考：https://blog.csdn.net/qq_35508118/article/details/81902178","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Python实现的图片转文字小工具","slug":"Python实现的图片转文字小工具","date":"2019-03-01T07:27:16.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/03/01/Python实现的图片转文字小工具/","link":"","permalink":"http://yoursite.com/2019/03/01/Python实现的图片转文字小工具/","excerpt":"阅读PDF书籍时如果该书是扫描版的那么记笔记就需要手打文字。个人感觉及其麻烦（主要还是懒）。所以想着实现一个简单的图片转文字小工具提升一下自己的阅读效率。","text":"阅读PDF书籍时如果该书是扫描版的那么记笔记就需要手打文字。个人感觉及其麻烦（主要还是懒）。所以想着实现一个简单的图片转文字小工具提升一下自己的阅读效率。操作系统：Ubuntu18.04编程语言：Python3.6 监听文件夹使用系统自带的截图工具（Ubuntu为screenshot，快捷键是Shift+PrtSc）选择截取屏幕，screenshot会将截取的图片自动保存到“/home/用户/图片”目录下，那么我只需要监听该目录就可以获取到截取的图片。使用Python文件监听工具pyinotify来实现目录监听。使用pip3 install pyinotify安装该模块，具体监听代码如下：123456789101112131415161718class EventHandler(ProcessEvent): def process_IN_CREATE(self, event): text = os.path.join(event.path,event.name) print(text)def auto_compile(path='.'): wm = WatchManager() mask = IN_CREATE notifier = ThreadedNotifier(wm, EventHandler()) notifier.start() wm.add_watch(path, mask, rec=True, auto_add=True) while True: try: notifier.process_events() if notifier.check_events(): notifier.read_events() except KeyboardInterrupt: notifier.stop() break 代码参考pyinotify使用的是Linux底层的Inotify机制。 使用tesseract-ocr识别获取的图片获取到截取的图片的地址后就可以通过Python的tesserocr模块调用tesseract-ocr来识别图片中的文字。具体代码如下：12345678def image2word(path): try: time.sleep(1) # 停1秒，否则可能会读取图片失败 image = Image.open(path) words = tesserocr.image_to_text(image) print(words) except (OSError, NameError): print(&quot;os error&quot;) Ubuntu下安装tesserocr 安装tesseract-ocr：sudo apt-get install -y tesseract-ocr libtesseract-dev libleptonica-dev。 查看语言支持：tesseract –list-langs。 安装语言：git clone https://github.com/tesseract-ocr/tessdata.gitsudo mv tessdata/* /usr/share/tesseract-ocr/tessdata 安装 tesserocr：pip3 install tesserocr pillow。笔者安装使出现error: command ‘x86_64-linux-gnu-gcc’ failed with exit status 1 ‘错误。 sudo apt install python3-dev \\ build-essential libssl-dev libffi-dev \\ libxml2-dev libxslt1-dev zlib1g-dev 使用pyperclip模块将识别后的文字添加到剪切版 在Ubuntu中使用该模块需要先安装xsel和xclip。sudo apt-get install xselsudo apt-get install xclip 使用pip安装pyperclip：pip3 install pyperclip。 具体代码只需要一行：pyperclip.copy(words)。 源码改善目标 使用Python实现截图后解析替代使用系统自带截图工具。 提高中文识别率。 解决跨平台问题。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Nginx使用","slug":"其它之Nginx使用","date":"2019-01-26T06:07:10.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2019/01/26/其它之Nginx使用/","link":"","permalink":"http://yoursite.com/2019/01/26/其它之Nginx使用/","excerpt":"Nginx基本概念 Nginx是一款轻量级的Web服务器、反向代理服务器及电子邮件代理服务器。目前大多数公司使用Nginx作为反向代理服务器，反向代理是指接受外部网络请求后转发到内网中真正可以处理业务逻辑的服务器上，并将从服务器上得到的结果返回给用户。 正向代理和反向代理的区别是正向代理的用户的真实访问地址不是代理服务器，却通过代理服务器进行了转发；反向代理的用户的访问地址就是代理服务器，而真实处理请求的服务器却不是代理服务器。 代理连接的是两个或多个使用相同协议的应用程序，而网关连接的则是两个或多个使用不同协议的端点。网关扮演的是协议转换器的角色，即使客户端和服务器使用的是不同的协议，客户端也可以通过它完成与服务器之间的事务处理。","text":"Nginx基本概念 Nginx是一款轻量级的Web服务器、反向代理服务器及电子邮件代理服务器。目前大多数公司使用Nginx作为反向代理服务器，反向代理是指接受外部网络请求后转发到内网中真正可以处理业务逻辑的服务器上，并将从服务器上得到的结果返回给用户。 正向代理和反向代理的区别是正向代理的用户的真实访问地址不是代理服务器，却通过代理服务器进行了转发；反向代理的用户的访问地址就是代理服务器，而真实处理请求的服务器却不是代理服务器。 代理连接的是两个或多个使用相同协议的应用程序，而网关连接的则是两个或多个使用不同协议的端点。网关扮演的是协议转换器的角色，即使客户端和服务器使用的是不同的协议，客户端也可以通过它完成与服务器之间的事务处理。 Nginx源码目录解析├ auto #自动检测系统环境以及编译相关的脚本，configure执行时会调用│ ├── cc #关于编译器相关的编译选项的检测脚本│ ├── lib #nginx编译所需要的一些库的检测脚本│ ├── os #与平台相关的一些系统参数与系统调用相关的检测│ └── types #与数据类型相关的一些辅助脚本├ conf #存放默认配置文件，在make install后，会拷贝到安装目录中去├ contrib #存放一些实用工具，如geo配置生成工具（geo2nginx.pl）├ html #存放html文件，在make install后，会拷贝到安装目录中├ man #存放Nginx软件帮助文档，Nginx安装完成后，在命令行中使用man命令可以查看├ objs #configure执行成功时会生成该目录├ src #存放Nginx所有源代码 Nginx配置解析块配置项块配置项由一个配置项名和一对大括号组成。具体有events、http、server、location、upstream等。快配置可以嵌套，内层快直接继承外层快当内外层块中的配置发生冲突时，究竟是以内层块还是外层块的配置为准，取决于解析这个配置项的模块。 Nginx服务的基本配置 daemon on|off：是否以守护进程方式运行Nginx。默认是启用(on)。 master_process on|off：是否以master/worker方式工作。默认是启用(on)，如果用off关闭了master_process方式，就不会fork出worker子进程来处理请求，而是用master进程自身来处理请求。 error_log pathfile level：error日志的设置。默认是error_log logs/error.log error。 debug_connection [IP|CIDR]：仅对指定的客户端输出debug级别的日志，这个配置项实际上属于事件类配置，因此，它必须放在events{…}中才有效。 12345events &#123; # 来自以上IP地址的请求才会输出debug级别的日志，其他请求仍然沿用error_log中配置的日志级别。 debug_connection 10.224.66.14; debug_connection 10.224.57.0/24;&#125; include pathfile：嵌入其他配置文件，将其他配置文件嵌入到当前的nginx.conf文件中，它的参数既可以是绝对路径，也可以是相对路径。 pid path/file：保存master进程ID的pid文件存放路径。默认pid logs/nginx.pid。 user username [groupname]：用于设置master进程启动后，fork出的worker进程运行在哪个用户和用户组下。默认user nobody nobody。 worker_rlimit_nofile limit：设置一个worker进程可以打开的最大文件句柄数。 worker_rlimit_sigpending limit：设置每个用户发往Nginx的信号队列的大小。也就是说，当某个用户的信号队列满了，这个用户再发送的信号量会被丢掉。 HTTP核心模块配置123456789101112131415161718192021222324252627282930# 所有的HTTP配置项都必须直属于http块、server块、location块、upstream块或if块等。http &#123; gzip on; upstream &#123; … &#125; server &#123; # listen参数决定Nginx服务如何监听端口。不加端口时，默认监听80端口。 listen localhost:80; # location会尝试根据用户请求中的URI来匹配上面的/uri表达式，如果可以匹配，就选择location&#123;&#125;块中的配置来处理用户请求。 location /webstatic &#123; if … &#123; … &#125; # 以root方式设置资源路径。 root optwebresource; # 访问首页。访问站点时的URI是/，这时一般是返回网站的首页。 index index.html index.htm; … &#125; location ~* .(jpg|jpeg|png|jpe|gif)$ &#123; … &#125; # 当对于某个请求返回错误码时，如果匹配上了error_page中设置的code，则重定向到新的URI中。 error_page 404 /404.html; &#125; server &#123; … &#125;&#125; client_header_timeout time：读取HTTP头部的超时时间，单位是秒，默认值是60。 client_body_timeout time：读取HTTP包体的超时时间。 send_timeout time：发送响应的超时时间，即Nginx服务器向客户端发送了数据包，但客户端一直没有去接收这个数据包。如果某个连接超过send_timeout定义的超时时间，那么Nginx将会关闭这个连接。 keepalive_disable [msie6|safari|none]：对某些浏览器禁用keepalive功能，针对IE 6及其早期版本、Safari浏览器默认是禁用。 keepalive_timeout time：一个keepalive连接在闲置超过一定时间后（默认的是75秒），服务器和浏览器都会去关闭这个连接。 keepalive_requests n：keepalive长连接上允许承载的请求最大数，一个keepalive连接上默认最多只能发送100个请求。 tcp_nodelay on|off：确定对keepalive连接是否使用TCP_NODELAY选项。 Nginx负载均衡配置12345678910111213141516171819# upstream块定义了一个上游服务器的集群，便于反向代理中的proxy_pass使用。upstream backend &#123; # 将来自某一个用户的请求始终落到固定的一台上游服务器中。 ip_hash; # server指定了一台上游服务器的名字，这个名字可以是域名、IP地址端口、UNIX句柄等。 server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3;&#125;server &#123; location / &#123; # 将当前请求反向代理到URL参数指定的服务器上，URL可以使域名、IP地址等，也可以直接使用upstream块。 proxy_pass http://backend; # 默认情况下反向代理是不会转发请求中的Host头部的。如果需要转发，那么必须加上该配置。 proxy_set_header Host $host; # 此配置项表示转发时的协议方法名。如下配置客户端发来的GET请求在转发时方法名也会改为POST。 proxy_method POST; &#125;&#125;","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"Dubbo之RPC实现细节","slug":"Dubbo-RPC实现细节","date":"2019-01-18T12:43:36.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2019/01/18/Dubbo-RPC实现细节/","link":"","permalink":"http://yoursite.com/2019/01/18/Dubbo-RPC实现细节/","excerpt":"Dubbo使用了Mine、Netty3和Netty4等框架实现了RPC调用，本文主要基于Netty分析Dubbo的RPC实现源码。这部分源码在dubbo-remoting-netty4模块中的NettyServer类中。","text":"Dubbo使用了Mine、Netty3和Netty4等框架实现了RPC调用，本文主要基于Netty分析Dubbo的RPC实现源码。这部分源码在dubbo-remoting-netty4模块中的NettyServer类中。 测试代码12345678910111213public class DubboProtocolTest &#123; private Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); private ProxyFactory proxy = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); @Test public void testDemoProtocol() throws Exception &#123; DemoService service = new DemoServiceImpl(); protocol.export(proxy.getInvoker(service, DemoService.class, URL.valueOf(\"dubbo://127.0.0.1:9020/\" + DemoService.class.getName() + \"?codec=exchange\"))); service = proxy.getProxy(protocol.refer(DemoService.class, URL.valueOf(\"dubbo://127.0.0.1:9020/\" + DemoService.class.getName() + \"?codec=exchange\").addParameter(\"timeout\", 3000L))); service.sayHello(\"world\"); &#125;&#125; 服务导出 ProxyFactory的getInvoker(T proxy, Class type, URL url)方法的逻辑是通过客户端传递过来的参数来调用真实的业务逻辑所在的类的对应方法。以JdkProxyFactory为例（默认是，简单的反射调用逻辑。 1234567891011public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; Method method = proxy.getClass().getMethod(methodName, parameterTypes); return method.invoke(proxy, arguments); &#125; &#125;;&#125; 开启RPC服务的逻辑在NettyServer类的构造方法中，该方法会调用父类的构造方法 –&gt; doOpen()方法。doOpen()方法中实现了使用Netty开启RPC服务器端的逻辑。 服务引入 在Protocol的refer(Class, URL)方法中构建一个Invoker，远程调用服务端的逻辑在Invoker中。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"}]},{"title":"Dubbo之SPI基础使用","slug":"Dubbo-SPI基础使用","date":"2019-01-13T04:29:51.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2019/01/13/Dubbo-SPI基础使用/","link":"","permalink":"http://yoursite.com/2019/01/13/Dubbo-SPI基础使用/","excerpt":"SPI简介SPI全称为Service Provider Interface，是一种服务发现机制。SPI的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过SPI机制为我们的程序提供拓展功能。","text":"SPI简介SPI全称为Service Provider Interface，是一种服务发现机制。SPI的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过SPI机制为我们的程序提供拓展功能。 Java SPI简单测试定义一个接口名称为Autobot。@SPI和@Adaptive是Dubbo注解，为了在Dubbo示例中可以复用该接口。12345678910@SPI(\"optimusPrime\")public interface Autobot &#123; @Adaptive void sayHello1(URL url); @Adaptive(\"test\") void sayHello2(Invoker invoker);&#125; 定义两个实现类，分别为OptimusPrime和Bumblebee。1234567891011121314151617181920212223public class Bumblebee implements Autobot &#123; @Override public void sayHello1(URL url) &#123; System.out.println(\"Hello1, I am Bumblebee.\"); &#125; @Override public void sayHello2(Invoker invoker) &#123; System.out.println(\"Hello, I am Bumblebee.\"); &#125;&#125;public class OptimusPrime implements Autobot &#123; @Override public void sayHello1(URL url) &#123; System.out.println(\"Hello1, I am Optimus Prime.\"); &#125; @Override public void sayHello2(Invoker invoker) &#123; System.out.println(\"Hello, I am Optimus Prime.\"); &#125;&#125; 接下来在resource下创建META-INF/services文件夹，并在其中创建一个文件，名称为Autobot的全限定名spi.Autobot，内容为两个实现的全限定名。 spi.OptimusPrime spi.Bumblebee 测试代码如下：12345678910public class SPITest &#123; @Test public void testJava() &#123; ServiceLoader&lt;Autobot&gt; serviceLoader = ServiceLoader.load(Autobot.class); System.out.println(\"Java SPI\"); for (Autobot autobot : serviceLoader) &#123; autobot.sayHello1(null); &#125; &#125;&#125; Dubbo SPI简单测试接口和实现类代码和上面Java SPI的代码相同。但是需要在resource下创建META-INF/dubbo文件夹，并在其中创建一个文件，名称为Autobot的全限定名spi.Autobot，内容如下。 optimusPrime=spi.OptimusPrime bumblebee=spi.Bumblebee 测试代码如下：1234567891011121314151617public class SPITest &#123; @Test public void testDubbo() &#123; ExtensionLoader&lt;Autobot&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Autobot.class); System.out.println(\"Dubbo SPI\"); Autobot optimusPrime = extensionLoader.getExtension(\"optimusPrime\"); optimusPrime.sayHello1(null); Autobot bumblebee = extensionLoader.getExtension(\"bumblebee\"); bumblebee.sayHello1(null); // 1.输出的是 ==&gt; Hello1, I am Optimus Prime. Autobot autobot1 = extensionLoader.getAdaptiveExtension(); autobot1.sayHello1(URL.valueOf(\"test\")); // 2.输出的是 ==&gt; Hello1, I am Bumblebee. Autobot autobot2 = extensionLoader.getAdaptiveExtension(); autobot2.sayHello1(URL.valueOf(\"test\").addParameter(\"autobot\", \"bumblebee\")); &#125;&#125; Dubbo SPI扩展点自适应装配自适应装配指的是Dubbo SPI会根据方法中传递的URL对象中的配置信息自动解析出需要调用的具体实现类。其中@Adaptive注解的值会和URL的addParameter(String key, String value)中的Key进行匹配，默认是接口名的首字母小写。而@SPI注解的值则代表URL对象的配置信息中没有可以和@Adaptive注解的值配置的值的时候的默认值。具体调用方式如上面的测试代码的1、2所示。与此同时，ExtensionLoader还可以通过扫描扩展点实现类的所有setter方法来动态注入对应的实现类。实现步骤如下： 新建一个接口Robot。123456789@SPI(\"robotImpl\")public interface Robot &#123; @Adaptive void sayHello1(URL url); @Adaptive void sayHello2(Invoker invoker);&#125; 定义一个实现类RobotImpl。123456789101112131415161718192021public class RobotImpl implements Robot &#123; private Autobot autobot; public void setAutobot(Autobot autobot) &#123; this.autobot = autobot; &#125; @Override public void sayHello1(URL url) &#123; autobot.sayHello1(url); System.out.println(\"hello1\"); &#125; @Override public void sayHello2(Invoker invoker) &#123; autobot.sayHello2(invoker); System.out.println(\"hello2\"); &#125;&#125; 在META-INF/dubbo文件夹创建spi.Robot文件。名称为Robot的全限定名spi.Robot，内容为实现类的全限定名。 robotImpl=spi.RobotImpl robotFilter=spi.RobotFilterWrapper 上述代码会自动将Autobot对应的实现类注入到RobotImpl中。具体测试代码如下：12345678910public class SPITest &#123; @Test public void testDubbo2() &#123; Robot robot = ExtensionLoader.getExtensionLoader(Robot.class).getAdaptiveExtension(); System.out.println(\"Dubbo2 SPI\"); robot.sayHello2(new MyInvoker()); System.out.println(\"=============================================\"); robot.sayHello1(URL.valueOf(\"test\").addParameter(\"autobot\", \"bumblebee\")); &#125;&#125; 输出如下： Dubbo2 SPI Hello2, I am Bumblebee. hello2 ============================================= Hello1, I am Bumblebee. hello1 其中匹配方式除了直接传递URL对象，还可以传递Invoker接口的实现类，会根据该实现类的getUrl()方法返回的URL的实例进行匹配。1234567891011121314151617181920public class MyInvoker implements Invoker &#123; @Override public Class getInterface() &#123; return null; &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; return null; &#125; @Override public URL getUrl() &#123; return URL.valueOf(\"test\").addParameter(\"test\", \"bumblebee\"); &#125; @Override public boolean isAvailable() &#123; return true; &#125; @Override public void destroy() &#123;&#125;&#125; 扩展点自动激活有些扩展类可以同时加载多个实现，此时，可以用自动激活来简化配置，如：123456789101112@SPIpublic interface Filter &#123; void testFilter();&#125;@Activate(\"test\")public class MyFilter implements Filter &#123; @Override public void testFilter() &#123; System.out.println(\"filter\"); &#125;&#125; 在META-INF/dubbo文件夹新建spi.Filter文件，内容为： myFilter=spi.MyFilter 扩展点自动包装ExtensionLoader在加载扩展点时，如果加载到的扩展点有拷贝构造函数，则判定为扩展点代理类。123456789101112131415161718192021public class RobotFilterWrapper implements Robot &#123; private Robot robot; public RobotFilterWrapper(Robot robot) &#123; this.robot = robot; &#125; @Override public void sayHello1(URL url) &#123; robot.sayHello1(url); &#125; @Override public void sayHello2(Invoker invoker) &#123; // 根据invoker.getUrl()返回值加载Filter，因为URL中包含有Key为test的配置，所以会调用MyFilter ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension( invoker.getUrl(), \"myFilter\").forEach(Filter::testFilter); robot.sayHello2(invoker); &#125;&#125; 现在调用上面的测试类输出的值为： filter Hello2, I am Bumblebee. hello2 ============================================= Hello1, I am Bumblebee. hello1","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"}]},{"title":"Dubbo之服务的注册发现与访问","slug":"Dubbo-服务的注册方向与访问","date":"2018-12-28T11:49:14.000Z","updated":"2021-07-10T11:03:49.747Z","comments":true,"path":"2018/12/28/Dubbo-服务的注册方向与访问/","link":"","permalink":"http://yoursite.com/2018/12/28/Dubbo-服务的注册方向与访问/","excerpt":"Dubbo基础RPC请求过程客户端启动的时候会根据配置的信息（集成Spring的xsd扩展槽，生成一些自定义的XML标签）为需要远程的接口生成代理类，在代理类中会集成网络通讯的逻辑，即将请求的方法和参数序列化到服务器端，服务器执行后将执行结果序列化返回给客户端，所以在客户端看起来像是直接访问服务端的方法。 服务治理和服务发现服务治理指管理各个服务的服务。服务治理最核心的问题是服务发现和服务注册。Dubbo引入了一个注册中心的概念，服务的注册和发现主要依赖这个服务中心。具体过程为： 服务提供者启动并将服务注册到注册中心注册自己提供的服务。 服务消费者启动，向注册中心订阅自己需要的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法（默认是基于权重的随机算法），选一台提供者进行调用，如果调用失败，在选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Dubbo健壮性 监控中心宕机不影响使用，只是丢失部分采样数据。 注册中心对等集群，任意一台宕机后，将自动切换到另一台。 注册中心全部宕机后，服务提供者和服务消费者仍能通过本地缓存通信。 服务提供者无状态，任意一台宕机后，不影响使用。 服务提供者全部宕机后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复。 在一定时间内服务提供者没有返回，则认为本次调用失败。失败后会再次调用，如果在配置的调用次数内都失败，则认为此次请求异常，抛出异常。可能引发发送邮件重复或账户注册重复等问题。 Dubbo保证幂等性用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。首先在业务逻辑中就应该注意保证接口的幂等性，而像转账这些无法保证的操作可以考虑使用分布式锁。例如使用redis的setNX（SET if Not eXists）若给定的key已经存在，则setNX不做任何操作。支付操作流程：先查询订单状态如果订单未付款就使用setNX根据订单号设置一个key，当服务调用成功或回滚后才会删除key。然后构建一个本地事务修改订单状态和扣款。转账类似，在确认转账但未输入密码付款前可以生成一条有唯一编号且状态为未付款的交易记录。 Dubbo配套设施熔断、限流、降级、隔离，监控、服务测试、api网关、注册中心等。 服务注册与发行：Zookeeper和Eureka（不维护）和Nacos。 负载均衡：自带管控台可以进行配置。 服务熔断：Sentinel和Hystrix（不在活跃开发）。 分布式配置：Nacos，即Nacos可以作为sentinel规则配置中心。 Dubbo调用Dubbo调用原理分析 基于Spring的XML解析扩展机制自定义Dubbo的基于XML的配置格式。 dubbo-config项目的dubbo-config-spring子项目负责解析Dubbo的XML配置文件（主要是解析出Dubbo的注册中心地址、使用的传输协议、服务器端的端口号等）。 解析出配置后服务器端启动，并将自己所能提供的服务注册到注册中心，然后通过dubbo-remoting项目的dubbo-remoting-netty4子项目（dubbo协议）开启服务。 客户端同样通过Spring的XML解析机制解析出配置的各种参数，在通过注册中心或直接配置拿到服务器端的地址，然后通过dubbo-remoting项目的dubbo-remoting-netty4子项目（dubbo协议）连接到服务器端。","text":"Dubbo基础RPC请求过程客户端启动的时候会根据配置的信息（集成Spring的xsd扩展槽，生成一些自定义的XML标签）为需要远程的接口生成代理类，在代理类中会集成网络通讯的逻辑，即将请求的方法和参数序列化到服务器端，服务器执行后将执行结果序列化返回给客户端，所以在客户端看起来像是直接访问服务端的方法。 服务治理和服务发现服务治理指管理各个服务的服务。服务治理最核心的问题是服务发现和服务注册。Dubbo引入了一个注册中心的概念，服务的注册和发现主要依赖这个服务中心。具体过程为： 服务提供者启动并将服务注册到注册中心注册自己提供的服务。 服务消费者启动，向注册中心订阅自己需要的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法（默认是基于权重的随机算法），选一台提供者进行调用，如果调用失败，在选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Dubbo健壮性 监控中心宕机不影响使用，只是丢失部分采样数据。 注册中心对等集群，任意一台宕机后，将自动切换到另一台。 注册中心全部宕机后，服务提供者和服务消费者仍能通过本地缓存通信。 服务提供者无状态，任意一台宕机后，不影响使用。 服务提供者全部宕机后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复。 在一定时间内服务提供者没有返回，则认为本次调用失败。失败后会再次调用，如果在配置的调用次数内都失败，则认为此次请求异常，抛出异常。可能引发发送邮件重复或账户注册重复等问题。 Dubbo保证幂等性用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。首先在业务逻辑中就应该注意保证接口的幂等性，而像转账这些无法保证的操作可以考虑使用分布式锁。例如使用redis的setNX（SET if Not eXists）若给定的key已经存在，则setNX不做任何操作。支付操作流程：先查询订单状态如果订单未付款就使用setNX根据订单号设置一个key，当服务调用成功或回滚后才会删除key。然后构建一个本地事务修改订单状态和扣款。转账类似，在确认转账但未输入密码付款前可以生成一条有唯一编号且状态为未付款的交易记录。 Dubbo配套设施熔断、限流、降级、隔离，监控、服务测试、api网关、注册中心等。 服务注册与发行：Zookeeper和Eureka（不维护）和Nacos。 负载均衡：自带管控台可以进行配置。 服务熔断：Sentinel和Hystrix（不在活跃开发）。 分布式配置：Nacos，即Nacos可以作为sentinel规则配置中心。 Dubbo调用Dubbo调用原理分析 基于Spring的XML解析扩展机制自定义Dubbo的基于XML的配置格式。 dubbo-config项目的dubbo-config-spring子项目负责解析Dubbo的XML配置文件（主要是解析出Dubbo的注册中心地址、使用的传输协议、服务器端的端口号等）。 解析出配置后服务器端启动，并将自己所能提供的服务注册到注册中心，然后通过dubbo-remoting项目的dubbo-remoting-netty4子项目（dubbo协议）开启服务。 客户端同样通过Spring的XML解析机制解析出配置的各种参数，在通过注册中心或直接配置拿到服务器端的地址，然后通过dubbo-remoting项目的dubbo-remoting-netty4子项目（dubbo协议）连接到服务器端。 Dubbo服务调用过程客户端通过一个接口调用方法时，真实调用的是使用Java动态代理、CGLIB、Javassist或者ASM等技术为该接口生成的一个代理对象的方法，该对象的每个方法都会通过使用Netty等网络框架将真正的需要调用的类和方法等参数封装为一个对象并序列化传递到服务器端，服务器端会通过这些参数反射调用真正的业务逻辑实现类并将执行结果序列化并传递回客户端。 服务器端调用链 调用Spring接口解析XML或注解生成一个ServiceBean，该Bean实现了InitializingBean接口，所以在该Bean被Spring容器实例化后会自动调用afterPropertiesSet()方法。 然后调用ServiceBean的父类ServiceConfig的export() –&gt; doExport() –&gt; doExportUrls() –&gt; doExportUrlsFor1Protocol(ProtocolConfig, List)，doExportUrlsFor1Protocol方法会解析出该Bean的传输协议类型。 如果是dubbo协议且有注册中先会调用RegistryProtocol的export(Invoker) –&gt; doLocalExport(Invoker)在调用DubboProtocol的export(Invoker)方法。 如果没有注册中心而是使用直连的话会直接调用DubboProtocol的export(Invoker) –&gt; openServer(URL) –&gt; createServer(URL)–&gt; Exchangers的bind(URL, ExchangeHandler)方法 –&gt; HeaderExchanger的bind(URL, ExchangeHandler)方法 –&gt; Transporters的bind(URL, ChannelHandler…)方法 –&gt; NettyTransporter的bind(URL, ChannelHandler)方法。 在NettyTransporter的bind()方法中会新建一个NettyServer实例，NettyServer的父类AbstractServer的构造方法会调用NettyServer的doOpen()方法。doOpen方法中实现了Netty构建服务器端的逻辑。 其中DubboProtocol的openServer方法会将创建好的NettyServer实例放入一个Map集合中，集合的key是服务器端的真实地址，所以说服务器端并不是每个service都创建一个网络服务，而是根据每个地址创建一个对应的服务。 在步骤3时，如果有注册中心，在服务导出后需要调用注册服务注册到注册中心。在RegistryProtocol的export(Invoker)方法中调用本类的register(URL registryUrl, URL registedProviderUrl)方法，然后调用AbstractRegistryFactory的getRegistry(URL)方法获取Registry。 getRegistry方法会先尝试从缓存中获取Registry，如果缓存中不存在就调用子类的createRegistry(URL)方法创建一个Registry。如果使用Zookeeper作为注册中心，调用的就是ZookeeperRegistryFactory的createRegistry(URL)方法。该方法会构建一个ZookeeperRegistry对象并返回，具体操作注册中心的业务逻辑在该对象中。 客户端调用链Dubbo引用的时机有两个，第一个是在Spring容器调用ReferenceBean的afterPropertiesSet方法时引用服务，第二个是在ReferenceBean对应的服务被注入到其他类中时引用。这两个引用服务的时机区别在于，第一个是饿汉式的，第二个是懒汉式的。默认情况下，Dubbo使用懒汉式引用服务。Dubbo有三种调用服务的方式，第一种是引用本地(JVM)服务，第二是通过直联方式引用远程服务，第三是通过注册中心引用远程服务。不管是哪种引用方式，最后都会得到一个Invoker实例。如果有多个注册中心，多个服务提供者，这个时候会得到一组Invoker实例，此时需要通过集群管理类Cluster将多个Invoker合并成一个实例。 调用Spring接口解析XML或注解生成一个ReferenceBean，该Bean实现了InitializingBean接口，所以在该Bean被Spring容器实例化后会自动调用afterPropertiesSet()方法。 调用本类的getObject() –&gt; 父类ReferenceConfig的get()方法 –&gt; init() –&gt; createProxy(Map&lt;String, String&gt;)方法。 createProxy(Map&lt;String, String&gt;)方法会首先根据配置检查是否为本地调用，若是，则调用InjvmProtocol的refer方法生成InjvmInvoker实例。然后判断是否需要向注册中心请求服务提供方的地址，如果dubbo:reference标签中没有配置url属性就会调用loadRegistries(boolean)方法去加载注册中心。 如果是dubbo协议，会调用DubboProtocol的refer(Class, URL) –&gt; getClients(URL) –&gt; getSharedClient(URL) –&gt; initClient(URL) –&gt; Exchangers的connect(URL, ExchangeHandler)方法 –&gt; HeaderExchanger的connect(URL, ExchangeHandler)方法 –&gt; Transporters的connect(URL, ChannelHandler…)方法 –&gt; NettyTransporter的connect(URL, ChannelHandler)方法。 新建一个NettyClient实例，NettyClient的父类AbstractClient的构造方法会调用NettyClient的doOpen()方法。doOpen方法中实现了Netty客户端连接到服务器端的逻辑。 Invoker模型Invoker是Dubbo的核心模型，代表一个可执行体。在服务提供方，Invoker用于调用服务提供类。在服务消费方，Invoker用于执行远程调用。Invoker是由Protocol实现类构建而来。下图为一个服务的真正调用过程： 集群容错服务目录 存储一些和服务提供者有关的信息，通过服务目录，服务消费者可获得服务提供者的信息，比如ip、端口、服务协议等。通过这些信息，服务消费者就可通过Netty等客户端进行远程调用。 在一个服务集群中，服务提供者数量并不是一成不变的，如果集群中新增了一台机器，相应地在服务目录中就要新增一条服务提供者记录。或者，如果服务提供者的配置修改了，服务目录中的记录也要做相应的更新。 服务目录的服务配置信息是从注册中心获取的。获取到配置信息后会为每条配置信息生成一个Invoker对象，并把这个Invoker对象存储起来，这个Invoker才是服务目录最终持有的对象。Invoker是一个具有远程调用功能的对象。 所以说服务目录可以看做是Invoker集合，且这个集合中的元素会随注册中心的变化而进行动态调整。 服务路由服务路由包含一条路由规则，路由规则决定了服务消费者的调用目标，即规定了服务消费者可调用哪些服务提供者。 集群当出现多个服务提供者时，服务消费者需要决定选择哪个服务提供者进行调用。另外服务调用失败时的处理措施也是需要考虑的，是重试呢，还是抛出异常，亦或是只打印异常等。集群Cluster用途是将多个服务提供者合并为一个Cluster Invoker，并将这个Invoker暴露给服务消费者。这样一来，服务消费者只需通过这个Invoker进行远程调用即可，至于具体调用哪个服务提供者，以及调用失败后如何处理等问题，现在都交给集群模块去处理。 负载均衡负载均衡的责任是将网络请求，或者其他形式的负载均摊到不同的机器上。避免集群中部分服务器压力过大，而另一些服务器比较空闲的情况。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"}]},{"title":"计算机网络","slug":"基础之计算机网络","date":"2018-12-01T07:32:20.000Z","updated":"2021-07-09T13:13:39.705Z","comments":true,"path":"2018/12/01/基础之计算机网络/","link":"","permalink":"http://yoursite.com/2018/12/01/基础之计算机网络/","excerpt":"TCP/IP提供一种面向连接的、可靠的字节流服务。面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信。广播和多播不能用于TCP。","text":"TCP/IP提供一种面向连接的、可靠的字节流服务。面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信。广播和多播不能用于TCP。 计算机网络基础日常网络设备 调制解调器：通常称为猫；负责将数字信号调变到模拟信号上进行传输，并解调收到的模拟信号以得到数字信号。它的目标是产生能够方便传输的模拟信号并且能够通过解码还原原来的数字信号。调制解调器可以使用不同的手段来传送模拟信号，比如使用光纤，射频无线电或电话线等。现在大多数猫都具备路由功能。 路由器：使用IP地址转发分组的存储转发分组交换即，提供了路由和传送两种重要机制。路由器又分为静态路由（由网络管理员手动配置路由表的路由方式）和动态路由（路由器会根据生成算法自动生成路由表）。 路由：决定数据包从来源端到目的端的所经过的路由路径。 传送：将路由器输入端的数据包移送至适当的路由器输出端。 将客户端连接到Internet的路由器被称为边缘路由器。只负责与其他路由器之间（例如ISP的网络）传递数据的路由器被称为核心路由器。其中，边缘路由器一般都具有交换机的功能和NAT功能。 交换机：工作在链路层，用于同一网络内部的快速传输，主要通过MAC地址将在局域网中将数据传送到对应的机器上。交换机只工作在局域网内，不具有路由器的功能，只能实现数据包的转发，其解包只能解链路层协议，再往上层（IP层及以上）都不会被解析。 交换式集线器简称交换机，而中继式集线器简称集线器。 MAC地址表：交换机记录所连接设备的MAC地址和交换机端口的对应关系的表。 ARP缓存表：记录着主机的IP地址和MAC地址的对应关系。 计算机中需要配置的一些信息 子网掩码：负责将IP地址划分为网络地址和主机地址。即指明了一个IP地址的哪些位标识的是主机所在的网络地址以及哪些位标识的是主机地址的位掩码。 网关：负责转发其他服务器通信数据的服务器，接收从客户端发送来的请求时，它就像自己拥有资源的源服务器一样对请求进行处理。有时客户端可能都不会察觉，自己的通信目标是一个网关。由于历史的原因，许多有关TCP/IP的文献曾经把网络层使用的路由器（英语：Router）称为网关，在今天很多局域网采用都是路由来接入网络，因此现在通常指的网关就是路由器的IP。 默认路由：对IP数据包中的目的地址找不到存在的其他路由时，路由器所选择的路由。目的地不在路由器的路由表里的所有数据包都会使用默认路由。主机里的默认路由通常被称作默认网关。 TCP/IP分层模型链路层-以太网协议也称作数据链路层或网络接口层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。它们一起处理与电缆（或其他任何传输媒介）的物理接口细节。在链路层中有两种截然不同的链路层信道。第一种是广播信道，主要用于连接有线局域网、卫星网和混合光纤同轴电缆接入的多台主机；第二种是点对点通信链路，一般用于长距离链路连接的两台路由器之间或用户主机和邻近的以太网交换机之间。而目前大多数有线局域网都使用以太网协议进行通信。 ARP（地址解析协议）：负责将IP地址转换成MAC地址（以太网地址）。 RARP（逆地址解析协议）：和ARP相反，负责将MAC地址转换成IP地址。 ARP首部 上图中的以太网首部使用的是Ehternet II（以太网第二版）协议，它当今现有局域网采用的最通用的通信协议标准。 源地址和目的地址：48bit的MAC地址，目的地址为全1的特殊地址是广播地址。电缆上的所有以太网接口都要接收广播的数据帧。 两个字节长的以太网帧类型表示后面数据的类型。对于ARP请求来说，该字段的值为0x0806。对于IPv4请求来说是0x0800。 硬件类型字段表示硬件地址的类型。它的值为1即表示以太网地址。 协议类型字段表示要映射的协议地址类型。它的值为0x0800即表示IP地址。它的值与包含IP数据报的以太网数据帧中的类型字段的值相同。 硬件地址长度和协议地址长度分别指出硬件地址和协议地址的长度，以字节为单位。对于以太网上IP地址的ARP请求或应答来说，它们的值分别为6和4。 操作字段指出四种操作类型，它们是ARP请求（值为1）、ARP应答（值为2）、RARP请求（值为3）和RARP应答（值为4）。 发送端的硬件地址（在本例中是以太网地址）、发送端的协议地址（IP地址）、目的端的硬件地址和目的端的协议地址。这是一些重复信息：在以太网的数据帧报头中和ARP请求数据帧中都有发送端的硬件地址。 网络层-IP协议也称作互联网层，处理分组在网络中的活动，例如分组的选路。 IP协议（网际协议）：IP提供不可靠、无连接的数据报传送服务。不可靠（unreliable）的意思是它不能保证IP数据报能成功地到达目的地。IP仅提供最好的传输服务。如果发生某种错误时，如某个路由器暂时用完了缓冲区，IP有一个简单的错误处理算法：丢弃该数据报，然后发送ICMP消息报给信源端。任何要求的可靠性必须由上层来提供（如TCP）；无连接（connectionless）这个术语的意思是IP并不维护任何关于后续数据报的状态信息。每个数据报的处理是相互独立的。这也说明，IP数据报可以不按发送顺序接收。如果一信源向相同的信宿发送两个连续的数据报（先是A，然后是B），每个数据报都是独立地进行路由选择，可能选择不同的路线，因此B可能在A到达之前先到达。 ICMP协议（Internet互联网控制报文协议）：IP协议的附属协议。IP层用它来与其他主机或路由器交换错误报文和其他重要信息。诊断工具，Ping和Traceroute都是用了该协议。 IGMP协议（Internet组管理协议）：IGMP是Internet组管理协议。它用来把一个UDP数据报多播到多个主机。 IP首部 首部长度指的是首部占32bit字的数目，包括任何选项。由于它是一个4比特字段，因此首部最长为60个字节。 服务类型（TOS）字段包括一个3bit的优先权子字段（现在已被忽略），4bit的TOS子字段和1bit未用位但必须置0。4bit的TOS分别代表：最小时延、最大吞吐量、最高可靠性和最小费用。 总长度字段是指整个IP数据报的长度，以字节为单位。利用首部长度字段和总长度字段，就可以知道IP数据报中数据内容的起始位置和长度。由于该字段长16比特，所以IP数据报最长可达65535字节。 标识字段唯一地标识主机发送的每一份数据报。通常每发送一份报文它的值就会加1。 TTL（time-to-live）生存时间字段设置了数据报可以经过的最多路由器数。它指定了数据报的生存时间。TTL的初始值由源主机设置（通常为32或64），一旦经过一个处理它的路由器，它的值就减去1。当该字段的值为0时，数据报就被丢弃，并发送ICMP报文通知源主机。 首部检验和字段是根据IP首部计算的检验和码。它不对首部后面的数据进行计算。ICMP、IGMP、UDP和TCP在它们各自的首部中均含有同时覆盖首部和数据检验和码。 传输层-TCP协议主要为两台主机上的应用程序提供端到端的通信。 TCP（传输控制协议）：面向连接的安全的流式传输协议。可以为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等。由于运输层提供了高可靠性的端到端的通信，因此应用层可以忽略所有这些细节。为了提供可靠的服务，TCP采用了超时重传、发送和接收端到端的确认分组等机制。 UDP（用户数据报协议）：面向无连接的不安全的报式传输。即只为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。一个数据报是指从发送方传输到接收方的一个信息单元（例如，发送方指定的一定字节数的信息）。UDP协议任何必需的可靠性必须由应用层来提供。 TCP首部 源端和目的端的端口号：用于寻找发端和接收端应用进程。这两个值加上IP首部中的源端IP地址和目的端IP地址唯一确定一个TCP连接。 序号(Seq)：表示本报文段所发送数据的第一个字节的编号。在TCP连接中所传送的字节流的每一个字节都会按顺序编号。由于序列号由32位表示，所以每2^32个字节，就会出现序列号回绕，再次从0开始。 确认序号(Ack)：表示发送确认的一端所期望收到的下一个序号，即希望发送方下次发送给自己的TCP报文段的序号的值是这个确认号。因此，确认序号应当是上次已成功收到数据字节序号加1。 首部长度：由于TCP首部包含一个长度可变的选项部分，所以需要这么一个值来指定这个TCP报文段到底有多长。 6个标志比特： ACK：表示前面的确认号字段是否有效。只有当ACK=1时，前面的确认序号字段才有效。TCP规定，连接建立后，ACK必须为1。 SYN：在建立连接时使用，用来同步序号。当SYN=1，ACK=0时，表示这是一个请求建立连接的报文段；当SYN=1，ACK=1时，表示对方同意建立连接。SYN=1，说明这是一个请求建立连接或同意建立连接的报文。只有在前两次握手中SYN才置为1。 FIN：发标记数据是否发送完毕。如果FIN=1，就相当于告诉对方我的数据已经发送完毕，你可以释放连接了。 RST：如果你收到一个RST=1的报文，说明你与主机的连接出现了严重错误（如主机崩溃），必须释放连接，然后再重新建立连接。或者说明你上次发送给主机的数据有问题，主机拒绝响应。 URG：表示本报文段中发送的数据是否包含紧急数据。后面的紧急指针字段只有当URG=1时才有效。 PSH：告诉对方收到该报文段后是否应该立即把数据推送给上层。如果为1，则表示对方应当立即把数据提交给上层，而不是缓存起来。 窗口大小(Win)：滑动窗口（缓存）大小，即允许对方发送的数据量。也就是告诉对方，从本报文段的确认号开始允许对方发送的数据量。 检验和：提供额外的可靠性。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段（希望发端超时并重发）。 紧急指针：一个正的偏移量，标记紧急数据在数据字段中的位置。 选项部分：其最大长度可根据TCP首部长度进行推算。TCP首部长度用4位表示，那么选项部分最长为：(2^4-1)*4-20=40字节。 应用层应用层负责处理特定的应用程序细节。 HTTP（超文本传输协议）：一种用于分布式、协作式和超媒体信息系统的应用层协议。一般使用80端口。 DNS（域名系统）：将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53。 FTP（文件传输协议）：用于在网络上进行文件传输的一套标准协议，使用客户/服务器模式。一般运行在20和21两个端口。端口20用于在客户端和服务器之间传输数据流，而端口21用于传输控制流，并且是命令通向ftp服务器的进口。 SSH（安全外壳协议）：通过在网络中创建安全隧道来实现SSH客户端与服务器之间的连接。一般监听22端口，用于远程登录。 SMTP（简单邮件传输协议）：一个相对简单的基于文本的协议。在其之上指定了一条消息的一个或多个接收者（在大多数情况下被确认是存在的），然后消息文本会被传输。一般使用25端口。 网络通信过程局域网内两台主机间的通信当一台主机把以太网数据帧发送到位于同一局域网上的另一台主机时，是根据48bit的以太网地址（MAC地址）来确定目的接口的。设备驱动程序从不检查IP数据报中的目的IP地址。 发送端IP层先查看主机的路由表，通过查找路由表（netstat -rn）选择一条路由，但是该路由的网关是On-link（在链路上）。On-link的意思是直接相连，不需要经过路由，可将数据包直接发送至目的地址。这时路由器将被当做交换机来使用。 由于可直接将数据包发送至目的地址不需要路由，这时需要查找目的IP地址对应的MAC地址，即查找ARP缓存表（arp -a）。 如果没有找到目的IP地址对应的表项，主机发送一条ARP广播（链路层）。交换机（路由器）收到ARP广播后，将主机的MAC地址写入自己的MAC地址表并转发给交换机上的各个接口（LAN口）。 目的主机收到ARP广播发现目的IP地址和本机IP地址相同就回复一条ARP应答，交换机（路由器）收到ARP应答将目的主机的MAC地址写入到自己的MAC地址表并转发给源主机。 发送端得到了目标主机的MAC地址，将ICMP包（ping包）发送出去，同时更新自己的ARP表，将目标主机的表项加入进去。 交换机（路由器）接收到发送端的ICMP包，并接其转发给目的主机。 公网中的两台主机间的通信 发送端IP层先查看主机的路由表，通过查找路由表选择一条路由，根据路由信息获取到了网关的IP地址。根据该IP地址查找自身ARP表，如果没有则会发出ARP广播包。如果有直接向目的端发送数据包。 路由器R1收到数据吧包并查到数据包的目的MAC地址为自己MAC地址，将包解封到IP层获取目的IP地址。 根据目的IP地址查询路由表：在路由表中查到最优匹配项，查找到下一跳接口IP地址并将数据包发送出去；如果没有最优匹配项，则按照默认路由发送，没有默认路由则丢弃数据包，并发送回应包，目的地址不可达。 路由器R2（连接公网的端口）接收到数据包，检验目的MAC地址和自己的MAC地址相等后接收并解封至IP层，查询路由表发现转发接口为自己连接局域网的端口且目的IP地址与转发接口在同一网段内，查找ARP表中目的IP的MAC地址得到目的主机的MAC地址。如果没有查到，则通过发送ARP广播包查询IP地址为的MAC地址。 路由器将封装好的数据包发送出去，目的主机接收到发送端发来的数据包，解封检验MAC地址为自己MAC地址，接收数据包并向原地址发送ICMP应答数据包，过程相似。 内网穿透网络地址转换 | P2P的实现 TCP协议保证可靠性的工作原理超时重传 应用数据被分割成TCP认为最合适的长度进行发送。由TCP传递给IP的信息单位称为报文段或段（segment）。 当TCP收到发自发送端的数据，它将回复一个确认。这个确认不是立即发送，通常将推迟几分之一秒。 当TCP发出一个报文段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段，即超时重传。 滑动窗口发送方在可以同时发送多个数据分组，即使用滑动窗口机制来发送数据。由于发送方不必每发一个分组就停下来等待确认，因此该可以加速数据的传输，提高网络吞吐量。同时为了保证包的顺序性，接收端可以先缓存提前到的数据，如果超过一定时间，等待的数据还没到达，则丢掉之前缓存的数据。当发送端和接受端传输速率不一致时就有可能发生缓冲区溢出，所以接收端返回的数据的TCP首部中会包含自己的接收窗口的大小来控制发送方的数据发送（流量控制）。 首先发送端发送A,B,C,D四个包，但是A,B丢失，只有C,D到达接收端。 接收端没有收到A，所以不回复ACK包。发送端重传A,B,C,D四个包，这次全都到达了。 接收端先获得A，发ACK包A，但是中途丢失；获得B后，根据累计确认的原则，发D的ACK包，然后窗口滑动。再次获得C,D后，连续回复2个D的ACK包，其中C对应的ACK包丢失。 发送端连收2个D的ACK包，说明4个包对方都已收到，窗口滑动，发E,F,G,H包，其中G包丢失。现在整个序列的状态：ABCD是已发送已确认，EFGH是已发送未确认，I~S是不能发送。 接收端先收到E，发ACK包；收到F后发F的ACK包；未收到G，还是发F的ACK包；收到H，还是发F的ACK包。不幸的是，三个ACK包全都丢失。 发送端收到E的ACK包，窗口向右滑动一位；然后再发送F,G,H,I，其中F丢失。 接收端获得I，因为没有G，只好回复F的ACK包。相继收到G,H包。 接收端根据累计确认，连发两个I包，其中H对应的丢失。窗口向右滑动。 发送端接收I的ACK包后，向右滑动四位。发送J,K,L,M四个包，后面不再分析。 拥塞窗口 流量控制只是简单地表明了接收方的处理能力，并不能代表中间网络的处理能力。如果一开始把滑动窗口内的数据全部发送出去，中间路由器可能一时处理不了如此多的突发流量导致拥塞（路由器因无法处理高速到达的流量而被迫丢弃数据信息的现象称为拥塞）。 TCP具备拥塞控制机制，即让每一个发送方感知到网络的拥塞程度来限制其能向连接发送流量的速率。 如果一个TCP发送方感知从它到目的地之间的路径上没有拥塞，则发送方增加其发送速率；如果发送方感知到该路径有阻塞，则降低其发送速率。 运行在发送方的TCP拥塞控制机制跟踪一个额外的变量，即拥塞窗口来限制其向其连接发送流量。 TCP拥塞控制算法：该算法包括三个部分，慢启动、拥塞避免和快速恢复。 TCP连接管理建立连接的三次握手 客户端发送一个（SYN=1,ACK=0,序号为x）的请求给服务器端。 服务器端回复一个（SYN=1,ACK=1,序号为y,确认序号为x+1）的请求给客户端。 客户端再次发送一个（SYN=0,ACK=1,确认序号为y+1）的请求给服务器端表示连接建立成功。 终止连接的四次挥手每一端都能主动关闭这个连接（即首先发送FIN）。然而，一般由客户端决定何时终止连接，因为客户进程通常由用户交互控制，用户会键入诸如quit一样的命令来终止进程，所以第一个SYN一般是从客户传到服务器。 主动关闭方发送一个（FIN=1,序号为x）的请求给被动关闭方。 被动关闭方回复一个（FIN=0,确认序号为x+1）的请求给主动关闭方。此时主动关闭方处于半关闭状态，即它还能接收来自另一端数据并回复确认信息。 被动关闭方发送一个（FIN=1,序号为y）的请求给主动关闭方。 主动关闭方回复一个（FIN=0,确认序号为y+1）的请求给被动关闭方。连接彻底关闭。 为什么建立连接协议是三次握手，而关闭连接却是四次握手？服务端的LISTEN状态下的SOCKET当收到SYN报文的连接请求后，它可以把ACK和SYN(ACK起应答作用，而SYN起同步作用)放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可能未必会马上会关闭SOCKET,即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以这里的ACK报文和FIN报文多数情况下都是分开发送的。 TCP状态转换 CLOSED：一个假想的起点和终点，不是一个实际的状态。 LISTEN：监听状态，服务器正在等待连接进入。 SYN_SENT：在客户端发送第一个同步报文段（第一次握手）之后的状态，等待服务器端确认。如果服务器端不能连接，则直接进入CLOSED状态。 SYN_RCVD：服务器向客户端发送了确认同步报文段（第二次握手）之后的状态。 ESTABLISHED：在收到服务端发送的确认和同步报文段（第二次握手）后，客户端只需要发送出一个确认报文段（第三次握手）就进入该状态；收到客户端发来的确认报文段（第三次握手）后服务器端也进入该状态。 FIN_WAIT_1：主动关闭方发出第一个FIN报文段（第一次挥手）后进入该状态。 CLOSE_WAIT：被动关闭方接收到主动方发送的FIN报文，并发送了返回的ACK（第二次挥手）后进入该状态。 FIN_WAIT_2：主动关闭接收到被动方返回的ACK（第二次挥手）后进入该状态。 LAST_ACK：被动方发送FIN给对方（第三次挥手）后进入该状态。 TIME_WAIT：主动方最后回应一个ACK（第四次挥手）后进入该状态。 TIME_WAIT状态主动关闭的一端会在最后回应一个ACK后进入该状态，并在该状态停留的持续时间是最长分节生命期的两倍。最长分节生命期(MSL)指任何IP数据报能再因特网上存活的最长时间。之所以要有该状态是因为以下两个理由： 可靠地实现TCP全双工连接的终止。如果最终的ACK丢失了，服务器将重新发送它的最终那个FIN，因此客户必须维护状态信息，以允许它重新发送最终那个ACK。要是客户不维护状态信息，它将响应以一个RST（另外一种类型的TCP分节），该分节将被服务器解释成一个错误。 允许老的重复分节在网络中消逝。关闭一个连接后，过一段时间在相同的IP地址和端口之间建立另一个连接。后一个连接称为前一个连接的化身因为它们的IP地址和端口号都相同。TCP必须防止来自某个连接的老的重复分组在该连接已终止后再现，从而被误解成属于同一连接的某个新的化身。 TCP拆包和粘包TCP协议是基于字节流传输的。应用层传递的是大小不等的数据块，但是TCP并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包的划分，所以在业务上认为，一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送。这就需要拆包和粘包。 拆包粘包的四种解决方案 消息长度固定，例如每120个字节代表一个整包消息，不足的前面补位。解码器在处理这类定常消息的时候比较简单，每次读到指定长度的字节后再进行解码。 回车换行符作为结束符，在文本协议中应用比较广泛。HTTP协议头使用这种方式。 将特殊的分隔符作为消息的结束标志，回车换行符就是一种特殊的结束分隔符。 通过在协议头/消息头中设置长度字段来标识整包消息。例如HTTP协议就是在协议头中设定了body的长度。 Netty针对上述四种方案都提供了对应的解码器 通过FixedLengthFrameDecoder定长解码器来解决定长消息的黏包问题。 通过LineBasedFrameDecoder和StringDecoder来解决以回车换行符作为消息结束符的TCP黏包的问题。 通过DelimiterBasedFrameDecoder特殊分隔符解码器来解决以特殊符号作为消息结束符的TCP黏包问题。 通过LengthFieldBasedFrameDecoder和LengthFieldPrepender自定义长度解码器解决TCP黏包问题。","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"操作系统","slug":"基础之操作系统","date":"2018-09-07T23:53:07.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2018/09/08/基础之操作系统/","link":"","permalink":"http://yoursite.com/2018/09/08/基础之操作系统/","excerpt":"操作系统的引导 开机时，CS=0xFFFF IP=0x0000，所以会跳转到固化在内存中的基本输入输出系统(BIOS)； BIOS从引导扇区(0磁道0扇区)读取bootsect.s(512k)到内存中。 bootsect.s将操作系统读到内存中。1. 读入setup；2. 在屏幕上打出logo；3. 调用13号中断读取操作系统后面的system部分。 setup完成操作系统启动前的初始化，获取硬件信息如内存的大小等。 setup进入保护模式，然后跳转到system模块的head.s中。 head.s再次初始化GDT表等，然后调用main函数(汇编调用C函数)。 main函数初始化页表等资源，然后阻塞。","text":"操作系统的引导 开机时，CS=0xFFFF IP=0x0000，所以会跳转到固化在内存中的基本输入输出系统(BIOS)； BIOS从引导扇区(0磁道0扇区)读取bootsect.s(512k)到内存中。 bootsect.s将操作系统读到内存中。1. 读入setup；2. 在屏幕上打出logo；3. 调用13号中断读取操作系统后面的system部分。 setup完成操作系统启动前的初始化，获取硬件信息如内存的大小等。 setup进入保护模式，然后跳转到system模块的head.s中。 head.s再次初始化GDT表等，然后调用main函数(汇编调用C函数)。 main函数初始化页表等资源，然后阻塞。 操作系统的一些基本概念 实模式寻址：CS（段寄存器）左移4位（乘16） + IP（段内偏移）。 保护模式寻址：根据CS的值从GDT表中查出基址 + IP。 用户态和内核态，硬件保证了用户态不能访问操作系统所在的内存(内核段)，所以程序运行的状态应该是用户态，即不具备访问操作系统内核的权限，如果需要使用操作系统内核，可以调用系统提供的API，即陷入内核。 CPL代表当前进程可以访问的内存的特权级，由CS寄存器的最低2位表示。0代表看看呀访问内核态、3代表只能访问用户态。 DPL存放在GDT表中，用来描述目标内存段的特权级。 全局描述符表(GDT)：保护模式所必须的数据结构，存放了段的起始地址、界限、属性等内容。 冯洛伊曼体系结构 CPUCPU（中央处理器）主要负责解释计算机指令以及处理计算机软件中的数据。CPU主要包含两个基本部分：数据通路和控制器。 数据通路：主要用来执行算术逻辑和逻辑运算以及寄存器和存储器的读写控制等。 算术逻辑单元（ALU）：责执行计算机中所有底层的算术操作和逻辑操作。ALU中最基本的部件是加法器，所有的算术运算都可以基于加法运算和逻辑运算来实现。 控制器：用来对指令进行译码，生成相应的控制信号，以控制数据通路进行正确的操作。控制器还负责决定下一步需要取出和执行哪一条指令。 存储器 - 分为内存和外存 内存包括主存储器和高速缓冲存储器。内存由半导体存储器芯片组成，芯片有多种类型： 随机存取存储器(RAM)： 包括静态存储器(SRAM)，由六个晶体管构成，一般用作高速缓存；动态存储器(DRAM)，由单个晶体管组成，可以大规模集成，一般用作主存。 只读存储器(ROM)：又称为闪存，不可以更改写入的内容，一般用作基本输入输出系统(BIOS)。 外存包括辅助存储器和海量后备存储器，通常把系统运行时直接和主存交换信息的存储器称为辅助存储器，目前主要的辅存是磁盘存储器和固态硬盘；而磁带和光盘存储器的容量大、速度慢，主要用于信息的备份和脱机存档，因此被用作海量后备存储器。 存储器层次结构寄存器 –&gt; 高速缓存(SRAM) –&gt; 主存(DRAM) –&gt; 本地磁盘 –&gt; 分布式文件系统、web服务器等。 局部性：一个编写良好的计算机程序倾向于引用邻近于其它最近引用过的数据项的数据项，或者最近引用过的数据项本身。 时间局部性：被引用过一次的内存位置很可能在不远的将来再被多次引用。 空间局部性：一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。 强制性缓存不命中：缓存为空的时候，对任何对象都会不命中。 冲突缓存不命中：为了更容易定位缓存中的数据，一般会将第k+1层的某个快限制放置在第k层的一个小的子集中。例如，第k+1层的快0、4、8、12会映射到第k层的块0；块1、5、9、13会映射到块1；以此类推。因此，虽然缓存足够大，能够保持被引用的数据对象，但是因为这些对象会映射到同一个缓存块，缓存会一直不命中。 缓存容量不命中：即缓存太小了。 高速缓存行、组、快 块：一个固定大小的信息包，在高速缓存和主存之间来回传送。 行：高速缓存中的一个容器，存储块以及其他信息(例如有效位和标记位)。 组：一个或多个行的集合。直接映射高速缓存中的组只由一行组成。组相连和全相连高速缓存中的组是由多个行组成。 外部设备简称外设，也称为I/O设备。外设通常由机械部分和电子设备部分组成，并且两部分通常是可以分开的。机械部分是即外部设备本身，而电子部分则是控制外部设备工作的I/O控制器或I/O适配器。 I/O映像：创建I/O设备的二进制仿真，使其对于CPU而言，看上去就像普通的内存段，屏蔽到不同输入输出设备的差异。 总线总线是传输信息的介质，用于在部件之间传输信息，CPU、主存和I/O模块通过总线互联。 地址总线：CPU通过地址总线指定存储单元，地址总线的宽度决定了存储器的大小。 数据总线：负责CPU和内存或其他器件之间的数据传输，数据总线的宽度决定了CPU和外界的数据传输速度。 控制总线：负责CPU对外部器件的控制，控制总线的宽度决定了CPU可以对外部器件提供的控制数。 内部总线：负责连接CPU内部各个器件进。 进程管理一个正在执行的程序称为一个进程，它包括程序计数器、寄存器和变量的当前值。进程管理部件的最主要任务是进程的创建和终止。它还包括一个进程调度器，负责选择下一步运行哪个进程或线程。 进程的切换 = 指令序列的切换 + 资源的变更 线程的切换 = 指令序列的切换：即多个线程使用同一片虚拟内存 用户态线程切换：整个过程类似于函数调用，只是切换了不同的栈，即每个进程都有一个自己的栈，并将栈信息保存在TCB中，切换时调用Yield函数根据TCP中的值修改esp寄存器的值就行。用户态线程切换无法使用到多核和多处理器。 内核态线程切换：需要切换一套栈，一套栈包括一个内核栈和一个用户栈。 进程挂起一个进程暂时被这样挂起后，在随后的某个时刻里，该进程再次启动时的状态必须与先前暂停时完全相同，这就意味着在挂起时该进程的所有信息都要保存下来。例如，为了同时读入信息，进程打开了若干文件。同每个被打开文件有关的是指向当前位置的指针（即下一个将读出的字节或记录）。在一个进程暂时被挂起时，所有这些指针都必须保存起来，这样在该进程重新启动之后，所执行的读调用才能读到正确的数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为进程表（process table），进程表是数组（或链表）结构，当前存在的每个进程都要占用其中一项。 进程的资源集操作系统维护了一张进程i表，表中包含了寄存器（含有程序计数器和堆栈指针）、打开的文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。 PCB和TCB 进程控制块(PCB)：操作系统为了管理进程设置的一个专门的数据结构。主要保存了： 进程状态：可以使new、ready、running、waiting或halted等。 程序计数器：接着要运行的指令地址。 CPU寄存器：如累加器、索引寄存器（Index Register）、堆栈指针以及一般用途寄存器、状况代码等，主要用途在于中断时暂时存储数据，以便稍后继续利用；其数量及类因计算机架构有所差异。 CPU排班法：优先级、排班队列等指针以及其他参数。 存储器管理：如分页表（Page Table）等。 会计信息：如CPU与实际时间之使用数量、时限、帐号、工作或进程号码。 输入输出状态：配置进程使用I/O设备，如磁带机。 线程控制块(TCB)：与进程的控制块相似的子控制块。 多处理器和多核 多处理器指多个独立的CPU，每个CPU都有较为独立的电路支持，有自己的Cache，有自己的MMU，而它们之间通过总线进行通信。在这个架构上跑多线程程序（常见的典型情况），不考虑超线程，那么每一个线程都要跑在一个独立的CPU上，线程间的所有写作都要走总线，而共享的数据可能在好几个Cache中同时存在。 多核单CPU只需要一套芯片组、一套存储，多核之间通过芯片内部总线进行通信，共享使用内存。 内存管理单元(MMU)：CPU用来管理虚拟存储器、物理存储器的控制线路，同时也负责将虚拟地址映射为物理地址，以及提供硬件机制的内存访问授权。 线程的实现方法 在用户空间中实现线程，对于内核来说直接按正常的方式进行管理，即单线程进程。 优点： 跨平台，即用户级线程包可以在不支持线程的操作系统上实现。 轻量级，不需要陷入内核，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。 允许每个进程有自己定制的调度算法。 缺点：无法使用内核提供的如阻塞等基本功能，即当某个线程调用和阻塞方法时可能导致该进程中所有的线程阻塞。 在内核中实现线程，由内核来完成线程切换，内核通过操纵调度器对线程进行调度。可以使用内核提供的各种功能，但是创建代价比较大。 混合实现：试图将用户级线程的优点和内核级线程的优点结合起来的方法。 内存管理存储管理任务包括维护虚拟内存到物理内存的映射，维护最近被访问页面的缓存以及实现一个好的页面置换算法，并且根据需要把需要的数据和代码页读入到内存中。操作系统在内存中寻找一块空闲的内存空间，将这一段内存的基地址放入PCB中，将程序载入进去，然后进行内存重定位。 内存重定位程序中的地址都是逻辑地址，即一般都是从0地址开始，实际运行时需要将其翻译成物理地址，即在内存中的实际地址。可以在编译、载入或运行时进行重定位，PC机一般是运行时重定位。 编译时重定位的程序只能放在内存中固定位置，所以效率高，一般嵌入式设备使用这种方式。 载入时重定位的程序一旦载入到内存中就不能再移动了。 运行时重定位的程序可以在运行时进行交换，即将长时间阻塞的进程换出，腾出内存空间。运行时重定位的物理内存 = 基地址(放在PCB中) + 逻辑地址。 内存分段程序一般分为不同的段（程序段、数据段、堆栈段等），每个段分别找到空闲的内存，将该内存的基地址存入段表，然后将该段程序裁人内存。所以程序的地址 = 段地址 + 段内偏移。而PCB中存储的也不在是基地址，而是段表（LDT表），GDT表就是类似操作系统对应的段表。 内存分页（如何在内存中找到一块空闲的区域）将物理内存分成大小相同的页，这样不会因为内存不断的划分出现内存碎片问题。但是需要在内存中维护一个页表。该表由MMU维护。 虚拟内存虚拟内存是计算机系统内存管理的一种技术。它使得程序认为自己拥有连续可用的内存（一个连续完整的地址空间）。而实际上，它通常被分隔成多个物理内存碎片（分页、分段），还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。具体实现就是将磁盘划出一部分来当做内存使用，当虚拟内存空间中实际用到的内存大于物理内存时就可能发生缺页，这时候就需要将一部分内存换出到磁盘上，同时将缺页部分换入到内存中。 内存换入：把准备好竞争CPU运行的程序从辅存移到内存。 内存换出：把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到侧畔，把内存空间腾出来。 文件系统在Linux操作系统中，所有的I/O设备（例如网络、磁盘和终端）都被模型化为文件，而所有的输入和输出都被当做对相应文件的读和写来执行。 文件操作过程 打开文件：一个应用程序通过要求内核打开相应的文件，来宣告它要访问一个I/O设备。内核返回一个称为描述符的小的非负整数，它在后续对此文件的所有操作中标识这个文件。 Linux shell创建的每个进程开始时都打开了三个文件：标志输入（描述符为0）、标志输出（描述符为1）和标志称为（描述符为2）。 改变当前的文件位置：对于每个打开的文件，内核保持一个文件位置k，初始值为0。这个文件位置是从文件开头起始的字节偏移量。应用程序可以通过执行seek操作，显示的设置当前位置为k。 读写文件：一个读操作就是从文件复制n&gt;0个字节到内存，从当前文件位置k开始，然后将k增加为k+n。给定一个大小为m字节的文件，当k大于等于m时执行读操作会触发一个end-of-file（EOF）的条件，应用程序能检测到这个条件。在文件结尾并没有明确的EOF符号。 关闭文件：当应用完成对文件的访问后，就通知内核关闭这个文件。作为响应，内核释放文件打开的创建的数据结构，并将这个描述符恢复到可用的描述符池中。无论一个进程因为何种原因终止时，内核都会关闭所有打开的文件并释放它们的内存资源。 文件在内核中的表示 描述符表：每个进程都有它独立的描述符表，它的表项由进程打开的文件描述符来索引。每个打开的文件描述符表项指向文件表中的一个表项。 文件表：打开文件的集合是由一张文件表来表示的，所有的进程共享这张表。每个文件表的表项由当前的文件位置、引用计数（即当前指向该表项的描述符表项数），以及一个指向v-node表中对应表项的指针。关闭一个描述符会减少相应的文件表表项中的引用计数。内核不会删除这个文件表的表项，直到他的引用计数为零。 v-node表：同文件表一样，所有进程共享这张表。每个表项包含stat结构中的大多数信息，包括st_mode和st_size。","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"Linux使用","slug":"其它之Linux使用","date":"2018-08-18T12:02:41.000Z","updated":"2022-09-25T03:56:26.526Z","comments":true,"path":"2018/08/18/其它之Linux使用/","link":"","permalink":"http://yoursite.com/2018/08/18/其它之Linux使用/","excerpt":"CentOS7配置网络 | Vim使用教程 | Make命令教程 | Diff命令教程","text":"CentOS7配置网络 | Vim使用教程 | Make命令教程 | Diff命令教程 Linux文件文件种类 正规文件：一般用来进行存取的文件，ls -al显示的第一个字符为[-]。 文本文件（ASCII）：人类可以直接阅读的数据。 二进制文件（binary）：可执行文件，.o文件等。 数据格式文件（data）：有些程序在运行时会读取某些特定格式的文件，例如Linux用户在登录时，都会将登录的数据记录在/var/log/wtmp文件中，该文件就是数据格式文件。 目录：第一个字符属性为[d]。 设备文件（device）：I/O设备及存储相关的一些文件，通常集中在/dev目录中。 区块（block）设备文件：随机存储设备，如硬盘（/var/sda）等。第一个字符属性为[b]。 字符（character）设备文件：即一次性读取，不能截断输出的设备，如键盘、鼠标等。第一个字符属性为[c]。 数据结构文件（sockets）：承接网络上的数据。第一个字符属性为[s]，/run和/tem目录中可以看到该类型文件。 数据输送文件（FIFO，pipo）：存在的主要目的是为了解决多个程序同时存取一个文件所造成的错误问题。第一个字符属性为[p]。 连接文件：类似Windows系统中的快捷方式。第一个字符属性为[l]。常用的日志文件 /var/log/messages或者 /var/log/syslog文件：记录了系统错误信息、系统的启动和关闭、网络配置修改等信息。可以用来排查进程为什么被系统杀死。 dmesg命令：用于查看ring buffer中的信息，ring buffer中存储了类似于设备驱动的初始化信息等。可以用于启动过程中故障排除。 turbostat命令：用于统计处理器的频率、空闲状态、电源状态、温度等状态。 各目录的作用 根目录(/)：所有的目录都是由根目录衍生出来的，同时根目录也与开机、还原、系统修复等动作有关。 /bin目录：放置在单人维护模式下还能被操作的指令。 /boot目录：放置开机会使用文件，包括Linux核心文件以及开机菜单与开机所需配置文件等。 /dev目录：在Linux系统中，任何设备都是以文件的形态存在于这个目录中。 /etc目录：系统中主要的配置文件几乎都放置在这个目录中，例如人员的账号密码、各种服务的启动配置等。 /lib目录：放置开机时会用到的函数库和/bin或/sbin目录下面的指令会调用的函数库。 /media目录：放置可移除的设备。包括软盘、光盘、DVD等。 /mnt目录：一般用来暂时挂载某些额外的设备。 /opt目录：第三方软件安装目录，也可以用来当做用户软件安装目录，不过一般用户软件还是会安装到/usr/local目录中。 /run目录：FHS 规定系统开机后所产生的各项信息应该要放置到该目录。 /srv目录：作为一些网络服务启动后需要取用的数据的目录。 /tmp目录：一般使用者或者正在执行的程序暂时存放文件的地方。这个目录是任何人都能够存取的，所以需要定期的清理一下。 /usr目录：其下的目录结构和根目录相似，但根目录中的文件多是系统级的文件，而/usr中是用户级的文件，一般与具体的系统无关。 /var目录：包括了一些数据文件，如系统日志等。/var的存放使得/usr被只读挂载成为可能。 /home目录：系统默认的使用者主文件夹。 /root目录：系统管理员（root）的主文件夹。 /lost+found：使用标准的ext2/ext3/ext4文件系统格式才会产生的一个目录，目的在于当文件系统发生错误时，将一些遗失的片段放置到这个目录下。 /proc：这个目录本身是一个虚拟文件系统（virtual filesystem），他放置的数据都是在内存当中，例如系统核心、行程信息（process）、周边设备的状态及网络状态等等。不占硬盘容量。 /sys：这个目录其实跟/proc非常类似，也是一个虚拟的文件系统，主要也是记录核心与系统硬件信息较相关的信息。包括目前已载入的核心模块与核心侦测到的硬件设备信息等等。同样不占硬盘容量。 Linux操作命令 pwd：显示当前目录。 file：查看文件所属的类型。 sync：将内存中尚未被写回到硬盘的数据写回硬盘。 screen：打开一个子界面；在子界面按Ctrl+a+d退出子界面；screen -ls会显示所有的子界面；screen -r id可以进入子界面。 source 配置文件名：使修改的配置文件不需要重新登录立即生效。 tar -cf 压缩文件 被压缩的文件夹；tar -xf 压缩文件。 nohup command &gt; myout.file 2&gt;&amp;1 &amp;：将command后台运行并将输出重定向到myout.file文件。 ln -s 源文件 目标文件：创建一个软连接，一般在/usr/local/bin目录中创建一个连接到其它命令的软连接。 gnome-screensaver-command -l：锁屏。 iostat -d 1：每秒打印一下磁盘的访问信息。 iftop -i eth0 -n：实时查看网卡eth0的流量信息。 ps -p 3224 etime/lstart：列出3224进程的运行时间/开始时间。 系统问题排查 内存不够导致进程被kill可以查看/var/log/messages文件，如果出现 kernel: Out of memory: Kill process意味着整个系统的内存已经不足，如果不杀死进程的话，就会导致系统的崩溃。 日志操作命令 动态打印后200条日志：tail -fn 200 log/ladybird-web-1.0.log 根据关键字过滤日志：cat -n log/ladybird-web-1.0.log | grep “key” 根据日期过滤日志：sed -n ‘/2020-04-22 11:30:00/,/2020-04-22 11:33:00/p’ log/ladybird-web-1.0.log 查询开始时间到当前时间日志：sed -n ‘/2020-04-22 11:40:00/,$p’ log/ladybird-web-1.0.log 查找命令 whereis [-bmsu] 文件或目录名：在一些特定的目录中寻找文件。如/bin/sbin和/usr/share/man等目录。 locate -i / config：忽略大小写查询根目录中文件路径包括config的文件。 find：强大的文件查找命令。find ~/nginx/ -name “nginx.c”代表在工作目录下的nginx目录查找nginx.c。find ~/nginx/ -iname “*.C”代表忽略大小写的通配符查找。 查看磁盘命令 du –max-depth=1 -h：查看当前目录下各文件和文件夹大小。 du -sh *：当前目录各文件和文件夹大小 df -h：列出文件系统的整体磁盘使用量。 lsblk：列出系统上的所有磁盘列表。 blkid：列出磁盘的UUID等参数。 parted：列出磁盘的分区表类型与分区信息。 进程管理命令 Ctrl + z：将当前任务丢到背景中暂停。 jobs：观察目前背景中的任务状态。 fg jobnum：将背景中任务拿到前台来处理。 bg jobnum：让任务在背景下接着运行。 kill -9 %jobnum：杀死一个背景任务。-9代表立刻强制删除一个工作；-15代表以正常的程序方式终止一项工作。 ps -aux：列出所有系统运行的进程；ps -l则是列出自己bash下的进程。 pstree：以进程树的方式列出进程。 top：监视系统中不同的进程所使用的资源。它提供实时的系统状态信息。 fusre和lsof：查看某个文件被哪些进程使用。 文件管理 chgrp -R fengbo practice：改变文件所属的群组。 chown -R fengbo practice：改变文件的所有者。 chmod -R 741 practice：改变文件的权限。 lsof：查看当前系统打开的文件。 Vim命令 c2l：删除后面两字符，并进入输入模式. c2w：删除后面两个词，并进入输入模式。 dl：删除当前元素，相当于x命令。 d2l：删除当前元素和当前元素后面的一个元素；dj删除光标所在行。 Ctrl + r：重做。 文件切换 :ls 显示所有打开的文件。 :bn：切换到下一个文件，bn2则是切换到下两个文件。 :bp：切换到上一个文件。 窗口分割 :sp filename：上下分割，并打开一个新的文件。 :vsp filename：左右分割，并打开一个新的文件。 Ctrl + w + w：切换到下一个窗口。 Ctrl + w + h：切换到左边的窗口。 代码折叠 za：打开或关闭当前折叠。 zm：关闭所有折叠。 zr：打开所有折叠。 编辑二进制文件 使用vi -b filename打开文件。 输入:%!xxd将其转换为十六进制显示。 使用:%!xxd -r在编辑完成后将其转换回去。 替换命令 :s/vivian/sky/：替换当前行第一个vivian为sky。 :s/vivian/sky/g：替换当前行所有vivian为sky。 :n,$s/vivian/sky/：替换第n行开始到最后一行中每一行的第一个vivian为sky。 :n,$s/vivian/sky/g：替换第n行开始到最后一行中每一行所有vivian为sky。n为数字，若n为.，表示从当前行开始到最后一行。 :%s/vivian/sky/：替换每一行的第一个vivian为sky。 :%s/vivian/sky/g：替换每一行中所有vivian为sky。 网络管理基础命令 route -n：查看本机的路由表。 traceroute -n www.baidu.com：检查本机到百度所经过的各个路由器。traceroute -nT www.baidu.com通过TCP来检测。 netstat -nlpt：查看监听的端口服务。 netstat -nta | grep 100 | wc -l：查看100端口的连接数。 netstat -nt 2&gt;/dev/null | grep :100 | grep “ESTABLISHED” | awk ‘{print $5}’ | cut -d: -f 4 | sort | uniq -c | sort -nr | head nmap localhost：扫瞄本机所启用的端口；nmap -sTU localhost会同时扫描UDP端口；nmap -sP 192.168.1.0/24会分析内网中有几台主机是启动的；yum install nmap安装nmap。 vi /etc/sysconfig/iptables：修改防火墙出站及入站规则。 TCPDUMP抓包 tcpdump tcp -i eth2.2 -s 0 and dst port ! 22 and src net ! 118.31.167.239 -w /mnt/sda1/target.cap System入门教程systemctl命令service和systemctl service命令会去启动/etc/init.d/目录的脚本。 systemctl是用于替换service命令的，默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/或者/lib/systemd/system/。systemctl常用命令12345678910111213141516# 重启系统systemctl reboot# 关闭系统，切断电源systemctl poweroff# CPU停止工作systemctl halt# 暂停系统systemctl suspend# 让系统进入冬眠状态systemctl hibernate# 让系统进入交互式休眠状态systemctl hybrid-sleep# 启动进入救援状态（单用户状态）systemctl rescue# 列出所有服务（包括启用和禁用）systemctl list-unit-files --type=service Unit File类型Systemd 将系统资源划分为12类，对应12种类型的单元文件。 系统资源类型 单元文件扩展名 单元文件描述 Service .service 封装守护进程的启动、停止、重启和重载操作，是最常见的一种 Unit 文件 Target .target 定义 target 信息及依赖关系，一般仅包含 Unit 段 Device .device 对于 /dev 目录下的硬件设备，主要用于定义设备之间的依赖关系 Mount .mount 定义文件系统的挂载点，可以替代过去的 /etc/fstab 配置文件 Automount .automount 用于控制自动挂载文件系统，相当于 SysV-init 的 autofs 服务 Path .path 用于监控指定目录或文件的变化，并触发其它 Unit 运行 Scope .scope 这种 Unit 文件不是用户创建的，而是 Systemd 运行时产生的，描述一些系统服务的分组信息 Slice .slice 用于表示一个 CGroup 的树 Snapshot .snapshot 用于表示一个由 systemctl snapshot 命令创建的 Systemd Units 运行状态快照，可以切回某个快照 Socket .socket 监控来自于系统或网络的数据消息 Swap .swap 定义一个用户做虚拟内存的交换分区 Timer .timer 用于配置在特定时间触发的任务，替代了 Crontab 的功能 语法Unit 文件可以分为三个配置区段： Unit 段：所有Unit文件通用，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系 Description：当前服务的简单描述 Documentation：文档地址，可以是一个或多个文档的URL路径。【依赖关系】只涉及依赖关系，默认情况下两个Unit同时启动。 Requires：与其它Unit的强依赖关系，如果其中任意一个Unit启动失败或异常退出，当前Unit也会被退出。 Wants：与其它Unit的弱依赖关系，如果其中任意一个Unit启动失败或异常退出，不影响当前Unit继续执行。 Binds To：与Requires相似，该字段指定的Unit如果退出，会导致当前Unit停止运行。 Part Of：一个Bind To作用的子集，仅在列出的Unit失败或重启时，终止或重启当前Unit，而不会随列出Unit的启动而启动。【启动顺序】只涉及启动顺序，不影响启动结果和运行情况 After：该字段指定的Unit全部启动完成以后，才会启动当前Unit。 Before：该字段指定的Unit必须在当前Unit启动完成之后再启动。 Install 段：所有Unit文件通用，用来定义如何启动，以及是否开机启动。 WantedBy：它的值是一个或多个target，执行enable命令时，符号链接会放入/etc/systemd/system目录下以 target 名+.wants后缀构成的子目录中。 RequiredBy：它的值是一个或多个target，执行enable命令时，符号链接会放入/etc/systemd/system目录下以target名+.required后缀构成的子目录中。 Alias：当前Unit可用于启动的别名。 Also：当前Unit被 enable/disable 时，会被同时操作的其他Unit。 Service 段：服务（Service）类型的Unit文件（后缀为 .service）特有的，用于定义服务的具体管理和执行动作。所有的启动设置之前，都可以加上一个连词号（-），表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如，ExecStart=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误。 Type：定义启动时的进程行为。 Type=simple：默认值，ExecStart字段启动的进程为主进程，服务进程不会fork，如果该服务要启动其他服务，不要使用此类型启动，除非该服务是socket激活型。 Type=forking：ExecStart字段将以fork()方式从父进程创建子进程启动，创建后父进程会立即退出，子进程成为主进程。通常需要指定PIDFile字段，以便Systemd能够跟踪服务的主进程。对于常规的守护进程（daemon），除非你确定此启动方式无法满足需求，使用此类型启动即可。 Type=oneshot：只执行一次，Systemd会等当前服务退出，再继续往下执行。适用于只执行一项任务、随后立即退出的服务。通常需要指定RemainAfterExit=yes字段，使得Systemd在服务进程退出之后仍然认为服务处于激活状态。 Type=dbus：当前服务通过D-Bus信号启动。当指定的BusName出现在DBus系统总线上时，Systemd认为服务就绪。 Type=notify：当前服务启动完毕会发出通知信号，通知Systemd，然后Systemd再启动其他服务。 Type=idle：Systemd会等到其他任务都执行完，才会启动该服务。一种使用场合是：让该服务的输出，不与其他服务的输出相混合 ExecStart：启动当前服务的命令。 ExecStartPre：启动当前服务之前执行的命令。 ExecStartPost：启动当前服务之后执行的命令。 ExecReload：重启当前服务时执行的命令。 ExecStop：停止当前服务时执行的命令。 ExecStopPost：停止当前服务之后执行的命令。 RemainAfterExit：当前服务的所有进程都退出的时候，Systemd仍认为该服务是激活状态。这个配置主要是提供给一些并非常驻内存，而是启动注册后立即退出，然后等待消息按需启动的特殊类型服务使用的。 TimeoutSec：定义Systemd停止当前服务之前等待的秒数。 RestartSec：Systemd重启当前服务间隔的秒数。 KillMode：定义Systemd如何停止服务，可能的值包括： control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉。 process：只杀主进程（sshd服务，推荐值）。 mixed：主进程将收到SIGTERM信号，子进程收到SIGKILL信号。 none：没有进程会被杀掉，只是执行服务的stop命令。 Restart：定义何种情况 Systemd 会自动重启当前服务，可能的值包括： no（默认值）：退出后不会重启。 on-success：只有正常退出时（退出状态码为0），才会重启。 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启（守护进程，推荐值）。 on-abnormal：只有被信号终止和超时，才会重启（对于允许发生错误退出的服务，推荐值）。 on-abort：只有在收到没有捕捉到的信号终止时，才会重启。 on-watchdog：超时退出，才会重启。 always：不管是什么退出原因，总是重启。 PIDFile：指向当前服务PID file的绝对路径。 User：指定运行服务的用户。 Group：指定运行服务的用户组。 EnvironmentFile：指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"HashMap原理分析","slug":"Java高级特性之HashMap原理分析","date":"2018-08-11T01:34:51.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/08/11/Java高级特性之HashMap原理分析/","link":"","permalink":"http://yoursite.com/2018/08/11/Java高级特性之HashMap原理分析/","excerpt":"JDK7中的HashMapHashMap底层维护了一个数组，数组的每一项都是一个Entry。transient Entry&lt;K,V&gt;[] table;","text":"JDK7中的HashMapHashMap底层维护了一个数组，数组的每一项都是一个Entry。transient Entry&lt;K,V&gt;[] table; HashMap中的key、value就存放在Entry中。static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; Entry&lt;K,V&gt; next; int hash; 而具体某个Entry应该存放在数组的哪个位置是通过key的hashCode来计算的。final int hash(Object k) { int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); } 通过hash计算出来的值将会使用indexFor方法找到它应该所在的table下标，即对table.length取模。static int indexFor(int h, int length) { return h &amp; (length-1); } 当两个key通过hashCode方法计算的结果相同时，称之为发生了hash冲突，HashMap解决hash冲突的方法是使用链表。即发生冲突时先使用equals方法判断key是否相等，如果相等则替换掉之前的value。public V put(K key, V value) { if (table == EMPTY_TABLE) { inflateTable(threshold); } if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null; } 如果不相等，则使用头插法将新Entry插入到table中，并将next指向该位置以前存在的那个对象。void addEntry(int hash, K key, V value, int bucketIndex) { // 扩容条件 threshold = (int)(capacity * loadFactor) if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); } 当hash冲突很多时，HashMap就退化成了链表。而随着元素数量的增多，hash冲突必然增多，所以当集合中的对象数大于当前容量 * 加载因子时，容器将自动扩容并重新hash。在JDK7中，只有当size &gt;= threshold并且table中的那个槽中已经有Entry时，才会发生resize。void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } 首先对数组中的元素进行遍历，然后遍历每一个节点，使用头插法将元素转移到新的Hash表。可以看出转移是逆序的，所以这个地方在多个线程同时操作时可能会出现循环引用。void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } } JDK8中的HashMapJDK7中HashMap采用的是位桶+链表方式，即散列链表的方式，而JDK8中采用的是位桶+链表/红黑树的方式，也是非线程安全的。当某个位桶的链表长度达到某个阀值时，这个链表就将转换成红黑树。 Entry的名字变成了Node，原因是和红黑树的实现TreeNode相关联。transient Node&lt;K,V&gt;[] table; 当冲突节点数不小于8-1时，转换成红黑树。static final int TREEIFY_THRESHOLD = 8; JDK8的put()方法。public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果当前map中无数据，执行resize方法，并且返回n。 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果要插入的键值对要存放的这个位置刚好没有元素，那么把他封装成Node对象，放在这个位置上。 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 否则的话，说明桶上面有元素。 else { Node&lt;K,V&gt; e; K k; // 如果这个元素的key与要插入的一样，那么就替换掉它。 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果当前节点是TreeNode类型的数据，执行putTreeVal方法。 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { // 还是遍历链表上的数据，跟jdk7没什么区别。 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 完成了操作后多做了一件事情，判断，并且可能执行treeifyBin方法。 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 将链表转换成红黑树。 treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 判断阈值，决定是否扩容。 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } JDK8的resize()方法。将原来该位置上的链表拆成了2个链表，因为扩容为原来数组的两倍，所以拆完之后在分别放到原索引位置和原索引+原集合长度的位置上。解决了循环引用问题。final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 其它Map实现类LinkedHashMapHashMap的直接子类，二者唯一的区别是LinkedHashMap在HashMap的基础上，采用双向链表的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同。迭代LinkedHashMap时不需要像HashMap那样遍历整个table，而只需要直接遍历header指向的双向链表即可，也就是说LinkedHashMap的迭代时间就只跟entry的个数相关，而跟table的大小无关。 TreeMap基于红黑树的实现。查看键或者键值对时，它们会被排序（次序由Comparable或Comparator决定）。TreeMap是唯一带有subMap()方法的Map，它可以返回一个子树。 WeakHashMapWeakHashMap的entry保存的是关于对象的弱引用，即该对象可能会被GC自动删除，即使程序员没有调用remove()或者clear()方法。WeekHashMap 的这个特点特别适用于需要缓存的场景。在缓存场景下，由于内存是有限的，不能缓存所有对象；对象缓存命中可以提高系统效率，但缓存MISS也不会造成错误，因为可以通过计算重新得到。 参考文章JDK7与JDK8中HashMap的实现 | 谈谈HashMap线程不安全的体现 | Java Collections Framework Internals","categories":[],"tags":[{"name":"Java高级特性","slug":"Java高级特性","permalink":"http://yoursite.com/tags/Java高级特性/"}]},{"title":"Java反射源码分析","slug":"Java高级特性之反射源码分析","date":"2018-08-04T02:39:10.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/08/04/Java高级特性之反射源码分析/","link":"","permalink":"http://yoursite.com/2018/08/04/Java高级特性之反射源码分析/","excerpt":"java.lang.reflect.Method每个Java方法有且只有一个Method对象作为root，它相当于根对象，对用户不可见。当我们创建Method对象时，我们代码中获取的Method对象都相当于它的副本（或引用）。root对象持有一个MethodAccessor对象，所以所有获取到的Method对象都共享一个MethodAccessor对象，因此必须保证它在内存中的可见性。","text":"java.lang.reflect.Method每个Java方法有且只有一个Method对象作为root，它相当于根对象，对用户不可见。当我们创建Method对象时，我们代码中获取的Method对象都相当于它的副本（或引用）。root对象持有一个MethodAccessor对象，所以所有获取到的Method对象都共享一个MethodAccessor对象，因此必须保证它在内存中的可见性。 Img1Img1.1.检查AccessibleObject的override属性的值。 java.lang.reflect.AccessibleObject该类是Field、Method和Constructor对象的基类。它提供了将反射的对象标记为在使用时取消默认Java语言访问控制检查的能力。 override的值默认是false，表示需要权限调用规则，调用方法时需要检查权限； 可以用setAccessible方法设置为true，忽略权限规则，调用方法时无需检查权限（即可以调用任意的private方法，违反了封装原则）。 Img1.2.调用sun.reflect.Reflection类的quickCheckMemberAccess(Class&lt;?&gt;, int)方法检查方法是否为public。Img1.3.如果不是public方法调用Reflection类的getCallerClass()方法获取调用这个方法的Class对象，这是一个native方法。Img1.4.调用AccessibleObject类的checkAccess(Class&lt;?&gt;, Class&lt;?&gt;, Object, int)。 Img2Img2.1.执行一次快速校验，一旦调用方法的Class正确则权限检查通过。Img2.2.若快速检查未通过，则创建一个缓存，中间再进行一堆检查（比如检验是否为protected属性）。Img2.3.如果上面的所有权限检查都未通过，那么将调用本类的slowCheckMemberAccess(Class&lt;?&gt;, Class&lt;?&gt;, Object, int, Class&lt;?&gt;)方法执行更详细的检查。 Img3Img3.1.调用Reflection类的ensureMemberAccess(Class&lt;?&gt;, Class&lt;?&gt;, Object, int)方法继续进行权限检查。 Img4如果检查通过则返回，如果没有通过检查则会抛出异常。Img3.2.更新缓存，这样下一次同一个类调用同一个方法时就不用执行权限检查了。 Img1.5.第一次调用一个Java方法对应的Method对象的invoke()方法之前，实现调用逻辑的MethodAccessor对象还没有创建；等第一次调用时才新创建MethodAccessor并更新给root。 Img5调用sun.reflect.ReflectionFactory类的newMethodAccessor(Method)方法生成MethodAccessor实例。 Img1.6.委托给sun.reflect.MethodAccessor来处理反射调用逻辑。 Img6MethodAccessor接口的实现类NativeMethodAccessorImpl的invoke(Object, Object[])方法，调用本类的本地方法invoke0(Method, Object, Object[])方法来对反射逻辑进行处理。 参考文章深入解析Java反射","categories":[],"tags":[{"name":"Java高级特性","slug":"Java高级特性","permalink":"http://yoursite.com/tags/Java高级特性/"}]},{"title":"动态代理源码分析","slug":"Java高级特性之动态代理源码分析","date":"2018-07-28T06:18:58.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/07/28/Java高级特性之动态代理源码分析/","link":"","permalink":"http://yoursite.com/2018/07/28/Java高级特性之动态代理源码分析/","excerpt":"Java动态代理是利用反射机制在运行时创建代理对象，灵活的实现了代理模式。将-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true参数加入到JVM启动参数中，可以将JDK动态生成的代理类的字节码保存到硬盘上。","text":"Java动态代理是利用反射机制在运行时创建代理对象，灵活的实现了代理模式。将-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true参数加入到JVM启动参数中，可以将JDK动态生成的代理类的字节码保存到硬盘上。 Img1上面的写法是Proxy类的newProxyInstance(ClassLoader, Class&lt;?&gt;[], InvocationHandler)方法内部的写法相似。所以从上面的代码入手分析。即首先通过Prosy类的getProxyClass(ClassLoader loader, Class&lt;?&gt;… interfaces)方法获取代理类的字节码对象。 Img2调用本类的getProxyClass0(ClassLoader loader, Class&lt;?&gt;… interfaces)方法。 Img3如果实现当前接口的代理类存在，直接从缓存中返回，如果不存在，则通过ProxyClassFactory类的apply方法来创建。这里可以明显看到有对interface接口数量的限制，不能超过65535。 Img4Img4.1.代理类的名字前缀统一为$Proxy。Img4.2.每个代理类前缀后面都会跟着一个唯一的编号，如$Proxy0、$Proxy1、$Proxy2。Img4.3.验证类加载器加载接口得到对象是否与由apply函数参数传入的对象相同。Img4.4.验证这个Class对象是不是接口。Img4.5.验证这个接口是否重复。Img4.6.生成非公共代理接口的包名，即用和被代理类接口一样的包名。Img4.7.如果全是公共代理接口，包名生成逻辑默认是com.sun.proxy。Img4.8.生成代理类的类名，类名默认是$Proxy加上一个自增的整数值，由4.1和4.2生成。Img4.9.调用ProxyGenerator类的generateProxyClass(String, Class&lt;?&gt;[], int)方法根据具体传入的接口创建代理字节码。 Img5Img5.1.调用ProxyGenerator类的generateClassFile()方法生成代理类字节码文件。 Img6Img6.1.将Object类中的hashCode、equals和toString方法添加到代理类中。Img6.2.将接口中的所有方法添加到代理类中。Img6.3.验证具有相同方法签名的方法的返回类型是否一致。Img6.4.生成代理类的构造函数。Img6.5.为代理类生成静态代码块对某些字段进行初始化。Img6.6.代理类中的方法数量超过65535就抛异常。Img6.7.代理类中字段数量超过65535也抛异常。Img6.8.下面是对文件进行处理的过程。Img5.2.保存代理类的字节码文件，saveGeneratedFiles变量获取的就是-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true配置的值。Img4.10.调用本类的native方法把字节码通过传入的类加载器加载到JVM中。","categories":[],"tags":[{"name":"Java高级特性","slug":"Java高级特性","permalink":"http://yoursite.com/tags/Java高级特性/"}]},{"title":"Properties文件解析","slug":"Spring源码解析-Properties文件解析","date":"2018-07-14T02:30:07.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/07/14/Spring源码解析-Properties文件解析/","link":"","permalink":"http://yoursite.com/2018/07/14/Spring源码解析-Properties文件解析/","excerpt":"将Properties文件中内容解析到容器中Img1配置文件在XML中的配置。","text":"将Properties文件中内容解析到容器中Img1配置文件在XML中的配置。 Img2XML中解析context标签的NamespaceHandler。可以看出property-placeholder标签由PropertyPlaceholderBeanDefinitionParser类解析。 Img3Img3.1.使用了模板方法模式，Spring会默认调用BeanDefinitionParser接口的parse(Element element, ParserContext parserContext)方法，而该接口的顶层实现类是AbstractBeanDefinitionParser。 Img4使用模板方法调用子类的，本处是类AbstractSingleBeanDefinitionParser的parseInternal(Element, ParserContext)方法。下面的逻辑是构建BeanDefinition并注册到BeanDefinition容器中。 Img5Img5.1.使用模板方法模式调用子类，本处是PropertyPlaceholderBeanDefinitionParser类的getBeanClass(Element element)的方法获取真正构建的类PropertySourcesPlaceholderConfigurer。PropertySourcesPlaceholderConfigurer类在Spring3.1后替代了PropertyPlaceholderConfigurer类，该类间接实现了BeanFactoryPostProcessor接口，所以postProcessBeanFactory方法会在容器实例化之前被调用。 Img6Img6.1.调用父类PropertiesLoaderSupport的mergeProperties()方法获取所有一个包含所有配置文件的配置信息的Properties实例并用PropertySource实例进行包装。 Img7调用本类的loadProperties(Properties props)方法。 Img8循环调用PropertiesLoaderUtils.fillProperties(Properties props, EncodedResource resource, PropertiesPersister persister)方法将Resource资源解析到Properties对象中。Img5.2.使用模板方法模式调用子类，本处是PropertyPlaceholderBeanDefinitionParser类的doParse(Element element, BeanDefinitionBuilder builder)方法，即回到Img3.2。 Img3.2.调用父类AbstractPropertyLoadingBeanDefinitionParser的doParse(Element element, BeanDefinitionBuilder builder)方法，该方法和本类下面的代码主要解析property-placeholder的各种属性并保存到BeanDefinition中。 将容器中的配置解析到BeanDefinitionImg6.2.调用本类的processProperties(ConfigurableListableBeanFactory beanFactoryToProcess, ConfigurablePropertyResolver propertyResolver)方法。 Img9Img9.1.调用本类的doProcessProperties(ConfigurableListableBeanFactory beanFactoryToProcess, 方法。StringValueResolver valueResolver)方法。 Img10Img10.1.遍历所有的BeanDefinition并对它们进行解析，如果有需要替换的EL表达式就进行替换。Img10.2.调用BeanDefinitionVisitor类的visitBeanDefinition(BeanDefinition)方法对BeanDefinition进行解析。 Img11调用本类的visitPropertyValues(MutablePropertyValues pvs)方法解析setter方法注入的属性。 Img12Img12.1.遍历所有的setter方法注入的属性。Img12.2.调用本类的resolveValue(Object value)方法，对该属性进行解析。 Img13Img13.1.判断传递过来的属性是否是TypedStringValue类型。Img13.2.如果是，调用本类的resolveStringValue(String strVal)方法对该类型的值即EL表达式进行解析。 Img14回调Img9.2的匿名内部类。Img9.2.调用AbstractPropertyResolver类的resolveRequiredPlaceholders(String text)方法。 Img15调用本类的doResolvePlaceholders(String text, PropertyPlaceholderHelper helper)方法。 Img16Img16.1.调用PropertyPlaceholderHelper类的replacePlaceholders(String value, PlaceholderResolver placeholderResolver)方法。 Img17调用本类的parseStringValue(String value, PlaceholderResolver placeholderResolver, Set visitedPlaceholders)方法。 Img18Img18.1.解析出EL表达式中真正的字符串。Img18.2.回调Img16.2。Img16.2.使用模板方法模式调用子类PropertySourcesPropertyResolver的String getPropertyAsRawString(String key)方法。 Img19调用本类的getProperty(String key, Class targetValueType, boolean resolveNestedPlaceholders)方法。 Img20Img20.1.遍历存放着所有从Properties文件中解析出来的值的PropertySource列表。Img20.2.从PropertySource中获取该EL表达式所对应的真正的值。Img13.3.将真正的值存入TypedStringValue中。 将容器中的配置注入到实例中AutowiredAnnotationBeanPostProcessor类实现了InstantiationAwareBeanPostProcessor接口，Bean在初始化时会循环调用该类的postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName)方法。 Img21调用InjectionMetadata类的inject(Object target, String beanName, PropertyValues pvs)方法。 Img22回调子类AutowiredAnnotationBeanPostProcessor.AutowiredFieldElement类的inject(Object bean, String beanName, PropertyValues pvs)方法。 Img23Img23.1.调用DefaultListableBeanFactory类的resolveDependency(DependencyDescriptor descriptor, String requestingBeanName, Set autowiredBeanNames, TypeConverter typeConverter)方法获取Properties文件配置的真正数据。 Img24调用本类的doResolveDependency(DependencyDescriptor descriptor, String beanName, Set autowiredBeanNames, TypeConverter typeConverter)方法。 Img25Img25.1.获取@Value注解中的EL表达式。Img25.2.调用AbstractBeanFactory类的resolveEmbeddedValue(String value)方法。 Img26回调Img9.2的内部类，剩下的解析流程就和将容器中的配置解析到BeanDefinition一样。","categories":[],"tags":[{"name":"Spring基础","slug":"Spring基础","permalink":"http://yoursite.com/tags/Spring基础/"}]},{"title":"IoC源码解析-实例化阶段","slug":"Spring-IoC源码解析2","date":"2018-07-07T01:42:36.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/07/07/Spring-IoC源码解析2/","link":"","permalink":"http://yoursite.com/2018/07/07/Spring-IoC源码解析2/","excerpt":"Img1","text":"Img1Img1.2.调用AbstractBeanFactory的getBean(String name)方法。 Img20调用本类的doGetBean(String name, Class requireType, Object[] args, boolean typeCheckOnly)方法。 Img21Img21.1.转换beanName。Img21.2.调用DefaultSingletonBeanRegistry类的getSingleton(String beanName)方法。 Img21#1调用本类的重载方法getSingleton(String beanName, boolean allowEarlyReference)。 Img21#2这部分代码主要是用来解决循环依赖问题。循环依赖指两个或两个以上的bean互相持有对方，最终形成闭环。如A依赖B，B依赖C，C又依赖A。Img21#2.1.根据beanName从单例bean容器singletonObjects（又称为一级缓存）中获取实例化对象。如果该对象实例以及存在直接返回该对象。Img21#2.2.如果单例容器没有该实例且当前正在创建的单例bean容器singletonsCurrentlyInCreation中有该实例，即当前对象正在创建中（比如A的构造器依赖了B对象所以得先去创建B对象， 或则在A的populateBean过程中依赖了B对象，得先去创建B对象，这时的A就是处于创建中的状态）。从二级缓存earlySingletonObjects容器中获取该实例对象。Img21#2.3.如果earlySingletonObjects中也没有该实例且允许singletonFactories通过getObject()获取（allowEarlyReference属性为true），尝试从单例对象工厂容器singletonFactories（又称三季缓存）中获取该实例。如果singletonFactories中存在该beanName实例，则通过单例工厂的getObject()方法获取真正的实例。并将该实例添加到earlySingletonObjects容器中且从singletonFactories容器中删除该实例。Img21#2.4.返回创建的单例对象，如果还没有开始创建则返回NULL。 Img21.3.调用本类的getObjectForBeanInstance(Object beanInstance, String name, String beanName, RootBeanDefinition mbd)方法。 Img21#3处理FactoryBean类型的bean。Img21#3.1.如果name是以&amp;开头且beanInstance不是FactoryBean类型的就抛出异常。Img21#3.2.如果beanInstance不是FactoryBean类型或者name以&amp;开头直接返回该实例。Img21#3.3.检查父类FactoryBeanRegistrySupport类名为factoryBeanObjectCache的Map容器是否已经缓存了该对象。如果有就直接返回。Img21#3.4.获取合并之后的BeanDefinition。Img21#3.6.调用父类FactoryBeanRegistrySupport的getObjectFromFactoryBean(FactoryBean factory, String beanName, boolean shouldPostProcess)方法。 Img21#3#1从FactoryBean中获取Bean。Img21#3#1.1.判断该FactoryBean实例是单例的且已经被创建，即已经被缓存到singletonObjects容器中。Img21#3#1.2.判断该bean实例是否被创建，即被缓存到factoryBeanObjectCache容器中。如果是直接返回。Img21#3#1.4.执行后置处理器接口的方法BeanPostProcessor中的postProcessAfterInitialization(Object result, String beanName)方法。Img21#3#1.5.将通过factoryBean.getObject()方法得到的bean对象存到factoryBeanObjectCache容器中。Img21#3#1.6.调用本类的doGetObjectFromFactoryBean(FactoryBean factory, String beanName)方法。 Img21#3#2调用自己实现的FactoryBean实现类的getObject()方法返回真正的bean实例。 Img21.4.如果存在循环引用，则抛出异常。Img21.5.获取父容器。如果父容器存在，并且beanName在当前的容器不存在，那就去父容器查找。Img21.6.判断beanName是否存在&amp;，如果有的话去掉、检查是不是别名，如果是别名改成正真的beanName、判断如果传进来的带有 &amp;，则给它重新加上。Img21.7.委托父容器的getBean(String beanName, Object[] args)来获取bean。Img21.8.标记这个bean被创建过，即将该beanName加入到AbstractBeanFactory的名为alreadyCreated的Set集合中。Img21.9.调用本类的getMergedLocalBeanDefinition(String beanName)方法。 Img21#4父子bean的合并。当给定的bean是一个childe类型，它还有parent属性；则将parent的属性和childe属性合并一下。即newsListener会基础djNewsProvider的所有属性。Img21#4.1.从mergedBeanDefinitions获取BeanDefinition，如果有就直接返回。mergedBeanDefinitions是已经合并过的BeanDefinition容器。Img21#4.2.如果mergedBeanDefinition容器中没有，就调用本类的getMergedBeanDefinition(String beanName, BeanDefinition bd)方法。 Img21#5调用本类中的重载方法getMergedBeanDefinition(String beanName, BeanDefinition bd, BeanDefinition containingBd)方法。 Img21#6Img21#6.1.如果之前没有合并过，即mergedBeanDefinitions容器中没有该bean实例。Img21#6.2.如果没有配置parent属性。Img21#6.3.判断BeanDefinition是不是RootBeanDefinition类型。Img21#6.4.克隆新的实例。Img21#6.5.如果设置了parent属性。Img21#6.6.根据父beanName获取父类的BeanDefinition，如果父类还有父类会递归调用。Img21#6.7.如果父类的beanName和当前beanName相同。Img21#6.8.根据父BeanDefinition创建RootBeanDefinition。Img21#6.9.然后将子类的BeanDefinition所有已配置的数据覆盖父类的属性。Img21#6.10.如果没有设置作用域，默认Singleton。Img21#6.11.一个bean中包含了一个非单例的bean，则它本身就不能够是单例的。Img21#6.12.缓存合并之后的BeanDefinition，即将其加入到mergedBeanDefinitions容器中。 Img21.10.检查mbd是不是设置了属性abstract=true，如果设置了，不能去实例化，抛出异常。Img21.11.检查是否有依赖的bean。这里是deponse-on属性的依赖，跟bean内部依赖另外的bean不是一回事。Img21.12.调用本类的isDependent(String beanName, String dependentBeanName)方法。 Img21#7检查是否有循环依赖。Img21#7.1.如果beanName已经检查过了就直接返回。Img21#7.2.dependentBeanMap保存的是beanName的所有依赖的beanName。 Img21.13.标记依赖。Img21.14.依赖注入。Img21.15.调用DefaultSingletonBeanRegistry类的getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory)方法创建单例实例。 Img22Img22.1.如果正在销毁对象则抛出异常，不能继续创建单例对象。Img22.2.创建之前的一些操作。如将beanName放到singletonsCurrentlyInCreation集合中。Img22.3.调用ObjectFactory类的getObject()方法。参考Img21.15可以发现最终调用的是AbstractAutowireCapableBeanFactory类的createBean(String beanName, RootBeanDefinition mbd, Object[] args)方法。 Img23负责创建bean实例，填充bean实例，以及后置处理器等待等。Img23.1.填充BeanClass属性。Img23.2.准备overides数据。Img23.3.调用本类的resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd)方法。 Img23#1给BeanPostProcessors一个机会返回一个代理对象，主要调用的是接口InstantiationAwareBeanPostProcessor里面的方法。Img23#1.1.调用本类的applyBeanPostProcessorsBeforeInstantiation(Class beanClass, String beanName)方法。该方法会循环调用所有实现InstantiationAwareBeanPostProcessor接口的实现类的postProcessBeforeInstantiation(Class beanClass, String beanName)方法。如果该方法返回null，则部分逻辑结束，接着调用doCreateBean方法创建bean。如果postProcessBeforeInstantiation返回不为null说明修改了bean对象，则直接返回修改后的bean对象。Img23#1.2.调用本类的applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName)。该方法会循环调用所有实现InstantiationAwareBeanPostProcessor接口的postProcessAfterInitialization方法（注意这个是初始化之后的方法，也就是通过这个方法实例化了之后，直接执行初始化之后的方法，中间的实例化之后和初始化之前都不执行）如果postProcessAfterInitialization方法返回null，则接着返回并执行执行后面的初始化方法doCreateBean方法。如果不返回null那这个bean就直接返回给ioc容器。 Img23.4.调用本类的doCreateBean(String beanName, RootBeanDefinition mbd, Object[] args)方法。 Img24Img24.1.factoryBeanInstanceCache是缓存未完成的FactoryBean的实例对象的容器。Img24.2.调用本类的createBeanInstance(String beanName, RootBeanDefiniton mbd, Object[] args)方法。 Img25使用工厂方法为指定的bean创建一个新的实例，返回的是一个BeanWrapper包装类。Img25.1.如果配置了factory-method属性，则用工厂方法生成对象。Img25.3.BeanPostProcessor接口的调用。Img25.4.调用本类的instantiateBean(String beanName, RootBeanDefinition mbd)方法。 Img26使用默认的构造函数实例化bean，并且返回一个bean的包装类。调用SimpleInstantiationStrategy类的instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner)方法。 Img27Img27.1.根据bd的MethodOverrides属性来判断，只有在设置了lookup-method或replace-method的时候才会有。这里是在没有设置这两个属性的情况下就用反射来实例化对象。Img27.2.获取默认的构造函数。Img27.3.resolvedConstructorOrFactoryMethod字段保存的是使用哪个构造器生成实例化的或者是使用工厂方法生成实例化的。Img27.4.利用默认的构造函数反射生成实例化对象，里面调用了ctor.newInstance(args)。Img27.5.如果配置了lookup-method或replace-method就利用CGlib调用enhancer.createClass()生成了子类Class类型。 Img24.3.得到生成的实例。Img24.4.允许post-processors修改mergedBeanDefinition。Img24.5.判断PostProcessors后置处理器是否执行过。Img24.6.修改一下mergedBeanDefinition。Img24.7.调用DefaultSingletonBeanRegistry类的addSingletonFactory(String beanName, ObjectFactory singletonFactory)方法。 Img24#3提前暴露实例化的引用，即将bean实例添加到三级缓存singletonFactories中，主要是解决循环引用问题。此时单例对象已经通过createBeanInstance方法被创建出来，即调用了构造器，虽然还没有进行依赖注入，但是已经可以根据对象引用定位到堆中的对象。 Img24.9.获取提前暴露引用。Img24.10.填充bean属性。Img24.11.调用本类的initializeBean(String beanName, Object name, RootBeanDefinition mbd)方法。 Img24#1Img24#1.1.将Aware接口定义中规定的依赖注入给当前对象实例。Img24#1.2.分别遍历调用BeanPostProcessor接口的postProcessBeforeInitialization(Object bean, String beanName)和postProcessAfterInitialization(Object bean, String beanName)方法。Img24#1.3.检查当前实例是否实现了InitializingBean接口以决定是否调用afterPropertiesSet()方法。 Img24#2Img24#2.1.判断当前bean是否实现了InitializingBean接口且afterPropertiesSet这个方法没有注册为外部管理的初始化方法。如果没有就回调afterPropertiesSet()方法。Img24#2.2.调用本类的invokeCustomInitMethod(String beanName, Object bean, RootBeanDefinition mbd)方法执行用户配置的初始化方法。 Img22.4.调用本类的afterSingletonCreation(String beanName)方法结束创建bean。 Img22#1从singletonsCurrentlyInCreation容器remove掉该beanName。 Img22.5.调用本类的addSingleton(String beanName, Object singletonObject)方法。 Img22#2如果是一个新的实例，则把这个实例放入到一级缓存singletonObjects中，然后把二级和三级缓存都删除掉。","categories":[],"tags":[{"name":"Spring基础","slug":"Spring基础","permalink":"http://yoursite.com/tags/Spring基础/"}]},{"title":"IoC源码解析-容器启动阶段","slug":"Spring-IoC源码解析1","date":"2018-07-01T01:49:40.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/07/01/Spring-IoC源码解析1/","link":"","permalink":"http://yoursite.com/2018/07/01/Spring-IoC源码解析1/","excerpt":"Img1","text":"Img1Img1.1.调用AbstractBeanDefinitionReader类的loadBeanDefinitions(String)方法。 Img2调用本类的loadBeanDefinitions(String, Set)方法。 Img3Img3.1.获取ResourceLoader类。 Img3#1如果传递进来的BeanDefinitionRegistry接口的实现类没有实现ResourceLoader接口，会在AbstractBeanDefinitionReader抽象类的构造方法中默认创建一个PathMatchingResourcePatternResolver实例。 org.springframework.core.io.support.PathMatchingResourcePatternResolver 该类实现了ResourcePatternResolver接口，而ResourcePatternResolver接口继承了ResourceLoader接口并扩展了一个获取Resource数组的getResources(String)方法。 如下图Img3#2所示，该类内部默认持有一个DefaultResourceLoader实例，PathMatchingResourcePatternResolver会调用该实例去加载各种资源。所以如果不在构建该实例时传递一个ResourceLoader进去，该实例加载资源的模式就和DefaultResourceLoader相同。 Img3#2Img3.2.调用AbstractBeanDefinitionReader内部的重载方法。 Img4通过模板方法模式调用子类的loadDefinitions(Resource)方法，本案例使用的是XmlBeanDefinitionReader，所以调用的是XmlBeanDefinitionReader类的loadDefinitions(Resource)方法。 Img5调用自己重载的方法loadBeanDefinitions(EncodedResource)。 Img6调用本类的doLoadBeanDefinitions(InputSource, Resource)方法。 Img7Img7.1.将XML资源文件解析成org.w3c.dom.Document对象。Img7.2.调用本类的registerBeanDefinitions(Document, Resource)方法。 Img8Img8.1.调用本类的createBeanDefinitionDocumentReader()方法创建BeanDefinitionDocumentReader对象。 Img8#1根据XmlBeanDefinitionReader中的documentReaderClass属性判断创建BeanDefinitionDocumentReader类型，但是Spring中该接口只有DefaultBeanDefinitionDocumentReader一个实现类。Img8.2.调用DefaultBeanDefinitionDocumentReader的registerBeanDefinitions(Document, XmlReaderContext)方法。 Img9调用本类的doRegisterBeanDefinitions(Element)方法。 Img10Img10.1.调用本类的createDelegate(XmlReaderContex, Element, BeanDefinitionParserDelegate)方法。 Img10#1调用BeanDefinitionParserDelegate类的initDefaults(Element, BeanDefinitionParserDelegate)方法。 org.springframework.beans.factory.xml.BeanDefinitionParserDelegate在DefaultBeanDefinitionDocumentReader处理Document元素时，将Document文档内元素具体解析工作委托给BeanDefinitionParserDelegate类来处理，默认BeanDefinitionParserDelegate会处理http://www.springframework.org/schema/beans 命名空间下元素及其属性。 Img10#2调用本类的populateDefaults(DocumentDefaultsDefinition, DocumentDefaultsDefinition, Element)方法。 Img10#3将XML文件中的一些命名空间的基本配置转如default、lazy-init、autowire、dependency、check、settings、init-method、destroy-method等解析到DocumentDefaultsDefinition对象。图中标红的就是检查beans标签中default-lazy-init属性的值。Img10.2.调用本类的parseBeanDefinitions(Element, BeanDefinitionParserDelegate)方法。 Img11Img11.1.判断root的NamespaceURI是不是默认的命名空间URI=http://www.springframework.org/schema/beansImg11.2.调用本类的parseDefaultElement(Element, BeanDefinitionParserDelegate)方法解析属于beans命名空间的标签。 Img12Img12.1.调用本类的importBeanDefinitionResource(Element)方法解析import标签。Img12.2.调用本类的processAliasRegistration(Element)方法解析alias标签。Img12.3.调用本类的processBeanDefinition(Element, BeanDefinitionParserDelegate)方法解析bean标签。 Img13Img13.1.调用BeanDefinitionParserDelegate类的parseBeanDefinitionElement(Element, BeanDefinition)方法。 Img14Img14.1.获取XML中的bean的id和name属性的值。Img14.2.如果neme属性有值，就按照字符串”,; “分割成数组放到别名列表aliases中.Img14.3.如果id没有值且name有值，那么就把name别名中的第一个当做id，并且从aliases中删除掉。Img14.4.调用本类的checkNameUniqueness(String beanName, List aliases, Element beanElement)方法。 Img14#1检查当前的beanName和aliases是否被使用。Img14#1.1.先判断this.usedNames是否包含beanName(this.usedNames是一个 set集合，专门保存所有的beanName和aliases)。Img14#1.2.如果this.usedNames不包含，再判断当前aliases集合中是否存在已经被保存到this.usedNames集合中的元素。Img14#1.3.如果上述beanName或者aliases中有元素已久存在在this.usedNames中就抛出异常。Img14#1.4.否则将beanName和aliase一起add到this.usedNames中去。 Img14.5.调用本类的parseBeanDefinitionElement(Element, String, BeanDefinition)方法，获取AbstractBeanDefinition实例。 Img15解析BeanDefinition，不包括名称和别名（Img14已经解析过了）。Img15.1.BeanEntry是一个bean的实体类，它实现了ParseState.Entry接口，Entry是一个标志接口，什么都没有做，BeanEntry只有一个beanDefinitionName属性；ParseState类里面有一个名为state的栈，存放的对象类型是Entry；ParseState简单的栈结构来跟踪逻辑位置中解析过程，主要是记录异常信息，在异常的时候Spring调用error方法，会把ParseState栈中的信息一起抛出。Img15.2.获取Element中的class属性。Img15.3.获取Element中的parent属性。Img15.4.调用本类的createBeanDefinition(String, String)方法获取AbstractBeanDefinition实例，并设置相应的属性。 Img16调用BeanDefinitionReaderUtils工具类的createBeanDefinition(String, String, ClassLoader)方法创建AbstractBeanDefinition实例。 Img17创建AbstractBeanDefinition的实现类GenericBeanDefinition的实例并返回。 Img15.5.调用本类的parseBeanDefinitionAttributes(Element, String, BeanDefinition, AbstractBeanDefinition)方法。 Img15#1解析bean标签里面所有的属性值，例如scope、abstract、lazy-init、autowire、primary、depends-on等，并设置AbstractBeanDefinition中。Img15#1.1.解析singleton属性，现已废弃。Img15#1.2.设置作用域scope。默认是””。Img15#1.4.设置abstractFlag属性，默认是false。Img15#1.5.设置懒加载lazyInit属性。Img15#1.6.设置注入方式即autowireMode属性；byName、byType等。Img15#1.7.设置依赖检查的类型，即dependencyCheck属性。Img15#1.8.设置dependsOn属性。Img15#1.9.设置autowireCandidate属性。Img15#1.10.设置primary属性。装配时当出现多个Bean候选者时，被标记为Primary的Bean将作为首选者，否则将抛出异常；默认为false。Img15#1.11.设置初始化方法，即initMethodName属性。Img15#1.12.如果当前元素没有设置initMethodName属性，则判断xml全局配置有没有设置。Img15#1.13.设置destroyMethodName属性。Img15#1.14.设置factoryMethodName属性，即Spring通过工厂方法配置Bean。Img15#1.15.设置factoryBeanName属性。 Img15.6.设置description属性的值。Img15.7.解析元数据Meta，将meta中的key和value放入到new BeanMetadataAttribute(key, value)中。Img15.8.Spring有一种机制，可以动态的实现或重写bean容器中指定bean的指定方法，然后将返回值指定为bean容器中的另一个bean。Img15.9.跟上面类似replaced method注入是spring动态改变bean里方法的实现。需要改变的方法，使用spring内原有其他类（需要继承接口org.springframework.beans.factory.support.MethodReplacer）的逻辑，替换这个方法。通过改变方法执行逻辑来动态改变方法。内部实现为使用cglib方法，重新生成子类，重写配置的方法和返回对象，达到动态改变的效果。Img15.10.调用本类的parseConstructorArgElements(Element, BeanDefinition)方法，解析bean标签内部包含的标签。 Img15#2调用本类的parseConstructorArgElement(Element, BeanDefinition)方法。 Img15#3解析构造函数，即constructor-arg标签。Img15#3.1.判断XML是否配置了index。Img15#3.3.调用本类的parsePropertyValue(Element, BeanDefinition, String)方法获取属性值。 Img15#4该方法负责解析property标签和constructor-arg标签。Img15#4.1.如果ref属性和value属性同时存在抛异常；如果ref或者value存在一个并且subElement也存在抛异常。Img15#4.2.如果存在的是ref属性，返回RuntimeBeanReference实例。Img15#4.3.如果是value属性，返回TypedStringValue实例。Img15#4.4.如果是list标签，调用本类的parsePropertySubElement(Element, BeanDefinition)方法。 Img15#5调用本类的parsePropertySubElement(Element, BeanDefinition, String)方法。 Img15#6Img15#6.1.判断是不是默认的命名空间，如果不是调用本类的parseNestedCustomElement(Element, BeanDefinition)方法。Img15#6.2.解析bean元素。Img15#6.3.如果是ref标签，构建RuntimeBeanReference实例。Img15#6.4.解析idref标签。Img15#6.5.解析value标签。Img15#6.6.解析null标签。Img15#6.7.解析array标签。Img15#6.8.解析list标签。Img15#6.9.解析set标签。Img15#6.10.解析map标签。Img15#6.11.解析props标签。 Img15#4.5.都不是返回null。 Img15#3.4.新建一个ValueHolder实例，专门存放构造参数的一些属性值。Img15#3.5.设置类型。Img15#3.6.设置name。Img15#3.7.验证index是否设置正确。 Img15.11.set方法注入的处理。即解析property标签。Img15.12.解析qualifier元素。 Img14.6.判断beanName是否为””，即bean标签是否是既没有设置id也没有设置name属性。Img14.7.如果是则自动生成beanName。Img14.8.返回一个BeanDefinitionHolder对象。这个对象持有beanDefinition、beanName和aliases。 Img13.3.调用BeanDefinitionReaderUtils工具类的registerBeanDefinition(BeanDefinitionHolder, BeanDefinitionRegistry)方法。 Img18通过Img1中new XmlBeanDefinitionReader(beanFactory)中构造方法中传递进去的DefaultListableBeanFactory实例的registerBeanDefinition(String, BeanDefinition)方法将BeanDefinition注册到beanDefinitionMap容器中。 org.springframework.beans.factory.support.DefaultListableBeanFactory 该类间接继承了AbstractBeanFactory类，所以间接实现了BeanFactory接口。该接口是从容器中获取对象实例的顶层接口。 该类还实现了BeanDefinitionRegistry接口，该接口定义了对BeanDefinition容器的操作（注册到容器、从容器中获取BeanDefinition等）。 Img19Img19.1.对BeanDefinition进行一些验证。例如，如果设置了MethodOverrides效果就不能同时存在工厂方法。Img19.2.从beanDefinitionMap中更加beanName获取BeanDefinition，并判断该容器是否已经存在该BeanDefinition。beanDefinitionMap中使用beanName为键，BeanDefinition为值存放了所以的BeanDefinition。Img19.3.覆盖beanDefinition容器中已经存在的beanName相同的BeanDefinition。Img19.4.注册到beanDefinition容器中。Img19.5.在beanDefinitionNames容器中添加beanName（大概是为了线程安全才这么做）。beanDefinitionNames容器存放了所有已经注册到beanDefinition的beanName。Img19.6.判断manualSingletonNames（单例对象注册容器）中是否存在相同的对象名，如果存在就表示不是单例对象了，就在manualSingletonNames中remove掉。Img19.7.如果走到else中，则证明还在启动阶段，就可以直接在上述三个容器中添加相应的实例。 Img12.4.调用本类的doRegisterBeanDefinitions(Element)方法解析beans标签。Img11.3.调用BeanDefinitionParserDelegate类的parseCustomElement(Element)方法。 Img11#1解析bean以外格式的自定义标签标签，如aop、context等。Img11#1.1.获取当前Element的命名空间。Img11#1.2.调用DefaultNamespaceHandlerResolver类的resolve(String)方法，然后根据命名空间得到具体的NamespaceHandler处理类。 org.springframework.beans.factory.xml.DefaultNamespaceHandlerResolver默认的命名空间解析对象选择器；主要作用就是根据不同的命名空间来选择对应的解析器。 Img11#2Img11#2.1.调用本类的getHandlerMappings()方法。 Img11#3加载所有jar包下的META-INF/spring.handlers文件，并将内容解析到DefaultNamespaceHandlerResolver类的名为handlerMappings的属性的Map集合中。Img11#2.2.判断是否已经把全类名路径转换成具体的实例了，如果是就直接返回。Img11#2.3.根据全类名路径来加载这个NamespaceHandler类。Img11#2.4.加载完类后，通过反射生成具体的实例对象，如ContextNamespaceHandler等。Img11#2.5.调用该实例对象的init()方法，注册对应的解析类到NamespaceHandlerSupport抽象类的名为parsers的属性的Map结合中。Img11#2.6.将DefaultNamespaceHandlerResolver实例的名为handlerMappings的属性的Map集合中的value值由解析出来的全类名替换成上面由该全类名构建的实例。Img11#1.3.使用NamespaceHandler处理类去解析Element，返回BeanDefinition对象。","categories":[],"tags":[{"name":"Spring基础","slug":"Spring基础","permalink":"http://yoursite.com/tags/Spring基础/"}]},{"title":"Spring事务","slug":"Spring事务","date":"2018-06-30T08:28:27.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/06/30/Spring事务/","link":"","permalink":"http://yoursite.com/2018/06/30/Spring事务/","excerpt":"事务基础概念 原子性：事务包含的所有操作是一个整体，这些操作要么全部提交成功，要么只要有一个操作失败，就全部失败。 一致性：甲乙共有400元钱，甲提交转账100给乙的请求后，不管操作成功还是失败，甲乙依旧共有400元钱。 持久性：一旦整个事务提交成功，对数据所做的变更将被记录并不可逆转。 隔离性：规定了各个事务之间相互影响的程度。一般为事务指定4种隔离级别，即下面的事务隔离级别。","text":"事务基础概念 原子性：事务包含的所有操作是一个整体，这些操作要么全部提交成功，要么只要有一个操作失败，就全部失败。 一致性：甲乙共有400元钱，甲提交转账100给乙的请求后，不管操作成功还是失败，甲乙依旧共有400元钱。 持久性：一旦整个事务提交成功，对数据所做的变更将被记录并不可逆转。 隔离性：规定了各个事务之间相互影响的程度。一般为事务指定4种隔离级别，即下面的事务隔离级别。 脏读、不可重复读、幻读 脏读：一个事务读到另一个事务尚未提交的修改。如果后一个事务回滚，前一个事务读到的数据就是脏数据。 不可重复读：同一个事务在整个事务过程中对同一个数据进行多次读取，读取到的结果不同。如果事务1在事务2更新之前读取一次数据，更新之后又读取一次数据，那么这两次读取的结果可能不同。解决办法是对该条数据进行锁定，即每次只能有一个事务操作。 幻读：同一个查询在整个事务中多次执行后，查询到的结果集是不一样的。即在两次读取间隙，另一个事务插入了一条数据。只能对整个数据库进行锁定，即每次只能有一个事务操作该数据库。 事务各个成员 Resource Manager（RM）：负责存储并管理系统数据资源的状态，比如数据库服务器、JMS消息服务器等都是相应 Transaction Processing Monitor（TPM）：负责在分布式事务中协调包含RM的事务处理，TPM通常对应特定的软件中间件。 Transaction Manager（TM）：TPM的核心模块，直接负责多RM之间事务处理的协调工作，并且提供事务界定、事务上下文传播等功能接口。 事务类型 全局事务：又称分布式事务。如果整个事务处理过程中有多个RM参与，那么就需要引入TPM来协调多个RM之间的事务处理。TPM将采用两段式提交协议来保证整个事务的ACID属性。 两段式提交：TM会分别询问两个RM，如果任何一个RM提交失败，则整个事务失败，双方都要回滚到之前的状态。 局部事务：当前事务只有一个RM参加。如对一个数据库进行更新，或者向一个消息队列中发送信息等。 Spring事务事务处理过程中出现的异常应该都是不可恢复的，所以应该抛出unchecked exception，并且有一个统一的父类，便于客户端处理。 org.springframework.transaction.TransactionDefinition该接口定义了事务的相关属性如事务的隔离级别（IsolationLevel）、事务的传播行为（PropagationBehavior）、事务的超时时间（Timeout）、是否为只读事务（ReadyOnly）。 org.springframework.transaction.TransactionStatus该接口定义表示了整个事务处理过程中的事务状态，一般在编程式事务中使用该接口。可以使用该接口查询事务状态、通过setRollbackOnly()方法标记事务以使其回滚、还可以通过Savepoint在当前事务中创建内嵌事务。 org.springframework.transaction.PlatformTransactionManager org.springframework.transaction.support.AbstractPlatformTransactionManagerPlatformTransactionManager接口的抽象实现类，以模板方法的形式封装了固定的事物处理逻辑，而只将与事物资源相关的操作以protected或abstract方式留给具体的实现类来实现。作为模板方法的父类，该类实现以下固定的事务内部处理逻辑： 判断是否存在当前事务，然后根据判断结果执行不同的处理逻辑。 结合是否存在当前逻辑的情况，根据TransactionDefinition中指定的传播行为的不同语义执行后继逻辑。 根据情况挂起或恢复事务。 提交事务之前检查readOnly字段是否被设置，如果是，以事务的回滚代替事务的提交。 在事务回滚的情况下，清理并恢复事务状态。 如果事务的Synchronization处于active状态，在事务处理的规定时点触发注册的Synchronization回调接口。 事务的隔离级别 ISOLATION_DEFAULT：PlatformTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别，另外四个与JDBC的隔离级别相对应。 ISOLATION_READ_UNCOMMITTED：对应Read Uncommitted，这是事务最低的隔离级别，它充许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻读。 ISOLATION_READ_COMMITTED(Oracle数据库默认的隔离级别)：对应Read Committed，保证一个事务修改的数据提交后才能被另外一个事务读取。该隔离级别可以避免脏读出现。 ISOLATION_REPEATABLE_READ(InnoDB默认的隔离级别)：对应Repeatable Read，保证在整个事务的过程中，对同一笔数据的读取结果是相同的，不管其他事务是否对同一个数据进行更新，也不管该数据提交与否。该隔离级别避免了脏读和不可重复读。 InnoDB虽然默认是该隔离级别，但是使用了Next-Key Lock锁的算法，因此可以避免幻读的产生。Next-Key Lock是结合了间隙锁(Gap Lock)和Record Lock的一种锁定算法。 ISOLATION_SERIALIZABLE：对应Serializable，所有的事务都必须依次执行，所以可以避免脏读、不可重复读和幻读。 事务的传播行为 PROPAGATION_REQUIRED(默认)：如果存在一个事务，则加入当前事务。如果没有事务则开启一个新的事务。 PROPAGATION_SUPPORTS：如果存在一个事务，加入当前事务。如果没有事务，则非事务的执行。 PROPAGATION_MANDATORY：如果已经存在一个事务，加入当前事务。如果没有一个活动的事务，则抛出异常。 PROPAGATION_REQUIRES_NEW：总是开启一个新的事务。如果一个事务已经存在，则将这个存在的事务挂起。 PROPAGATION_NOT_SUPPORTED：总是非事务地执行，并挂起任何存在的事务。 PROPAGATION_NEVER：总是非事务地执行，如果存在一个活动事务，则抛出异常。 PROPAGATION_NESTED：如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务, 则按PROPAGATION_REQUIRED属性执行。","categories":[],"tags":[{"name":"Spring基础","slug":"Spring基础","permalink":"http://yoursite.com/tags/Spring基础/"}]},{"title":"Spring-AOP揭秘","slug":"Spring-AOP揭秘","date":"2018-06-23T02:25:17.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2018/06/23/Spring-AOP揭秘/","link":"","permalink":"http://yoursite.com/2018/06/23/Spring-AOP揭秘/","excerpt":"AOP（面向切面编程）是面向对象编程模式的一个补足，负责将系统中的日志记录、安全检查、事物管理等无法通过OOP模块化的重复代码模块化，避免不必要的代码散落。而Spring AOP采用Java作为AOP的实现语言（AOL），较之想AspectJ那种语言扩展型的AOP实现，SpringAOP可以更快捷的融入开发，学习曲线相对平滑得多。","text":"AOP（面向切面编程）是面向对象编程模式的一个补足，负责将系统中的日志记录、安全检查、事物管理等无法通过OOP模块化的重复代码模块化，避免不必要的代码散落。而Spring AOP采用Java作为AOP的实现语言（AOL），较之想AspectJ那种语言扩展型的AOP实现，SpringAOP可以更快捷的融入开发，学习曲线相对平滑得多。 AOP基础概念 在系统运行前，AOP的功能模块都需要织入到OOP的功能模块中。进行这种织入过程，需要知道在系统的哪些执行点上进行织入操作，这些将要在其之上进行织入操作的系统执行点称之为Joinpoint。下面列举了常见的Joinpoint类型（Spring AOP只支持方法执行类型的Joinpoint）： 方法调用：当某个方法被调用的时候所处的程序执行点。 方法执行：不同于方法调用是在调用对象的执行点，方法执行是在被调用到的方法执行的时点。对于同一对象，方法调用先于方法执行。 构造方法调用：程序执行过程中对某个对象调用其构造方法进行初始化的时点。 字段设置：对象的某个属性通过setter方法被设置或者直接被设置的时点。 字段获取：相对于字段设置型的Joinpoint，字段获取型的Joinpoint，对应是某个对象相应属性被访问的时点。 异常处理执行：该类型的Joinpoint对应程序执行中，在某些异常类型抛出后，对应的异常处理逻辑执行的时点。 类初始化：类中某些静态类型或静态块的初始化时点。 Pointcut：Joinpoint的表述方式。将横切逻辑织入当前系统的过程中，需要参照Pointcut规定的Joinpoint信息，才能知道应该往系统的哪些Joinpoint上织入横切逻辑。 Advice：单一横切关注点逻辑的载体，代表将会织入到Joinpoint的横切逻辑。 Aspect：对系统中的横切关注点逻辑进行模块化封装的AOP概念实体。通常情况下，Aspect可以包含多个Pointcut已经相关的Advice定义。 织入器：负责将横切逻辑织入到目标对象。 目标对象：指符合Pointcut所指定的条件，将在织入过程中被织入横切逻辑的对象。 Java平台的AOP实现机制 动态代理（Spring默认使用）：JDK1.3之后引入了一种称之为动态代理的机制。使用该机制，我们可以为指定的接口在系统运行期间动态地生成代理对象。 缺点：被代理的类必须实现了相应的接口，如果某个类没有实现任何接口就没有办法使用该机制。 CGLIB动态字节码生成：如果Spring AOP发现目标对象没有实现任何接口，就会尝试使用该CGLIB的开源的动态字节码生成类库，为目标对象动态的构建子类的字节码的class文件。 原理：对目标对象进行继承扩展，为其生成相应的子类，而子类可以通过覆写来扩展父类的行为，只要将横切逻辑实现放到子类中，然后让系统使用扩展后的目标对象的子类，就可以达到与代理模式相同的效果了。 缺点：无法对私有方法和final方法进行覆写。 Java代码生成：根据部署描述符文件提供的织入信息，为相应的功能模块类生成对应的Java代码，然后通过部署工具或部署接口编译Java代码生成相应的Java类。 自定义类加载器：通过读取外部文件规定的织入规则和必要信息，在加载class文件期间就可以将横切逻辑添加到系统模块类的现有逻辑中，然后将改动后的class交给Java虚拟机运行。 AOL扩展：AspectJ使用的方式，在这种方式中，AOP的各种概念在AOL中大都有一一对应的实体。 Spring AOP实现机制织入器 - org.springframework.aop.framework.ProxyFactory ProxyFactory的父类ProxyCreatorSupport的有参构造方法中会接收一个AopProxyFactory作为创建AopProxy的工厂类。如果使用无参的构造方法，在构造方法中会创建一个DefaultAopProxyFactory实例，当然也可以通过setAopProxyFactory方法替换该实例。 AopProxyFactory会根据传入的AdvisedSupport实例提供的相关信息，来决定生成什么类型的AopProxy。 AdvisedSupport是一个生成代理对象所需要的信息的载体。该类继承了ProxyConfig类并实现了Advised接口。其中，ProxyConfig记录生成代理对象所需要的控制信息；Advised记录生成代理对象所需要的必要信息，如相关目标类、Advice、Advisor等。 Aspect - org.springframework.aop.AdvisorAdvisor是一种特殊的Aspect，通常只持有一个Pointcut和一个Advice。 Advice - org.aopalliance.aop.Advice per-class类型的Advice：该类型的Advice的实例可以在目标对象类的所有实例间共享。这种类型的Advice通常只提供方法拦截功能，不会为目标对象类保存任何状态或者添加任何属性。 per-instance类型的Advice：不会在目标类所有对象实例之间共享，而是会为不同的实例对象保存它们各自的状态以及相关逻辑。外在表现为可以为目标对象添加属性。 Pointcut - org.springframework.aop.Pointcut Pointcut持有ClassFilter和MethodMatcher的引用，ClassFilter和MethodMatcher则分别用于匹配将被织入操作的对象以及相应的方法。 根据MethodMatcher的isRuntime的返回值的不同，分为静态类型匹配和动态类型匹配。 返回false表示不会考虑具体Jointpoint的方法参数，这种类型的MethodMatcher称为StaticMethodMatcher。因为不用每次检查参数，那么对同类型的方法匹配结果，就可以在框架内缓存以提高性能。 当isRuntime返回true时，表明该MethodMatcher将会每次都对调用的参数进行匹配检查，这种类型的MethodMatcher称之为DynamicMethodMatcher。因为每次都要对方法参数进行检查，无法对匹配结果进行缓存。 在MethodMatcher的基础上，Pointcut分为两类，即StaticMethodMatcherPointcut和DynamicMethodMatcherPointcut。 AOP在Spring内部的应用 全局异常处理：对于RuntimeException，通常就是记录日志、通知相应人员、给用户一个统一的信息等。所以，这些相同的逻辑实现可以归并与一处进行处理。 使用拦截器获取Spring Security框架进行安全检查、Spring缓存机制、Spring事物等。","categories":[],"tags":[{"name":"Spring基础","slug":"Spring基础","permalink":"http://yoursite.com/tags/Spring基础/"}]},{"title":"Spring-IoC揭秘","slug":"Spring-IoC揭秘","date":"2018-06-16T07:22:30.000Z","updated":"2021-07-10T10:58:48.587Z","comments":true,"path":"2018/06/16/Spring-IoC揭秘/","link":"","permalink":"http://yoursite.com/2018/06/16/Spring-IoC揭秘/","excerpt":"IoC原理解析原来需要手动new对象，并且用完之后对象可能被废弃了，而Spring IoC可以帮助我们创建对象、管理对象的生命周期、对对象的依赖进行注入等。具体可以分为容器启动阶段和实例化阶段，容器启动阶段主要是解析配置文件，以XML为例，通过XmlBeanDefinitionReader加载所有的xml文件并在内部调用DefaultBeanDefinitionDocumentReader解析xml各个节点，主要是将bean标签解析到BeanDefinition中，在然后就可以通过BeanDefinitionRegistry将BeanDefinition添加到BeanDefinition容器中。实例化阶段在调用getBean方法后开始，一般我们在程序中调用getBean方法后会先去单例容器尝试获取该实例，如果存在就可以直接返回，如果不存在就会去判断该bean是否是单例的，然后去BeanDefinition容器获取该key对应的BeanDefinition对象，然后根据BeanDefinition去构建需要返回的对象实例。大概步骤是这样，中间还有很多需要注意的点，比如会尝试从父容器获取bean、对BeanPostProcessors的调用、循环依赖的问题等。 循环依赖问题Spring使用三级缓存来解决循环依赖问题，即将已经创建出来还没有注入依赖的对象放入singletonsCurrentlyInCreation缓存中，循环依赖时可以将还没有构建完成的实例从该容器中拿出来，并进行依赖注入。所以如果是构造方法注入的循环依赖，Spring会抛出异常。 容器启动阶段 Spring通过XmlBeanDefinitionReader解析XML配置将配置中的bean的基本信息解析到BeanDefinition实例中。 通过BeanDefinitionRegistry接口的registerBeanDefinition方法将BeanDefinition注册到BeanDefinition容器，即存放到变量名为beanDefinitionMap的Map集合中。 使用BeanFactoryPostProcessor在容器实例化相应对象之前，对注册到容器的BeanDefinition所保存的信息做相应的修改。可以以此来修改bean定义的某些属性，为bean定义增加其他信息等。 PropertyPlaceholderConfigurer实现类：允许我们在XML配置文件中使用占位符（PlaceHolder），并将这些站位符所代表的资源单独配置到简单的properties文件中来加载（例如数据库的数据源等配置内容，一般写在配置文件中）。 PropertyOverrideConfigurer实现类：可以对容器中配置的任何你想处理的bean定义的property信息进行覆盖替换。即读取properties文件中的配置项，用读取到beanName.propertyName=value的value值覆盖掉对应的原来XML中bean定义的property信息。 CustomEditorConfigurer实现类：容器从XML中读取的都是字符串形式的，最终的应用程序却是由各种类型的对象构成。要想完成这种由字符串到具体对象的转换，就需要转换规则相关的信息，CustomEditorConfigurer类就是负责将我们自己实现的PropertyEditor接口的实现类告知容器的。","text":"IoC原理解析原来需要手动new对象，并且用完之后对象可能被废弃了，而Spring IoC可以帮助我们创建对象、管理对象的生命周期、对对象的依赖进行注入等。具体可以分为容器启动阶段和实例化阶段，容器启动阶段主要是解析配置文件，以XML为例，通过XmlBeanDefinitionReader加载所有的xml文件并在内部调用DefaultBeanDefinitionDocumentReader解析xml各个节点，主要是将bean标签解析到BeanDefinition中，在然后就可以通过BeanDefinitionRegistry将BeanDefinition添加到BeanDefinition容器中。实例化阶段在调用getBean方法后开始，一般我们在程序中调用getBean方法后会先去单例容器尝试获取该实例，如果存在就可以直接返回，如果不存在就会去判断该bean是否是单例的，然后去BeanDefinition容器获取该key对应的BeanDefinition对象，然后根据BeanDefinition去构建需要返回的对象实例。大概步骤是这样，中间还有很多需要注意的点，比如会尝试从父容器获取bean、对BeanPostProcessors的调用、循环依赖的问题等。 循环依赖问题Spring使用三级缓存来解决循环依赖问题，即将已经创建出来还没有注入依赖的对象放入singletonsCurrentlyInCreation缓存中，循环依赖时可以将还没有构建完成的实例从该容器中拿出来，并进行依赖注入。所以如果是构造方法注入的循环依赖，Spring会抛出异常。 容器启动阶段 Spring通过XmlBeanDefinitionReader解析XML配置将配置中的bean的基本信息解析到BeanDefinition实例中。 通过BeanDefinitionRegistry接口的registerBeanDefinition方法将BeanDefinition注册到BeanDefinition容器，即存放到变量名为beanDefinitionMap的Map集合中。 使用BeanFactoryPostProcessor在容器实例化相应对象之前，对注册到容器的BeanDefinition所保存的信息做相应的修改。可以以此来修改bean定义的某些属性，为bean定义增加其他信息等。 PropertyPlaceholderConfigurer实现类：允许我们在XML配置文件中使用占位符（PlaceHolder），并将这些站位符所代表的资源单独配置到简单的properties文件中来加载（例如数据库的数据源等配置内容，一般写在配置文件中）。 PropertyOverrideConfigurer实现类：可以对容器中配置的任何你想处理的bean定义的property信息进行覆盖替换。即读取properties文件中的配置项，用读取到beanName.propertyName=value的value值覆盖掉对应的原来XML中bean定义的property信息。 CustomEditorConfigurer实现类：容器从XML中读取的都是字符串形式的，最终的应用程序却是由各种类型的对象构成。要想完成这种由字符串到具体对象的转换，就需要转换规则相关的信息，CustomEditorConfigurer类就是负责将我们自己实现的PropertyEditor接口的实现类告知容器的。 Bean实例化阶段实例化阶段又分为实例化和初始化，实例化是指创建一个bean的过程，即调用bean的构造函数；初始化指初始化bean属性，即调用bean的setter方法设置bean属性。 当某个请求方通过容器的getBean方法明确地请求某个对象，或者因依赖关系容器需要隐式地调用getBean方法时，先检查所请求的对象之前是否已经初始化，即检查DefaultSingletonBeanRegistry类的变量名为singletonObjects的Map集合中是否有所需要的对象。 如果没有，则判断是否为单例，如果是，根据注册的BeanDefinition所提供的信息实例化被请求对象，为其注入依赖，并存放到singletonObjects容器中。 检查当前对象实例是否实现了一系列的以Aware命名结尾的回调接口。如果是，则将这些Aware接口定义中规定的依赖注入给当前对象实例。 BeanNameAware：实现该接口的对象可以获取该对象实例对应的beanName。 BeanClassLoaderAware：实现该接口的对象可以获取加载该对象的Classloader。默认会使用加载org.springframework.util.ClassUtils类的Classloader。 BeanFactoryAware：实现该接口的对象可以获取到BeanFactory容器本身。 使用BeanPostProcessor接口对所有符合条件的实例化后的对象实例进行处理。 postProcessBeforeInitialization()方法是上图中BeanPostProcessor前置处理这一步将会执行的方法。 postProcessAfterInitialization()则是对应上图中BeanPostProcessor后置处理那一步将会执行的方法。 InitializingBean接口、bean的init-method属性和@PostConstruct注解：在对象实例化过程调用过BeanPostProcessor的前置处理之后，会接着检测当前对象是否实现了InitializingBean接口，如果是，则会调用其afterPropertiesSet()方法进一步调整对象实例的状态。 DisposableBean接口、bean的destroy-method属性和@PreDestory注解：当所有的一切，该设置的设置，该注入的注入，该调用的调用完成之后，容器将检查singleton类型的bean实例，看其是否实现了org.springframework.beans.factory.DisposableBean接口。或者其对应的bean定义是否通过bean的destroy-method属性指定了自定义的对象销毁方法。如果是，就会为该实例注册一个用于对象销毁的回调（Callback），以便在这些singleton类型的对象实例销毁之前，执行销毁逻辑。 ps：可以在 org.springframework.beans.factory.support.AbstractBeanFactory类的代码中查看到getBean()方法的完整实现逻辑，可以在其子类org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory的代码中一窥createBean()方法的全貌。 统一资源加载策略org.springframework.core.io.Resource ByteArrayResource：将字节（byte）数组提供的数据作为一种资源进行封装，如果通过InputStream形式访问该类型的资源，该实现会根据字节数组的数据，构造相应的ByteArrayInputStream并返回。 ClassPathResource ：该实现从Java应用程序的ClassPath中加载具体资源并进行封装，可以使用指定的类加载器（ClassLoader）或者给定的类进行资源加载。 FileSystemResource：对java.io.File类型的封装，所以，我们可以以文件或者URL的形式对该类型资源进行访问，只要能跟File打的交道，基本上跟FileSystemResource也可以。 UrlResource：通过java.net.URL进行的具体资源查找定位的实现类，内部委派URL进行具体的资源操作。 InputStreamResource：将给定的InputStream视为一种资源的Resource实现类，较为少用。可能的情况下，以ByteArrayResource以及其他形式资源实现代之。 org.springframework.core.io.ResourceLoader DefaultResourceLoader：默认实现类。 首先检查资源路径是否以classpath:前缀打头，如果是，则尝试构造ClassPathResource类型资源并返回。 尝试通过URL，根据资源路径来定位资源，如果没有抛出MalformedURLException，有则会构造UrlResource类型的资源并返回； 委派getResourceByPath(String)方法来定位，DefaultResourceLoader的getResourceByPath(String)方法默认实现逻辑是，构造ClassPathResource类型的资源并返回。 FileSystemResourceLoader：继承自DefaultResourceLoader，但覆写了getResourceByPath(String)方法，使之从文件系统加载资源并以FileSystemResource类型返回。 ResourcePatternResolver： ResourceLoader的扩展，ResourceLoader每次只能根据资源路径返回确定的单个Resource实例，而ResourcePatternResolver则可以根据指定的资源路径匹配模式，每次返回多个Resource实例。 PathMatchingResourcePatternResolver：在构造该实例的时候，可以指定一个ResourceLoader，如果不指定的话，则PathMatchingResourcePatternResolver内部会默认构造一个DefaultResourceLoader实例。然后将匹配后确定的资源路径委派给该ResourceLoader加载，所以如果不指定任何ResourceLoade 的话，PathMatchingResourcePatternResolver在加载资源的行为上会与DefaultResourceLoader基本相同，只存在返回的 Resource 数量上的差异。 classpath和classpath* classpath：指向编译过后的classes目录。只会到你当前项目的classes路径中查找文件。 对于maven的所有项目，配置文件一般放在resources目录下，当编译之后会自动复制到classes目录下。 非maven的所有项目，一般放在src目录下，编译之后也会自动复制到classes目录下面。 classpath*：不仅包含当前项目classes路径，还对当前项目包含的jar文件的classes路径进行查找。 在多个classpath中存在同名资源时，classpath只会加载第一个，而classpath*会都加载。 classpath需要遍历所有的classpath，所以加载速度是很慢的，因此，在规划的时候，应该尽可能规划好资源文件所在的路径，尽量避免使用classpath。 org.springframework.beans.factory.config.BeanPostProcessorBeanPostProcessors在spring中是一个非常重要的扩展接口，它使得我们可以在创建bean实例的前后做一些自己的处理。 方法描述 postProcessBeforeInitialization(Object bean, String beanName)：在初始化之前调用。具体在AbstractAutowireCapableBeanFactory类的applyBeanPostProcessorsBeforeInitialization方法中被循环调用。 postProcessAfterInitialization(Object bean, String beanName)：在初始化之后调用。具体在AbstractAutowireCapableBeanFactory类的applyBeanPostProcessorsAfterInitialization方法中被循环调用。 applyBeanPostProcessorsBeforeInitialization方法和applyBeanPostProcessorsAfterInitialization方法都是在本类的initializeBean(String, Object, RootBeanDefinition)方法中被调用。initializeBean则被本类的doCreateBean方法调用。 BeanPostProcessor子接口org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessorBeanPostProcessor作用于初始化阶段，而InstantiationAwareBeanPostProcessor作用于实例化阶段。 postProcessBeforeInstantiation(Class beanClass, String beanName)：实例化之前调用。具体在AbstractAutowireCapableBeanFactory类的applyBeanPostProcessorsBeforeInstantiation方法中被循环调用。 postProcessAfterInstantiation(Class beanClass, String beanName)：实例化之后设置bean属性时调用。具体在AbstractAutowireCapableBeanFactory类的populateBean方法中被循环调用。 org.springframework.beans.factory.config.SmartInstantiationAwareBeanPostProcessor该接口继承了InstantiationAwareBeanPostProcessor接口。 predictBeanType(Class beanClass, String beanName)：预测bean的类型，返回第一个预测成功的Class类型，如果不能预测返回null。具体在类AbstractAutowireCapableBeanFactory的predictBeanType(String beanNama, RootBeanDefinition mbd, Class[] typesToMatch)方法中循环调用。 determineCandidateConstructors(Class beanClass, String beanName)：选择合适的构造器，比如目标对象有多个构造器，在这里可以进一步定制化，选择合适的构造器。具体在类AbstractAutowireCapableBeanFactory的determineConstructorsFromBeanPostProcessors(Class beanClass, String beanName)方法中循环调用。 getEarlyBeanReference(Object bean, String beanName)：获得提前暴露的bean引用，主要用来解决循环引用问题，只有单例对象才会调用此方法。具体在类AbstractAutowireCapableBeanFactory的getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean)方法中循环调用。 org.springframework.context.ApplicationContextApplicationContext是在BeanFactory的基础上构建，不但拥有BeanFactory所有功能，同时提供了统一资源加载策略、国际化信息支持、容器类别事件发布等特性。而且ApplicationContext所管理的对象，在该容器启动之后，默认全部初始化并绑定完成。而不是像BeanFactory当客户端对象需要访问容器中的某个受管对象时，才对该对象进行初始化及依赖注入操作。即ApplicationContext会在启动阶段的活动完成后，紧接着通过org.springframework.context.support.AbstractApplicationContext的refresh()方法调用注册到该容器所有bean定义的实例化方法getBean()隐式初始化所有的bean。Img1.3.对BeanFactoryPostProcessor的实例类进行预处理。Img1.4.在此处通过PostProcessorRegistrationDelegate对BeanFactoryPostProcessor进行初始化并执行了postProcessBeanFactory方法。Img1.5.在此处通过PostProcessorRegistrationDelegate对所有的BeanPostProcessor实例初始化并注册到容器。Img1.6.如果有相关bean，则负责配置国际化操作。Img1.7.指定SimpleApplicationEventMulticaster作为系统观察者。Img1.9.在此处为观察者添加被观察者。Img1.10.对所有剩余普通的Bean(non-lazy-init)的初始化并注册到容器中。","categories":[],"tags":[{"name":"Spring基础","slug":"Spring基础","permalink":"http://yoursite.com/tags/Spring基础/"}]},{"title":"Spring其它","slug":"JavaWeb-Spring其它","date":"2018-06-09T01:05:52.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2018/06/09/JavaWeb-Spring其它/","link":"","permalink":"http://yoursite.com/2018/06/09/JavaWeb-Spring其它/","excerpt":"Spring定时任务实现延迟任务的几种方式 | Spring定时任务","text":"Spring定时任务实现延迟任务的几种方式 | Spring定时任务 Spring缓存 @Cacheable(value=”accountCache”)：当调用这个方法的时候，会从一个名叫accountCache的缓存中查询，如果没有，则执行实际的方法（即查询数据库），并将执行的结果存入缓存中，否则返回缓存中的对象。这里的缓存中的key就是参数，value就是返回的对象。 @CacheEvict(value=”accountCache”, key=”#account.getName()”)：当调用这个方法的时候会清空缓存，其中的Key是用来指定缓存的key的，这里因为我们保存的时候用的是account对象的name字段，所以这里还需要从参数account对象中获取name的值来作为key，前面的#号代表这是一个SpEL表达式，此表达式可以遍历方法的参数对象。 @CacheEvict(value=”accountCache”, key=”#account.getName()”)：清空accountCache key=account.getName()的缓存； @CacheEvict(value=”accountCache”, allEntries=true)：清空accountCache所有缓存。 @Cacheable(value=”accountCache”, condition=”#userName.length() &lt;= 4”)：缓存名叫accountCache，参数userName长度小于4的缓存。 @CachePut(value=”accountCache”, key=”#account.getName()”)：该注释可以确保方法被执行，同时方法的返回值也被记录到缓存中，实现缓存与数据库的同步更新。 Caching：缓存分组，能够同时应用多个其他的缓存。 在SpringBoot中的使用 各个jar包的作用 spring-aop：提供AOP（面向切面编程）的实现。 spring-aspects：提供了对AspectJ的支持。AspectJ是一个面向切面的框架。AspectJ定义了AOP语法，所以它有一个专门的编译器用来生成遵守Java字节编码规范的Class文件。 spring-beans：IoC的基础实现，包含访问配置文件、创建和管理bean等。如果应用只需基本的IoC/DI 支持，引入Spring Core及Spring Beans文件就可以了。 spring-context：在基础IoC功能上提供了扩展服务，此外还提供许多企业级服务的支持，有邮件服务、任务调度、JNDI定位，EJB集成、远程访问、缓存以及多种视图层框架的支持。 spring-context-support：spring-context的扩展支持，用于MVC方面。 spring-core：包含了基本的核心工具类。Spring其他组件都要使用这个包里面的类。 spring-expression：Spring表达式语言。 spring-instrument： spring-instrument-tomcat： spring-jdbc：对JDBC的简单封装 spring-jms：为简化JMS（Java消息服务）的使用而做的简单封装。 spring-message： spring-orm：整合第三方的orm实现，如hibernate、ibatis、jdo和spring的jpa实现。 spring-oxm：Spring对于object/xml映射的支持，可以让JAVA与XML之间来回切换。 spring-test：对JUNIT等测试框架的简单封装。 spring-tx：为JDBC、Hibernate、JDO、JPA等提供的一致的声明式和编程式事务管理。 spring-web：包含Web应用开发时，用到Spring框架时所需的核心类，包括自动载入WebApplicationContext特性的类、Struts与JSF集成类、文件上传的支持类、Filter类和大量工具辅助类。 spring-webmvc：包含SpringMVC框架相关的所有类。包含国际化、标签、Theme、视图展现的FreeMarker、JasperReports、Tiles、Velocity、XSLT相关类。当然，如果你的应用使用了独立的MVC框架，则无需这个JAR文件里的任何类。 spring-webmvc-portlet：对SpringMVC的增强。 spring-websocket：Spring对WebSocket的支持。","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"Sprin之XML解析","slug":"JavaWeb-XML解析","date":"2018-04-20T09:09:42.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2018/04/20/JavaWeb-XML解析/","link":"","permalink":"http://yoursite.com/2018/04/20/JavaWeb-XML解析/","excerpt":"Spring的IoC容器支持两种配置文件格式：Properties文件格式和XML文件格式。其中XML格式的容器信息管理方式是Spring提供的最为强大、支持最为全面的方式。","text":"Spring的IoC容器支持两种配置文件格式：Properties文件格式和XML文件格式。其中XML格式的容器信息管理方式是Spring提供的最为强大、支持最为全面的方式。 beans标签beans标签是XML配置文件中最顶层的元素，它下面可以包含0个或1个description标签和多个bean以及import或者alias标签。 相关属性 default-lazy-init：可以指定为true或者false，默认值是false。用来标志是否对所有的bean进行延迟初始化。 default-autowire：可以取值为no、byName、byType、constructor以及autodetect。默认为no，如果使用自动绑定的话，用来标志全体bean使用哪一种默认绑定方式。 default-dependency-check：可以取值none、objects、simple以及all，默认值是none，即不做依赖检查。 default-init-method：如果所有的bean按照某种规则，都有同样名称的初始化方法的话，可以在这里统一指定这个初始化方法名，而不用在每一个bean上都重复指定。 default-destroy-method：与default-init-method属性相对应，如果所有的bean有按照某种规则使用了相同名称的对象销毁方法，可以通过这个属性统一指定。 bean标签 id属性：每个注册到容器的对象都需要一个唯一标识来进行区分。通过id属性来指定当前注册对象的beanName。如果bean标签不存在id属性还可以通过name属性（别名）来指定beanName。 class属性：每个注册到容器的对象都需要通过class属性指定其类型，即通过那个类构建。 depend-on属性：如果没有通过ref标签明确的指定对象A依赖对象B，如果还需要在对象A实例化之前实例化对象B，那么就可以在对象A中指定该属性。 autowire属性：指定自动绑定的模式，对应beans标签的default-autowire属性。 dependency-check属性：指定对其所依赖对象进行检查的级别，对应beans标签的default-dependency-check属性。 lazy-init属性：设置该bean懒加载，对应beans标签的default-lazy-init属性。 parent属性：设置该bean继承设置的bean。可以复用一下属性。 abstract属性：声明为true的时候，说明该bean不需要被实例化。 bean标签的内部标签构造方法注入 - constructor-arg标签 type属性：指定构造方法的参数类型。 index属性：当某个对象的构造方法同时传入多个类型相同的参数时，index可以指定对应参数的顺序。 setter方法注入 - property标签 name属性：指定被注入的对象所对应的实例变量名称。之后通过value或ref属性或者内嵌的其他元素来指定具体的依赖对象的引用或者值。如果只使用property标签进行依赖注入的话，需要保证被注入的对象提供了默认的构造方法。 property和constructor-arg标签中可用的配置项 value标签：可用通过value为主体对象注入简单的数据类型，不但可用指定String类型的数据，还可以指定原始类型与其包装类等。 具体通过PropertyEditor接口的实现类来将字符串转换成对应的类型。其中原生类型及其实现类和Spring自己定义的StringArrayPropertyEditor(String数组，默认逗号分隔)、ClassEditor(Class对象)、FileEditor(File对象)、LocaleEditor(Locale对象)和PatternEditor(Pattern对象)等可以自动进行转换。如果需要自己指定类型时需要使用BeanFactoryPostProcessor接口的CustomEditorConfigurer类来将自己实现的PropertyEditor接口的实现类告知容器。 ref标签：用来引用容器中其他的对象实例。可以通过ref的local、parent和bean属性来指定引用对象的beanName是什么。 local属性：只能指定与当前配置的对象在同一个配置文件的对象定义的名称。 parent属性：只能指定位于当前容器的父容器中定义的对象引用。 bean属性：都可以指定，所以一般直接使用bean来指定对象引用。 idref标签：如果要为当前对象注入依赖的对象的名称，而不是引用可以使用该标签。 内部bean标签：如果我们所依赖的对象只有当前一个对象引用，可以使用内嵌的bean标签。 list标签：对应数组和java.util.List及其子类的依赖对象。 set标签：对应java.util.Set及其子类的依赖对象。 map标签：对应java.util.Map及其子类的依赖对象。 props标签：对应Properties的依赖对象。 null标签：对应null。而&lt;value&gt;&lt;/value&gt;对应的是空字符串。 工厂方法在XML文件中的配置可以使用实现FactoryBean接口或者使用@Bean注解替代。 静态工厂方法123456789public class StaticFactoryMethod &#123; public static IDemo getInstance(Test test) &#123; return new Demo(test); &#125;&#125;// 对应的XML配置&lt;bean id=\"demo\" class=\"...StaticFactoryMethod\" factory-method=\"getInstance\"&gt; &lt;constructor-arg ref=\"test\"/&gt;&lt;/bean&gt; 非静态工厂方法12345678public class NonStaticFactoryMethod &#123; public IDemo getInstance() &#123; return new Demo(); &#125;&#125;// 对应的XML配置&lt;bean id=\"factoryMethod\" class=\"...NonStaticFactoryMethod\"/&gt;&lt;bean id=\"demo\" factory-bean=\"factoryMethod\" factory-method=\"getInstance\"/&gt;","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"SpringMVC","slug":"JavaWeb-SpringMVC","date":"2018-03-20T12:42:35.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2018/03/20/JavaWeb-SpringMVC/","link":"","permalink":"http://yoursite.com/2018/03/20/JavaWeb-SpringMVC/","excerpt":"SpringMVC请求处理流程 用户发起请求到前端控制器(FrontController)。 前端控制器根据用户的URL请求一个或多个处理器映射器(HandlerMapping)，处理器映射器根据XML配置或者注解来进行查找匹配该URL的Handler，并返回给前端控制器。 前端控制器调用处理器适配器(HandlerAdaptor)去执行Handler，并返回一个ModelAndView。 如果ModelAndView中直接返回了具体的View实例，那么，前端控制器将直接从ModelAndView中获取该View并渲染视图。 如果返回的是逻辑视图名，前端控制器将请求视图解析器(ViewResolver)，将逻辑视图名解析成真正的视图。","text":"SpringMVC请求处理流程 用户发起请求到前端控制器(FrontController)。 前端控制器根据用户的URL请求一个或多个处理器映射器(HandlerMapping)，处理器映射器根据XML配置或者注解来进行查找匹配该URL的Handler，并返回给前端控制器。 前端控制器调用处理器适配器(HandlerAdaptor)去执行Handler，并返回一个ModelAndView。 如果ModelAndView中直接返回了具体的View实例，那么，前端控制器将直接从ModelAndView中获取该View并渲染视图。 如果返回的是逻辑视图名，前端控制器将请求视图解析器(ViewResolver)，将逻辑视图名解析成真正的视图。 SpringMVC主要组件 DispatcherServlet：整个框架的前端控制器，负责接收并分发所有Web请求。 HandlerMapping：帮助DispatcherServlet进行Web请求的URL到具体处理类的匹配。 HandlerAdaptor：使用适配器模式屏蔽不同Handler类型给DispatcherServlet造成的困扰。 Controller：SpringMVC框架支持的用于处理具体Web请求的Handler类型之一。 ModuleAndView：包含视图相关内容（可以使逻辑视图名称，也可以是具体的View实例）和模型数据。 ViewResolver：根据Controller所返回的ModuleAndView中的逻辑视图名，返回一个可用的View实例。 View：进行视图渲染，将提供的视图模板和最终提供的模型数据合并到一起，形成最终输出结果页面。 SpringMVC其它组件 文件上传 当Web请求到达DispatcherServlet并等待处理时，DispatcherServlet会先检查能否从自己的WebApplicationContext中找到一个名为multipartResolver的MultipartResolver(位于HandlerMapping之前)实例。 如果获得了该实例，DispatcherServlet将通过该实例的isMultipart(request)方法检测当前web请求是否为multipart类型。 如果是，DispatcherServlet将调用该实例的resolveMultipart(request)方法，并返回一个MultipartHttpServletRequest，否则，直接返回最初的HttpServletRequest。 MultipartHttpServletRequest的getFile(String)方法可以获得一个MultipartFile对象，然后就可以根据具体的业务对MultipartFile进行操作了。 拦截器(HandlerInterceptor) HandlerInterceptor接口中的方法 boolean preHandler(..)：该方法在HandlerAdaptor调用具体的Handler处理Web请求之前执行。返回true表示运行后续流程继续执行；false表示不允许。 void postHandler(..)：HandlerAdaptor调用Handler处理Web请求后，视图的解析和渲染之前执行。通过该方法可以获取Handler执行后的结果，即ModuleAndView。所以该方法可以对ModuleAndView进行添加统一的模型数据、数据变更等操作。 void afterCompletion(..)：在框架整个处理流程结束之后，或者说视图渲染完了的时候，不管是否发生异常，该方法都将被执行。如果处理时异常结束的话，我们可以在该方法中获取异常（Exception）的引用并对其进行统一处理。另外，如果Web请求过程中有相应的资源需要清理的话，也可以在这里完成。 SpringMVC内部实现 UserRoleAuthorizationInterceptor：通过HttpServletRequest的isUserInRole(..)方法，使用指定的一组用户角色(UserRoles)对当前请求进行验证。如果验证不通过将默认返回403状态码，即forbidden。 WebContextInterceptor：1.检查请求方法类型是否在支持的方法之列。如果当前请求的方法类型超出我们通过setSupportedMethods(..)方法指定的范围，那么将抛出HttpRequestMethodNotSupportedException从而阻断后续处理流程；2.检查必要的Session实例。如果我设置了requireSession属性为true，同时又发现当前请求不能返回一个已经存在的Session实例，将会抛出HttpSessionRequiredException阻断后续执行；3.检查缓存时间并通过设置相应的HTTP头(Header)的方式控制缓存行为。 拦截器和过滤器的区别 拦截器是基于Java的反射机制，即使用SpringAOP机制实现，而过滤器是基于函数回调。 拦截器是Spring组件，配置在Spring文件中，可以使用Spring的资源和对象（即拦截器可以获取IoC容器中的各个bean）。 过滤器在Servlet执行前和执行后执行，所以SpringMVC的全局异常处理无法处理过滤器中抛出的异常。 SpringMVC父子容器在Spring整体框架的核心概念中，容器是核心思想，负责管理Bean的整个生命周期。而在一个项目中，容器不一定只有一个，Spring中可以包括多个容器，而且容器有上下层关系，目前最常见的一种场景就是在一个项目中引入Spring和SpringMVC这两个框架，那么它其实就是两个容器，Spring是父容器，SpringMVC是其子容器，并且在Spring父容器中注册的Bean对于SpringMVC容器中是可见的，而在SpringMVC容器中注册的Bean对于Spring父容器中是不可见的，也就是子容器可以看见父容器中的注册的Bean，反之就不行。","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"汇编基础","slug":"基础之汇编基础","date":"2018-01-30T12:34:07.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2018/01/30/基础之汇编基础/","link":"","permalink":"http://yoursite.com/2018/01/30/基础之汇编基础/","excerpt":"寄存器 通用寄存器组(GPRs)：也称数据寄存器，用来存放一般性数据。 段寄存器(16位的寄存器)：CPU根据段寄存器的内容，与寻址方式确定的有效地址一起，并结合其它用户不可见的内部寄存器，生成操作数所在的存储地址。一共有6个，即代码段(CS)、堆栈段(SS)、数据段(DS)和3个附加段(ES、FS、GS)寄存器。 指令指针寄存器(RIP)：用来确认CPU需要执行的下一条指令在指令内存中的地址。 标志寄存器(FLAGS)：用来存储相关指令的某些执行结果；用来为CPU执行相关指令提供行为依据；用来控制CPU的相关工作方式。 程序计数器：CS和IP寄存器指示了CPU当前要读取指令的地址。CS为代码段寄存器，IP为指令指针寄存器。","text":"寄存器 通用寄存器组(GPRs)：也称数据寄存器，用来存放一般性数据。 段寄存器(16位的寄存器)：CPU根据段寄存器的内容，与寻址方式确定的有效地址一起，并结合其它用户不可见的内部寄存器，生成操作数所在的存储地址。一共有6个，即代码段(CS)、堆栈段(SS)、数据段(DS)和3个附加段(ES、FS、GS)寄存器。 指令指针寄存器(RIP)：用来确认CPU需要执行的下一条指令在指令内存中的地址。 标志寄存器(FLAGS)：用来存储相关指令的某些执行结果；用来为CPU执行相关指令提供行为依据；用来控制CPU的相关工作方式。 程序计数器：CS和IP寄存器指示了CPU当前要读取指令的地址。CS为代码段寄存器，IP为指令指针寄存器。 通用目的寄存器：一个x86-64位的中央处理单元（CPU）包含一组16个存储64位值的通用目的寄存器。01 rax -&gt; eax -&gt; ax -&gt; al 02 rbx -&gt; ebx -&gt; bx -&gt; bl 03 rcx -&gt; ecx -&gt; cx -&gt; cl 04 rdx -&gt; edx -&gt; dx -&gt; dl --&gt; 这四个主要用来存放操作数 05 rsi -&gt; esi -&gt; si -&gt; sil 06 rdi -&gt; edi -&gt; di -&gt; dil 07 rbp -&gt; ebp -&gt; bp -&gt; bpl --&gt; 基址指针寄存器： 08 rsp -&gt; esp -&gt; sp -&gt; spl --&gt; 栈指针寄存器：保存着栈顶的元素。 09 r8 -&gt; r8d -&gt; r8w -&gt; r8b 10 r9 -&gt; r9d -&gt; r9w -&gt; r9b 11 r10 -&gt; r10d -&gt; r10w -&gt; r10b 12 r11 -&gt; r11d -&gt; r11w -&gt; r11b 13 r12 -&gt; r12d -&gt; r12w -&gt; r12b 14 r13 -&gt; r12d -&gt; r13w -&gt; r13b 15 r14 -&gt; r14d -&gt; r14w -&gt; r14b 16 r15 -&gt; r15d -&gt; r15w -&gt; r15b 对于生成小于8字节结果的指令，寄存器中剩下的字节有两种可能： 生成1字节和2字节数字的指令会保持剩下的字节不变。 生成4字节数字的指令会把高位4字节置为0。 标志寄存器该寄存器的每一位都有专门的含义，记录特定的信息。其中有6个条件标志和3个控制标志。 CF –&gt; 进位标志，最近的操作使最高位产生了进位。可以用来检测无符号操作的溢出。 在进行无符号运算的时候，它记录了运算结果的最高有效位向更高有效位的进位值。 当两个数据相加时，如两个8位数据：98H + 98H，将产生进位。由于这个进位值在8位数上无法保存，在之前的理解中，只是简单的说这个进位值丢失了。其实CPU在运算的时候，并不丢弃这个进位值，而是记录在该标志位上。 当两个数据做减法的时候，有可能向更高位借位。例如，两个8位数据：97H - 98H，将产生借位，借位后，相当于计算197H - 98H。该标志位也可以用来记录这个借位值。 ZF –&gt; 零标志，最近操作得出的结果为0. 记录相关指令执行后，其结果是否为0。如果结果为0，那么zf = 1,；如果结果不为0，那么zf = 1。 SF –&gt; 符号标志，最近的操作得到的结果为负数。 记录相关指令执行后，其结果是否为负。如果结果为负，那么sf = 1；如果非负，那么sf = 1。 将数据当有符号数来运算的时候，可以通过它来得知结果的正负。如果将数据当做无符号数来运算，SF的值没有意义，虽然相关指令影响了它的值。 OF –&gt; 溢出标志，最近的操作导致一个补码溢出—正溢出或负溢出。 在进行有符号数运算时，如结果超过了机器所能表达的范围，称为溢出。 记录有符号运算的结果是否发生了溢出，发生了溢出，of = 1，没有发生溢出；of = 0。 PF –&gt; 奇偶标志。 AF –&gt; 辅助进位标志。 TF –&gt; 单步标志位。 IF –&gt; 中断允许位。 DF –&gt; 方向位。 指令赋值操作mov s, d --&gt; d = s movb --&gt; 传送字节 movw --&gt; 传送字（一个字等于两个字节） movl --&gt; 传送双字（四字节） movq --&gt; 传送四字（八字节） movabsq --&gt; 传送绝对的四字 C语言中的指针其实就是地址，间接引用指针就是将指针放在一个寄存器中，然后在内存引用中使用这个寄存器；局部变量通常存放在寄存器而不是内存中。 栈操作push s --&gt; 将四字（八字节）压入栈中 ==== subq $8, %rsp movq %rsp, (%rsp) pop s --&gt; 将四字（八字节）弹出 将一个四字压入栈中，首先要将栈指针减8，然后将值写到新的栈顶地址。 算术和逻辑操作（+、—、*、/）inc d -&gt; d = d + 1 -&gt; 加1 dec d -&gt; d = d - 1 -&gt; 减1 neg d -&gt; d = -d -&gt; 取负 not d -&gt; d = ~d -&gt; 取补 add s, d -&gt; d = d + s -&gt; 加 sub s, d -&gt; d = d - s -&gt; 减 imul s, d -&gt; d = d * s -&gt; 乘 xor s, d -&gt; d = d ^ s -&gt; 异或 or s, d -&gt; d = d | s -&gt; 或 and s, d -&gt; d = d &amp; s -&gt; 与 sal k, d -&gt; d = d &lt;&lt; k 左移 shl k, d -&gt; d = d &lt;&lt; k 左移（同sal） sar k, d -&gt; d = d &gt;&gt; k 算术右移 shr k, d -&gt; d = d &gt;&gt; k 逻辑右移 leaq s, d d = &amp;s 加载有效地址 和movq区别： movq (%rdi, %rsi, 4), %rax --&gt; rax等于4 * rsi + rdi所指向的内存的值 leaq (%rdi, %rsi, 4), %rax --&gt; rax等于4 * rsi + rdi leaq指令不改变条件码，因为他是用来进行地址计算的。上面的其他操作都会设置条件码。对于逻辑操作，例如XOR，进位标志和溢出标志会设置为0。对于移位操作，进位标志将设置为最后一个被移出的位，而溢出标志设置为0。INC和DEC指令会设置溢出和零标志，但不会改变进位标志。 比较操作（==、&gt;、&lt;、&gt;=、=&lt;）cmp --&gt; 根据两个操作数之差来设置条件码，除了只设置条件码而不更新目的寄存器之外，cmp指令和sub指令的行为是一样的。 cmp ax, bx ax == bx -&gt; ax - bx = 0 -&gt; zf = 1 ax != bx -&gt; ax - bx != 0 -&gt; zf = 0 ax &lt; bx -&gt; ax - bx 借位 -&gt; cf = 1 ax &gt;= bx -&gt; ax - bx 不借位 -&gt; cf = 0 ax &gt; bx -&gt; ax - bx != 0且不借位 -&gt; cf = 0且zf = 0 ax &lt;= bx -&gt; ax - bx == 0且借位 -&gt; cf = 1且zf = 1 test --&gt; 和and指令行为一样。 跳转操作（if、while、for、switch）jmp .L1 -&gt; 1 -&gt; 直接跳转 jmp *(%rax) -&gt; 1 -&gt; 间接跳转 je/jz .L1 -&gt; zf -&gt; 相等/零 jne/jnz .L1 -&gt; ~zf -&gt; 不相等/非零 js .L1 -&gt; sf -&gt; 负数 jns .L1 -&gt; ~sf -&gt; 非负数 jg/jnle .L1 -&gt; ~(sf ^ of) &amp; ~zf -&gt; 大于(有符号&gt;) jge/jnl .L1 -&gt; ~(sf ^ of) -&gt; 大于或等于(有符号&gt;=) jl/jnge .L1 -&gt; sf ^ of -&gt; 小于(有符号&lt;) jle/jng .L1 -&gt; (sf ^ of) | zf -&gt; 小于或等于(有符号&lt;=) ja/jnbe .L1 -&gt; ~cf &amp; ~zf -&gt; 超过(无符号&gt;) jae/jnb .L1 -&gt; ~cf -&gt; 超过或相等(无符号&gt;=) jb/jnae .L1 -&gt; cf -&gt; 低于(无符号&lt;) jbe/jna .L1 -&gt; cf | zf -&gt; 低于或相等(无符号&lt;=) 过程指令假设过程P调用过程Q，Q执行后返回P： 传递控制：在进入过程Q的时候，程序计数器必须被设置为Q的代码的起始地址，然后返回是，要把程序计数器设置为P中调用Q后面那条指令的地址。 call .L1/*(%rax) -&gt; 将当前的IP或CS和IP压入栈中，然后跳转 ret -&gt; 用栈中的数据修改IP的值，从而实现近转移 retf -&gt; 用栈中的数据修改CS和IP的值，从而实现远转移 传递数据：P必须能向Q提供一个或多个参数，Q必须能向P返回一个值。 x86-64中，可以通过寄存器最多传递6个整型（例如整数和指针）参数。 如果一个函数有超过6个参数，超过6个的部分就要通过栈来传递。 同时对一个局部变量使用地址运算符 &amp; 和当一个局部变量是数组或结构时，会使用栈来传递变量。 分配和释放内存：在开始时，Q可能需要为局部变量分配空间，而在返回时，又必须释放这些空间。 被调用函数需要保存寄存器rbx rbp r12-r15的值，要么不去修改它，要么把原始值压入栈中，并在返回前从栈中弹出旧值。","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"C语言常用函数","slug":"基础之C语言常用函数","date":"2017-12-20T12:29:44.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2017/12/20/基础之C语言常用函数/","link":"","permalink":"http://yoursite.com/2017/12/20/基础之C语言常用函数/","excerpt":"进程控制相关函数1234567891011121314// 获取进程和父进程pidpid_t getpid(void);pid_t getppid(void);// 创建和终止进程pid_t fork(void);void exit(int status);// 等待子进程终止或停止pid_t waitpid(pid_t pid, int *startusp, int options);pid_t wait(int *starusp); // wait函数是waitpid的简单版本// 让进程休眠unsigned int sleep(unsigned int secs);int pause(void);// 在当前进程的上下文中加载并运行一个新程序int execve(const char *filename, const char *argv[], const char *envp[]);","text":"进程控制相关函数1234567891011121314// 获取进程和父进程pidpid_t getpid(void);pid_t getppid(void);// 创建和终止进程pid_t fork(void);void exit(int status);// 等待子进程终止或停止pid_t waitpid(pid_t pid, int *startusp, int options);pid_t wait(int *starusp); // wait函数是waitpid的简单版本// 让进程休眠unsigned int sleep(unsigned int secs);int pause(void);// 在当前进程的上下文中加载并运行一个新程序int execve(const char *filename, const char *argv[], const char *envp[]); 普通IO系统调用1234567int open(const char *pathname, int flags, int perms);int close(int fd);ssize_t read(int fd, void *buf, size_t count);ssize_t write(int fd, void *buf, size_t count);off_t lseek(int fd, off_t offset, int whence);int ioctl(int fd, unsigned long request, ...);int fcntl(int fd, int cmd, ... /* arg */ ); 设置系统的环境变量1234// 获取、添加、删除环境变量char *getenv(const char *name);int setenv(const char *name, const char *newvalue, int overwrite);void unsetenv(const char *name); 字符串相关函数123456789101112// 返回str的长度size_t strlen(const char *str);// 在str所指向的字符串中搜索第一次出现字符c的位置char *strchr(const char *str, int c);// 复制字符c到参数str所指向的字符串的前n个字符void *memset(void *str, int c, size_t n);// 从src拷贝n个字节到destvoid *memcpy(void *dest, const void * src, size_t n);// 从str2中复制n个字符到str1中void *memmove(void *str1, const void *str2, size_t n);// 比较存储区str1和存储区str2的前n个字节int memcmp(const void *str1, const void *str2, size_t n); 内存分配相关函数12345// 在对内存中分配长度为size字节的连续区域void* malloc(unsigned size);// 给一个已经分配了地址的指针重新分配空间，参数ptr为原有的空间地址，newsize是重新申请的地址长度void* realloc(void* ptr, unsigned newsize);void* calloc(size_t numElements, size_t sizeOfElement);","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"C语言基础","slug":"基础之C语言基础","date":"2017-12-19T09:49:45.000Z","updated":"2021-07-03T01:30:27.672Z","comments":true,"path":"2017/12/19/基础之C语言基础/","link":"","permalink":"http://yoursite.com/2017/12/19/基础之C语言基础/","excerpt":"C语言基础基础数据类型 类型 存储大小 值范围 unsigned char 1字节 0到255 char 1字节 -128到127 unsigned int 2或4字节 0到65535或0到4294967295 int 2或4字节 -32768到32787或-2147483648到2147483647 unsigned short 2字节 0到65535 short 2字节 -32768到32767 unsigned long 4字节 0到4294967295 long 4字节 -2147483648到2147483647 float 4字节 1.2E-38到3.4E+38，精度为6位小数 double 8字节 2.3E-308到1.7E+308，精度为15位小数 long double 16字节 3.4E-4932到1.1E+4932，精度为19位小数 ps： 布尔类型可以使用int替代，1为TRUE，0为FALSE。 C语言使用常量来判断是否匹配返回值或信号时，这些常量需要设置为2的n次方。","text":"C语言基础基础数据类型 类型 存储大小 值范围 unsigned char 1字节 0到255 char 1字节 -128到127 unsigned int 2或4字节 0到65535或0到4294967295 int 2或4字节 -32768到32787或-2147483648到2147483647 unsigned short 2字节 0到65535 short 2字节 -32768到32767 unsigned long 4字节 0到4294967295 long 4字节 -2147483648到2147483647 float 4字节 1.2E-38到3.4E+38，精度为6位小数 double 8字节 2.3E-308到1.7E+308，精度为15位小数 long double 16字节 3.4E-4932到1.1E+4932，精度为19位小数 ps： 布尔类型可以使用int替代，1为TRUE，0为FALSE。 C语言使用常量来判断是否匹配返回值或信号时，这些常量需要设置为2的n次方。 逻辑运算符 与(&amp;)是有0则0，全1为1；或(|)是有1为1，全0为0。 异或：相同为0，不同为1。一个整数与自己异或的结果是0，一个整数与0异或的结果是自己，异或操作满足交换律，即a^b=b^a。 GDB调试工具 使用GCC编译时加参数–g，例：gcc tmp01.c –o tmp01 -g。 gdb tmp01 (gdb) l：查看载入的文件(list)。 (gdb) b 6：在第6行处设置断点。 (gdb) info b：查看设置的断点情况。 (gdb) r：开始运行程序，+行号可以从指定行开始运行。 (gdb) p n：查看变量的值。 (gdb) watch n：设置观察点（变量）。 (gdb) n：单步运行(next)。 (gdb) c：程度继续运行(continue)到下一个断点。 C语言变量局部变量和全局变量C语言中所有变量都有自己的作用域，按照作用域的范围可分为局部变量和全局变量。 局部变量也称为内部变量。局部变量是在函数内作定义说明的。其作用域仅限于函数内， 离开该函数后再使用这种变量是非法的。 全局变量也称为外部变量，它是在函数外部定义的变量。 它不属于哪一个函数，它属于一个源程序文件。其作用域是整个源程序。 静态存储和动态存储变量变量的存储方式可分为静态存储和动态存储两种，具体地又分为自动的（auto）、静态的（static）、寄存器的（register）、外部的（extern）。所谓存储方式，即存储类型是指变量占用内存空间的方式。静态存储方式是指在程序运行期间分配固定的存储空间的方式；动态存储方式是在程序运行期间根据需要进行动态的分配存储空间的方式。 auto：在声明局部变量时，若不指定static，默认均是auto，这类变量都是动态分配存储空间的，数据存储在动态存储区中。 static：在声明局部变量时，使用关键字static将局部变量指定为静态局部变量，这样在函数调用结束后不消失而保留原值，在下一次函数调用时，该变量已有值就是上次函数调用结束时的值。当全局变量被static修饰时，该变量的作用域局限于一个源文件内，只能为该源文件内的函数公用， 因此可以避免在其它源文件中引起错误。 extern：用于扩展全局变量的作用域，比如如果函数想引用一个外部变量，但该外部变量在该函数后定义，那么这个函数需要使用extern来声明变量，这样才能使用在该函数后面定义的全局变量。此外，extern还可以在多文件的程序中声明外部变量。 register：寄存器运算速度远高于内存；在声明动态局部变量或者函数形参时，可将变量声明为register，这样编译系统就会为变量分配一个寄存器而不是内存空间，通过这种方式可提升对某些局部变量频繁调用的程序的性能。 C语言程序的开发与执行过程从源程序到可执行程序 代码编写：通过程序编辑软件得到main.c文件。main.c在计算机中以ASCII字符方式存放。 预处理：使用预处理程序（cpp main.c main.i或gcc -E main.c -o main.i）对源程序中以字符#开头的命令进行处理，例如，将#include命令后面的.h文件内容嵌入到源程序文件中,替换define定义的宏。预处理程序输出结果还是一个源程序文件。 编译：编译程序（cc1 main.i或gcc -S main.i -o main.s）对预处理后的源程序进行编译，生成一个汇编语言源程序文件，同时生成符号和符号表。 汇编：汇编程序（as main.s -o main.o或gcc -c main.s -o main.o）对汇编语言源程序进行汇编，生成一个可重定位目标文件。该文件是一个二进制文件，因为其中的代码已经是机器指令，数据以及其它信息都是用二进制表示。 链接：链接程序（ld -o main main.o sum.o或gcc -o main main.o sum.o）将多个可重定位目标文件和标准库函数合并成为一个可执行目标文件，简称可执行文件。 可重定位目标文件的链接链接可以在编译时执行，也就是源代码被翻译成机器代码时；也可以在加载时执行，也就是程序被加载器加载到内存并执行时；甚至可以在运行时执行，也就是由应用程序来执行。 静态链接：以一组可重定位目标文件和命令行参数作为输出，生成一个完全链接的、可以加载和运行的可执行目标文件作为输出。 动态链接：在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。 链接操作的步骤 符号解析：将每个符号引用和一个符号定义关联起来。每个符号对应一个函数、一个全局变量或一个静态变量。 重定位：编译器和汇编器生成从地址0开始的代码和数据节。链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得他们指向这个内存位置。 静态库与共享库 将所有相关的目标模块打包成一个单独的文件(扩展名.a)，该文件称为静态库。当链接器构造一个可执行文件时，只复制静态库里面被应用程序引用的目标模块。静态库的存在使得我们在链接时不需要指定系统定义的大量标准函数的可重定位目标文件。 静态库的问题： 静态库在更新是需要手动重新链接，即每次操作系统升级都需要重新链接所有的软件。 使用标准库函数(例如标准I/O)时需要复制这些库函数的代码到可执行目标文件的文本段，运行时会浪费内存。 而共享库(.so文件)可以在启动或运行时被动态链接，被链接的库函数的代码不会被复制到可执行目标文件，而是复制了一些重定位条目和符号表。 可执行目标文件的加载 Linux系统中的每一个都运行在一个进程上下文中，有自己的虚拟地址空间。当shell运行一个程序时，父shell进程生成一个子进程，他是父进程的一个复制。 子进程通过execve系统调用启动加载器。 加载器删除子进程现有的虚拟内存段，同时根据可执行文件的程序（段）头表中的信息，将可执行文件的代码和数据从磁盘”拷贝”到存储器中（实际上并不会真正的拷贝，而是建立一种映射）并创建一组新的代码、数据、堆和栈段。新的栈和堆段被初始化为零。 通过将虚拟地址空间中的页映射到可执行文件的页大小的片，新的代码和数据段被初始化为可执行文件的内容。 加载后，将PC（RIP）设定执行Entry point（即符号_start处），调用应用程序的main函数。 可执行文件的启动与执行在Linux操作系统中，一般通过shell脚本执行可执行程序。即输入./hello并回车。 shell程序会将用户从键盘输入的每个字符逐一读入到CPU寄存器中，然后保存到主内存中，在主内存的缓冲区形成字符串”./hello”。 收到[Enter]按键时，shell将调出操作系统内核中相应的服务例程，由内核来加载磁盘上的可执行文件hello到存储器。 内核加载完可执行文件中的代码及其所要处理的数据后，将hello的第一条指令的地址送到程序计数器（简称PC）中。 处理器开始执行hello程序。 进程中的内存布局进程刚被创建的时候Program break位于Data Segment的结束位置。当进行堆内存分配时，会调用brk和sbrk来改变Program break的位置。其中brk通过传递的addr来重新设置Program break，成功则返回0，否则返回-1。而sbrk用来增加heap，增加的大小通过参数increment决定，返回增加大小前的heap的Program break，如果increment为0则返回当前Program break。 数据段(initialized)：存储已经初始化的全局和静态变量。 BSS段(uninitialized)：未初始化的全局变量和静态变量，并不会给该段的数据分配空间，只是记录一下大小。 代码段(Test Segment)：只能读取，存放的是程序的全部代码（指令），来源于二进制可执行文件中的代码部分，也有可能包含一些只读常量(.rodata)，可以被多进程共享。 反编译工具 size a.out：显示一个目标文件或者链接库文件中的目标文件的各个段的大小，当没有输入文件名时，默认为a.out。 objdump -S a.out：反汇编目标文件或者可执行文件，输出C源代码和反汇编出来的指令对照的格式。 构建一个内存分配器内存分配器将堆视为一组不同大小的块的集合，每个块都是一个连续的虚拟内存片。要么是已分配，要么是未分配。 构建一个空闲链表存放空闲块，其中隐式空闲链表是通过空闲块头部的块大小字段隐含链接的。下图是一个隐式空闲链表的块和其链接形式： 搜索空闲块：查找一个足够大可以放置请求块的空闲块(首次适配、最佳适配、下一次适配等)。 查找到空闲块后将空闲块分割为合适的大小。 当空闲链表上所有空闲块都不满足要求时，使用sbrk请求堆内存。 释放内存时将相邻的空闲块合并为一个大的空闲块。","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://yoursite.com/tags/计算机基础/"}]},{"title":"Spring注解","slug":"JavaWeb-Spring注解","date":"2017-11-26T03:34:14.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2017/11/26/JavaWeb-Spring注解/","link":"","permalink":"http://yoursite.com/2017/11/26/JavaWeb-Spring注解/","excerpt":"注解本身没有功能，和xml一样是一种元数据；元数据是解释数据的数据，即配置。","text":"注解本身没有功能，和xml一样是一种元数据；元数据是解释数据的数据，即配置。 声明bean的注解 @Component：无明确角色，下面三个由它实现。 @Controller：控制层bean。 @Service：业务逻辑层bean。 @Repository：数据访问层bean。 注入bean的注解 @Autowired：由Spring提供。 @Resource：由JSR-250提供。 @Qualifier(“userServiceImpl”)：当一个接口有多个实现类时，用来指明注入那个实现类。 @Required：此注解用于bean的setter方法上，表示此属性是必须的，必须在配置阶段注入，否则会抛出BeanInitializationExcepion。 @Autowired和@Resource区别和联系： 都可以用来装配bean。都可以写在字段上或者setter方法上。 @Autowired默认按类型装配，默认情况下要求依赖对象必须存在，如果需要允许null值，可以设置它的required属性为false。如果我们想使用名称装配可以结合@Qualifier注解进行使用。 @Resource默认按名称装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时默认取字段名，按照名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是如果name属性被指定，就只会按照名称进行装配。 @Inject：由JSR-330提供。 Spring配置类相关注解 @Configuration：声明当前类为配置类，相当于xml里面beans标签（类上）。 @Bean：声明当前方法的返回值为一个bean，相当于xml中的方式bean标签（方法上）。 @ComponentScan：用于对Component进行扫描，相当于xml中的&lt; context:component-scan base-package=”my.web”/&gt;（类上）。 @WishlyConfiguration：@Configuration与@ComponentScan的组合注解，可以替代这两个注解。 @Scope：设置bean的作用域。 singleton(默认)：一个容器中只有一个实例，容器销毁是才会被销毁。 protetype：每次都重新生成一个新的对象实例给请求方。即容器并不维护该类型对象的实例。 request：为每个HTTP请求创建一个新的对象实例(Web项目)。 session：为每个独立的session创建属于它们自己的对象实例(Web项目)。 globalSession：它会映射到portlet的global范围的session。如果在普通的基于servlet的Web应用中使用了这个类型的scope，容器会将其作为普通的session类型的scope对待(基于portlet的Web项目)。 @PostConstruct：由JSR-250提供，在构造函数执行完之后执行，相当于xml配置文件中bean的initMethod和InitializingBean接口。 @PreDestory：由JSR-250提供，在Bean销毁之前执行，相当于xml配置文件中bean的destroyMethod和DisposableBean接口。 AOP相关注解Spring支持AspectJ的注解式切面编程。可以使用@EnableAspectJAutoProxy注解开启Spring对AspectJ代理的支持。 @Aspect声明一个切面（类上）。 @PointCut声明切点（方法上）。 使用@After、@Before、@Around定义建言（advice），可直接将拦截规则（切点）作为参数。 @After在方法执行之后执行（方法上）。 @Before在方法执行之前执行（方法上）。 @Around在方法执行之前与之后执行（方法上）。 @Value为属性注入值// 注入普通字符 @Value(&quot;Michael Jackson&quot;) String name; // 注入操作系统属性 @Value(&quot;#{systemProperties[&apos;os.name&apos;]}&quot;) String osName; // 注入表达式结果 @Value(&quot;#{ T(java.lang.Math).random() * 100 }&quot;) String randomNumber; // 注入其它bean属性 @Value(&quot;#{domeClass.name}&quot;) String name; // 注入文件资源 @Value(&quot;classpath:com/hgs/hello/test.txt&quot;) String Resource file; // 注入网站资源 @Value(&quot;http://www.cznovel.com&quot;) Resource url; // 注入配置文件 @Value(&quot;${book.name}&quot;) String bookName; @ConfigurationProperties为属性注入值@Configuration @ConfigurationProperties(value = &quot;classpath:mail.properties&quot;, ignoreUnknownFields = false, prefix = &quot;mail&quot;) // ignoreUnknownFields：告诉SpringBoot在有属性不能匹配到声明的域的时候是否抛出异常，默认是ture，不抛异常。 public class MailConfiguration { @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; } 环境切换 @Profile通过设定Environment的ActiveProfiles来设定当前context需要使用的配置环境，即通过配置来改变参数，例如开发和生产使用不同的配置（类或方法上）。 @Conditional：Spring4中可以使用此注解定义条件话的bean，通过实现Condition接口，并重写matches方法，从而决定该bean是否被实例化（方法上）。 异步相关 @EnableAsync 配置类中，通过此注解开启对异步任务的支持，叙事性AsyncConfigurer接口（类上）。 @Async在实际执行的bean方法使用该注解来申明其是一个异步任务（方法上或类上所有的方法都将异步，需要@EnableAsync开启异步任务）。 定时任务相关 @EnableScheduling在配置类上使用，开启计划任务的支持（类上）。 @Scheduled来申明这是一个定时任务（方法上，需先开启计划任务的支持）。 cron：cron表达式 fixedDelay：上一个任务完成后，多少毫秒后再执行下一个任务。 fixedRate：上一个任务开启后，多少毫秒后再执行下一个任务。 @Enable*主要用来开启对xxx的支持。 @EnableAspectJAutoProxy开启对AspectJ自动代理的支持。 @EnableScheduling开启计划任务的支持。 @EnableWebMvc开启Web MVC的配置支持。 @EnableConfigurationProperties 开启对@ConfigurationProperties注解配置Bean的支持。 @EnableJpaRepositories开启对SpringData JPA Repository的支持。 @EnableTransactionManagement开启注解式事务的支持。 @EnableCaching开启注解式的缓存支持。 SpringBoot测试相关注解@RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = Application.class) public class RedisTest { } SpringBoot相关注解// @SpringBootApplication注解等价于以默认属性使用 @Configuration、@EnableAutoConfiguration和@ComponentScan @SpringBootApplication // @EnableAutoConfiguration注解告诉SpringBoot“猜”你将如何想配置Spring,基于你已经添加jar依赖项。如果spring-boot-starter-web已经添加Tomcat和SpringMVC,这个注释自动将假设您正在开发一个web应用程序并添加相应的spring设置。 @EnableTransactionManagement public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } }","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"AQS源码分析","slug":"Java高级特性之AQS源码分析","date":"2017-11-02T06:42:13.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/11/02/Java高级特性之AQS源码分析/","link":"","permalink":"http://yoursite.com/2017/11/02/Java高级特性之AQS源码分析/","excerpt":"AQS原理浅析，AQS的全称为（AbstractQueuedSynchronizer），是java.util.concurrent.locks包下面的一个抽象类。ReentrantLock/Semaphore/CountDownLatch等都是该类的子类。该类实现了锁升级（即由轻量级锁到重量级锁的过程）、锁自旋等逻辑。","text":"AQS原理浅析，AQS的全称为（AbstractQueuedSynchronizer），是java.util.concurrent.locks包下面的一个抽象类。ReentrantLock/Semaphore/CountDownLatch等都是该类的子类。该类实现了锁升级（即由轻量级锁到重量级锁的过程）、锁自旋等逻辑。下面以ReentrantLock的非公平锁为依托分析AQS源码。 获取锁Img1调用本类的静态内部类NonfairSync的lock()方法。NonfairSync继承了Sync抽象类，而Sync抽象类是AbstractQueuedSynchronizer类的子类。 Img2Img2.1.如果state状态位为0，即当前没有线程持有该锁。则使用CAS将state状态位设置为1，并把该锁的持有线程设置为当前线程。Img2.2.如果已经有线程持有该锁则调用AbstractQueuedSynchronizer类的acquire(int)方法。 Img3Img3.1.使用模板方法模式调用子类NonfairSync的tryAcquire(int acquires)方法。 Img4调用父类Sync的nonfairTryAcquire(int acquires)方法。 Img5Img5.1.重复Img2.1的逻辑。Img5.2.如果请求该锁的是之前持有该锁的线程，则进行一个可重入操作，即将state状态位加1。Img5.3.如果不是，则说明存在锁竞争。接着走Img3.2的逻辑。Img3.2.调用本类的acquireQueued(final Node node, int arg)方法。其中addWaiter(Node mode)方法用于将当前线程加入到等待队列的对尾，并返回当前线程所在的节点。 Img6Img6.1.自旋锁。Img6.2.如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源。Img6.3.拿到资源后，将head指向该结点。所以head所指的标杆结点，就是当前获取到资源的那个结点或null。Img6.4.此处再将head.next置为null，就是为了方便GC回收以前的head结点。Img6.5.调用本类的shouldParkAfterFailedAcquire(Node pred, Node node)方法判断当前线程是否可以wait。Img6.6.如果可以wait则在线程找好安全休息点后，进入wait状态。Img6.7.将interrupted设置为true，即中断过。那么就可以走到Img3.3。Img3.3.如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 释放锁Img7调用AbstractQueuedSynchronizer类的release(int arg)方法。 Img8模板方法模式调用子类的tryRelease(int releases)方法。 Img9Img9.1.如果该线程完全释放了锁，则将锁持有的线程设置为null。Img9.2.设置标志位，每次减1，即退出可重入锁。","categories":[],"tags":[{"name":"Java高级特性","slug":"Java高级特性","permalink":"http://yoursite.com/tags/Java高级特性/"}]},{"title":"Spring工具类","slug":"JavaWeb-Spring工具类","date":"2017-10-19T09:25:11.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2017/10/19/JavaWeb-Spring工具类/","link":"","permalink":"http://yoursite.com/2017/10/19/JavaWeb-Spring工具类/","excerpt":"StringUtils","text":"StringUtils isEmpty：判断字符串是否为空，如果为nul或者””则返回true，否则返回false hasLength：判断字符串是否有长度，不等于null同时长度大于0，则为true，这里重载两个hasLength方法，其中CharSequence是String的父类，是接口 hasText：如果为空则直接返回false，如果字符串中有一个不是空白，则表示有内容，返回true containsWhitespace：判断字符串是否包含空白，如果为空则直接返回false，遍历字符序列，如果其中有一个字符是空白，则返回true，如果都不是，返回false trimWhitespace：去除字符串前后的空白 trimAllWhitespace：去除字符串所有空白 trimLeadingWhitespace：去除前导空白，只取空白的前一部分 trimTrailingWhitespace：去除后导空白,取去除空白后一部分 trimLeadingCharacter(String str, char leadingCharacter)：删除前导为leadingCharacter的字符 trimTrailingCharacter(String str, char trailingCharacter)：删除后导字符trailingCharacter startsWithIgnoreCase(String str, String prefix)：忽略大小写，判断字符串是否以prefix开始 endsWithIgnoreCase(String str, String suffix)：忽略大小写，判断源字符串str是否以suffix结尾，处理逻辑类似上一个方法 ObjectUtils containsElement(Object[] array, Object element)：判断element是否属于array isArray(Object obj)：判断obj是不是数组 isCheckedException(Throwable ex)：判断一个异常是不是受检异常 isEmpty(Object obj)：判断一个对象是否为null isEmpty(Object[] array)：判断一个数组是否为null或长度为0 toObjectArray(Object source)：将一个数组对象转化成obj数组 BeanUtils copyProperties(java.lang.Object dest,java.lang.Object orig)：将两个具有很多相同属性的JavaBean，进行set/get转换，一般应用就是po和vo的转换。 ResourceUtils 从指定的地址加载文件资源。1234File clsFile = ResourceUtils.getFile(\"classpath:conf/file1.txt\"); System.out.println(clsFile.isFile()); String httpFilePath = \"file:D:/masterSpring/chapter23/src/conf/file1.txt\"; File httpFile = ResourceUtils.getFile(httpFilePath); FileCopyUtils copy：将一个文件或者二进制数组拷贝到另一个文件中 copyToByteArray：将一个文件转成二进制数组 copyToString：将一个文件转成String Assert notNull(Object object)：当object不为null抛出异常，isNull则是当object为null时抛出异常 isTrue(boolean expression)：当expression不为true抛出异常 hasLength(String text)：当 text 为 null 或长度为 0 时抛出异常 hasText(String text)：text不能为null且必须至少包含一个非空格的字符，否则抛出异常 notEmpty(Collection&lt;?&gt; collection)：当集合未包含元素时抛出异常 notEmpty(Object[] array)：当数组为null，或未包含元素时抛出异常 noNullElements(Object[] array)：当数组中有null元素时抛出异常 isInstanceOf(Class&lt;?&gt; clazz, Object obj)：如果obj不能被正确造型为clazz指定的类将抛出异常 isAssignable(Class&lt;?&gt; superType, Class&lt;?&gt; subType)：subType必须可以按类型匹配于superType，否则将抛出异常","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"Java对象的创建","slug":"Java高级特性之对象的创建","date":"2017-10-18T13:03:58.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/10/18/Java高级特性之对象的创建/","link":"","permalink":"http://yoursite.com/2017/10/18/Java高级特性之对象的创建/","excerpt":"对象创建时机 使用new关键字创建对象； 使用反射创建对象：即使用Class类的newInstance方法、Constructor类的newInstance方法等创建对象； 使用Clone方法创建一个对象：无论何时我们调用一个对象的clone方法，JVM都会帮助我们创建一个新的、一样的对象，且该对象的创建过程中并不会调用任何构造函数。 使用反序列化机制创建对象：当我们反序列化一个对象时，JVM会给我们创建一个单独的对象，且JVM并不会调用任何构造函数。","text":"对象创建时机 使用new关键字创建对象； 使用反射创建对象：即使用Class类的newInstance方法、Constructor类的newInstance方法等创建对象； 使用Clone方法创建一个对象：无论何时我们调用一个对象的clone方法，JVM都会帮助我们创建一个新的、一样的对象，且该对象的创建过程中并不会调用任何构造函数。 使用反序列化机制创建对象：当我们反序列化一个对象时，JVM会给我们创建一个单独的对象，且JVM并不会调用任何构造函数。 对象的创建过程 类加载：虚拟机遇到new指令时，根据这个指令的参数去常量池中定位一个类的符号引用。并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有那必须先执行相应的类加载过程。 内存分配：对象所需要的内存大小在类加载完成后便可以直接确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。 初始化：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）。 虚拟机对对象进行必要的设置，例如这个对象是哪个类的实例、如果才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象头中。根据虚拟机当前的运行状态不同，如是否设置偏向锁等，对象头会有不同的设置方式。 实例变量初始化和实例代码块初始化(目前所有实例变量都还为零)：在程序中可以直接对实例变量进行赋值或者使用实例代码块对其进行赋值。实际上使用上面两种方式编译器会将代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后，构造函数本身的代码之前。 执行＜init＞方法，把对象按照程序员的意愿进行初始化，即进行构造函数初始化。 进行内存分配的方法 指针碰撞：假设Java堆中内存是绝对完规整的，所有用过的内存都放在一边，空闲的内存都放在另一边，中间放着一个指针作为分界点的指示器，那所分配的内存就仅仅是把那个指针向空闲空间挪动一段与对象大小相等的距离。 空闲列表：如果Java堆中的内存不是规整的，已使用的内存和空闲的内存相互交错，虚拟机需要维护一个列表，记录上哪些内存块是可用的，在分配内存的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。 进行内存分配时遇到的问题 并发问题：即可能出现正在给对象A分配内存，指针还没来的及修改，对象B又同时使用了原来的指针来分配内存的问题。 解决办法 对内存空间的动作进行同步处理（实际上虚拟机采用CSA配上重试的方式保证更新操作的原子性）。 把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一块小的内存，成为本地线程分配缓冲（Thread Local Allocation Buffer TLAB），哪个线程分配内存，就在哪个线程的TLAB上分配，只有TLAB用完需要获取新的空间时（不常见），才需要同步锁定。 对象的内存划分对象头 存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，官方称它为Mark Word； 存储类型指针，即对象指向方法区对象类型数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。如果是数组对象的话，还会额外存储数组的长度。 实例数据这部分存储的是对象的真正的有效信息，即程序代码中定义的各种类型的字段内容。 对齐填充HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，对象头部分正好是8字节的倍数，因此，当对象实例数据部分不是8字节的整数倍时，就需要通过对齐填充来补全。 栈对堆中的对象的访问定位Java程序需要通过栈上的引用数据来操作堆上的具体对象。由于引用类型在Java虚拟机规范中值规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所有对象访问方式取决于虚拟机实现。 直接指针：栈中的引用类型存储的就是对象在堆上的地址。 使用句柄进行定位：Java堆中将会划分出一块内存来作为句柄池，栈中存储的就是对象的句柄地址。而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 对象在堆中的分配与回收 如果启动了本地线程分配缓存，将按线程优先在TLAB上分配。而在大多数情况下，对象在新生代Eden区中分配。当该区中没有足够的空间进行分配时，虚拟机将进行一次Minor GC。虚拟机提供了-XX:+PrintGCDetails这个收集器日志参数，告诉虚拟机在发生垃圾收集行为是打印回收日志。 对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。Survivor又分为Form和To区，它们是两块一模一样的内存区域；即使用复制算法将每次Minor GC后仍然存活的对象移动到另一端，然后清空该区域。 对象进入老年代的条件 大对象直接在老年代初始化，大对象是指需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组。大于-XX:PretenureSizeThreshold参数的值的对象直接在老年代分配。 对象在Survivor区中每活过一次Minor GC年龄+1，当它的年龄增加到一定程度（默认是15岁），就被移动到老年代中。可以通过参数-XX:MaxTenuringThreshold设置。 在Survivor区中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。 空间分配担保 IBM公司的专门研究表明，新生代中的对象98%都活不过第一次垃圾回收，所以新生代中Eden空间远大于两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收是，将Eden和Survivor中还存活的对象一次性复制到另一块Survivor空间上，然后清理掉Eden和刚刚用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor比例是8:1。当Survivor空间不够用是，需要依赖其它内存进行分配担保。 在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可用确保是安全的。不过不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用连续空间是否大于历次晋升老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这才Minor GC是有风险的；如果小于或者HandlePromotionFailure设置值不允许冒险，那么就改为进行一次Full GC。 风险是指当Minor GC后仍然有大量的对象存活，Survivor无法容纳的对象需要直接进入老年代，如果老年代也没有足够的空间，还是需要一次Full GC。相当于多进行了一次Minor GC。","categories":[],"tags":[{"name":"Java高级特性","slug":"Java高级特性","permalink":"http://yoursite.com/tags/Java高级特性/"}]},{"title":"Java虚拟机","slug":"Java高级特性之Java虚拟机","date":"2017-09-30T00:58:38.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/09/30/Java高级特性之Java虚拟机/","link":"","permalink":"http://yoursite.com/2017/09/30/Java高级特性之Java虚拟机/","excerpt":"内存模型相关概念缓存一致性问题为了弥补处理器和内存运算速度的巨大差异，现代计算机都会加入一层读写速度接近处理器运算速度的高速缓存。将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步会内存中。所以在多处理器系统中，因为每个处理器都有自己的高速缓存，而它们又共享同一主存。当它们的运算任务都涉及同一块主内存区域是，可能导致各自缓存数据不一致。","text":"内存模型相关概念缓存一致性问题为了弥补处理器和内存运算速度的巨大差异，现代计算机都会加入一层读写速度接近处理器运算速度的高速缓存。将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步会内存中。所以在多处理器系统中，因为每个处理器都有自己的高速缓存，而它们又共享同一主存。当它们的运算任务都涉及同一块主内存区域是，可能导致各自缓存数据不一致。 Java内存分析工具使用 top -Hp [pid]：查看进程中的线程情况。 jps：虚机机进程信息查看。 jinfo [pid]：查看Java进程的配置信息。 jstat -gcutil [pid] 1000 1000：查看gc回收情况，每一秒查询一次查询1000次。 jmap -heap [pid]：查看堆内存占用情况。 jmap -histo [pid]：查看堆里面的对象信息。 jstack [pid]：查看线程栈内对象情况。 内存重排序同时为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。 缓存一致性解决办法 通过在总线加锁的方式； 加锁会阻塞其他CPU对该部件（如内存）的访问，从而使得只有一个CPU能够使用该变量的内存。 锁住总线期间，其他CPU无法访问内存，导致效率低下。 通过缓存一致性协议。 如MESI协议，该协议保证了每个缓存中使用的共享变量的副本是一致的。 即当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 Java内存模型Java内存模型规定了所以的变量都存储在主内存中(对应主内存)；同时每条线程还有自己的工作内存(对应高速缓存)，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 先行发生原则如果操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，影响包括修改了内存中共享变量的值、发送了消息、调用了方法等。 Java内存模型中天然的先行发生关系 程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。 管程锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。 传递性：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。 对象终结规则：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。 JVM内存划分程序计数器 – 对应操作系统里的TCB 程序计数器可以看做是当前线程锁执行的字节码的行号指示器。即记录了Java虚拟机正在执行的字节码指令的地址。 在虚拟机概念模型中（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器就是通过改变计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要这个计数器来完成。 为了线程切换后能恢复到正确的执行位置，每条线程都有一个独立的程序计数器，各个计数器之间互不影响，独立存储。 如果线程正在执行一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器为空。 虚拟机栈 – 在HotSpot虚拟机中虚拟机栈和本地方法栈合二为一每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。栈里存在一个或多个栈帧，每个方法从调用开始执行到执行完成的过程，都对应一个栈帧在虚拟机栈里面从入栈到出栈的过程。 局部变量表：用于存放方法参数和方法内部定义的局部变量，局部变量表中可以存储八种基本数据类型和对象的引用。 操作数栈：一个后入先出的栈。操作数栈的每一个元素都可以是任意的Java数据类型；当方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中会有各种字节码指令在操作数栈中写入和提取内容，也就是出栈和入栈操作。例如，进行算术运算需要使用操作数栈，同时调用其他方法也是通过使用操作数栈进行参数传递的。 动态链接：每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接。 方法返回地址：方法正常退出时，调用者的PC计数器的值可以作为返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址要通过异常处理表来确定，栈帧一般不会保存这部分信息。 方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能只需的操作有：恢复上层方法的局部变量表和操作数栈；把返回值（如果有）压入调用者栈帧的操作数栈中；调用PC计数器的值以指向方法调用指令后面的一条指令等。 附加信息：虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧中，例如调试信息。 Java堆Java堆是Java虚拟机所管理的内存中最大的一块。它被所有的线程共享，在虚拟机启动时从创建。此内存的唯一目的就是存放对象实例。它也是垃圾收集器管理的主要区域，从内存回收的角度来看，由于现在的收集器基本都是使用分代收集算法，所以Java堆可以划分为新生代和老年代。其中新生代又分为Eden区和Survivor区。从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。 方法区方法区是JVM规范中的一个概念。它和堆一样是各个线程共享的内存区域，用于存储类信息、常量池、静态变量和JIT编译后的代码等数据。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫非堆。其中HotSpot虚拟机使用永久代来实现方法区，这样HotSpot的垃圾收集器可以想管理Java堆一样管理这部分内存。方法区的内存回收主要针对常量池和对类型的卸载。 在Java6中，除了JIT编译生成的代码存放在本地内存的CodeCache区域，其他都存放在永久代； 在Java7中，Symbol的存储从PermGen移动到了Native Memory，并且把静态变量从instanceKlass末尾（位于PermGen内）移动到了java.lang.Class对象的末尾（位于普通Java heap内）； 在Java8中，永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存——元空间（Metaspace）。 运行时常量池运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容在类加载后进入方法区的运行时常量池中存放。一般来说，翻译除了的直接引用也存储在运行时常量池中。 字面量：比较接近于Java语言层面的常量的概念，如文本字符串、声明为final的常量值等。 符号引用：属于编译原理方面的概念，包括：1.类和接口的全限定名；2.字段的名称和描述符；3.方法的名称和描述符。 JVM垃圾收集判断对象是否死亡 引用计数法：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。 相互引用时无法回收垃圾，如对象objA和objB都有字段instance，赋值令objA.instance=objB及objB.instance=objA，永远不会回收这两个对象，虽然这两个对象已经无用了。 可达性分析：通过一系列称为GC Roots的对象作为起始点，从这些节点向下搜索，搜索走过的路径成为引用链，当一个对象到GC Roots没有任何引用链时，判断该对象可回收。 在Java语言中，可作为GC Roots的对象有虚拟机栈（栈帧中的本地变量表）中引用的对象、方法区中类静态属性引用的对象（即static成员变量引用的对象）、方法区中常量引用的对象、本地方法栈中JNI（即一般说的Native方法）引用的对象。 引用的四种方式 强引用是指在程序代码之中普遍存在的，类似Object obj = new Object()这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用是用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK1.2之后，提供了SoftReference类来实现软引用。 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK1.2之后，提供了WeakReference类来实现弱引用。 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。在JDK 1.2之后，提供了PhantomReference类来实现虚引用。 分代垃圾收集分代垃圾收集算法基于以下两个观察事实（弱分代假设），如果不符合该假设，分代垃圾收集只会增加更多的开销，不过在实践中这样的引用很少。 大多数分配对象的存活时间很短。 存活时间久的对象很少引用存活时间短的对象。 Minor GC 在进行新生代垃圾收集时垃圾收集器不需要扫描整个（可能比新生代更大）老年代就能识别新生代中的存活对象，从而缩短Minor GC时间。HotSpot VM的垃圾收集器使用卡表的数据结构来达到这个目的。老年代以512字节为快划分为若干张卡。卡表是个单字节数组，每个数组元素对应一张卡。每次老年代对象中某个引用新生代的字段发生变化时，HotSpot VM就必须将该卡所对应的卡表元素设置为适当的值，从而将该引用字段所在的卡标记为脏。在Minor GC过程中，垃圾收集器只会在脏卡中扫描查找老年代-新生代引用。 HotSpot VM的字节码解释器和JIT编译器使用写屏障来维护卡表。写屏障是一小段将卡设置为脏的代码。解释器每次执行更新引用的字节码是，都会执行一段写屏障；JIT编译器在生成更新引用的代码后，也会生成一段写屏障。虽然写屏障使得应用线程增加了一下性能开销，但Minor GC变快了许多，整体的垃圾收集效率也提高了许多，通常应用的吞吐量也会有所改善。 垃圾回收算法 标记清除法：首先标记所有需要被回收的对象，在标记完成后统一回收所有被标记的对象。 复制算法：将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 标记整理法：标记过程和标记清除法一样，但是标记完不直接清除，而是让所有存活的对象向一端移动，然后直接清除掉端边界以外的内存。 垃圾收集器 Serial收集器(新生代)：单线程收集器，Client模式下默认新生代收集器。 Serial Old收集器(老年代)：使用标记整理算法的单线程收集器，一般用做CMS收集器的后备预案。 ParNew收集器(新生代)：Serial的多线程版本，一般和CMS收集器配合使用。 Parallel Scavenge收集器(新生代)：多线程、高吞吐量的收集器，主要适合后台运算不需要太多交互的任务。 Parallel Old收集器(老年代)：和Parallel Scavenge配合的收集器，使用标记整理算法的并发收集器，在注重吞吐量以及CPU资源敏感的场合，优先考虑二者的组合。 CMS收集器(老年代)：基于标记清除算法的以获取最短回收停顿时间为目标的并发收集器，每个垃圾收集周期只有两次短的停顿，目前应用于大部分B/S系统的服务器端上。 G1收集器(通用)：基于标记整理算法的并发的增量式压缩低停顿的面向服务器端的垃圾收集器，目标是替换CMS。 回收方法区在永久代，即HotSpot虚拟机的方法区实现中垃圾收集主要回收废弃的常量和无用的类。 废弃的常量如果一个字符串“abc”已经进入常量池中，但是当前系统没有任何一个String对象叫做“abc”，即没有任何String对象引用常量池中的“abc”常量，如果这时发生内存回收，且必要的话，这个“abc”常量就会被系统清理出常量池。 无用的类 该类所以的实例都已经被回收，即Java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 满足上述三个条件的类可以被虚拟机回收，但并不必然被回收。 JVM类加载机制在Java语言中，类的生命周期包括加载、连接、初始化、使用和卸载五个阶段；其中连接又分为验证、准备和解析三个阶段。而类的加载、连接和初始化都是在程序运行期间(而不是编译期)完成的。 加载 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据访问的入口。 数组类本身不通过类加载器创建，而是由Java虚拟机直接创建。 java.lang.Class类的对象并没有明确规定是在Java堆中。对于HotSpot虚拟机而言，Class虽然是对象，但是存放在方法区中。 连接 验证：确保Class文件的字节流中包含的信息符合当前虚拟机的要求， 并且不会危害虚拟机自身安全。 准备：正式为类变量分配内存并设置类变量初始值，这些变量所使用的内存都将在方法区中进行分配。 解析：虚拟机将常量池内的符号引用替换为直接引用。 符号引用：以一组符号来描述所引用的目标，符号可以使任何形式的字面量，只要使用时能无歧义地定位到目标即可。 直接引用：直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。 初始化 – 静态变量初始化和执行静态代码块 初始化阶段是执行类构造器clinit()方法的过程。 clinit()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块(static{}块)中的语句合并产生的，编译器收集的顺序是由语句在原文件中出现的顺序所决定的。静态语句块中只能访问定义在静态语句块之前的变量，定义在静态语句块之后的变量，在静态语句块中可以赋值，但是不能访问。 clinit()方法和类的构造函数不同，它不需要显式的调用父构造器，虚拟机会保证子类的clinit()方法执行之前，父类的clinit()方法已经执行完毕。 由于父类的clinit()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的类变量赋值操作。 clinit()方法对于类和接口来说并不是必须的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成clinit()方法。 接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成clinit()方法。但执行接口的clinit()方法并不需要先执行父接口的clinit()方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。同时接口的实现类被初始化时也一样不会执行接口的clinit()方法。 虚拟机会保证一个类的clinit()方法在多线程环境中被正确的加锁、同步，如果多个线程同时去初始化一个类，那么只有一个线程去执行这个类的clinit()方法，其他线程都需要阻塞等待，直到活动线程执行完clinit()方法。如果一个类的clinit()方法中有耗时很长的操作，就可能造成多个进程阻塞。 类初始化条件虚拟机规范严格规定了有且只有下列五种情况必须立即对类进行初始化（而加载、验证和准备自然而然需要在此之前开始）。 遇到new、getstatic、putstatic或invokestatic这四条字节码指令（注意，newarray指令触发的只是数组类型本身的初始化，而不会导致其相关类型的初始化，比如，new String[]只会直接触发String[]类的初始化，也就是触发对类[Ljava.lang.String的初始化，而直接不会触发String类的初始化）时，如果类没有进行过初始化，则需要先对其进行初始化。生成这四条指令的最常见的Java代码场景是： 使用new关键字实例化对象的时候； 读取或设置一个类的静态字段（被final修饰，放在常量池的常量除外）的时候； 调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行初始化则需要先触发其初始化。 当初始化一个类时，如果发现其父类没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main方法的那个类），虚拟机会先初始化这个主类。 当使用jdk1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 类加载器虚拟机设计团队把类加载阶段中的通过一个类的全限定名来获取描述此类的二进制字节流这个动作放到了Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确认其在Java虚拟机的唯一性。 JVM提供的类加载器 启动类加载器(Bootstrap ClassLoader)：又称为引导类加载器，负责将放在JAVA_HOME\\lib目录或被-Xbootclasspath参数所指定的路径中的，并被虚拟机所识别(仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载)类库加载到虚拟机内存中。 扩展类加载器(Extension ClassLoader)：负责加载JAVA_HOME\\lib\\ext目录或被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器(Application ClassLoader)：该类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所有一般称为系统类加载器。它负责加载用户路径(ClassPath)上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序默认的类加载器。 线程上下文类加载器：类java.lang.Thread中的方法getContextClassLoader()和setContextClassLoader(ClassLoader cl)用来获取和设置线程的上下文类加载器。如果没有通过setContextClassLoader(ClassLoader cl)方法进行设置的话，线程将继承其父线程的上下文类加载器。Java应用运行的初始线程的上下文类加载器是系统类加载器。该加载器一般是为了让父类加载器请求子类加载器去完成类加载操作。 双亲委派模式 一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的加载请求最终都会传递到顶层的启动类加载器中，只有父类的类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到锁需的类）时，子加载器才会尝试自己去加载。这里类加载器之间的父子关系一般都是以组合而不是继承的方式来复用父加载器的代码。 该模式的好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器来加载，因此Object类在程序的各种类加载器环境中都是同一个类。","categories":[],"tags":[{"name":"Java高级特性","slug":"Java高级特性","permalink":"http://yoursite.com/tags/Java高级特性/"}]},{"title":"Java并发编程","slug":"Java高级特性之Java并发编程","date":"2017-08-23T10:49:55.000Z","updated":"2021-07-10T08:48:08.691Z","comments":true,"path":"2017/08/23/Java高级特性之Java并发编程/","link":"","permalink":"http://yoursite.com/2017/08/23/Java高级特性之Java并发编程/","excerpt":"线程的生命周期","text":"线程的生命周期 新建状态：当程序使用new关键字创建一个线程之后，该线程就处于新建状态，此时仅由JVM为其分配内存，并初始化其成员变量。 就绪状态：当线程对象调用了start()方法后，该线程就处于就绪状态（即拥有执行资格）,JVM会为其创建方法调用栈和程序计数器，等待调度运行。 运行状态：如果处于就绪状态的线程获得了CPU的执行权，开始执行run()方法的线程执行体，则该线程处于运行状态。 阻塞状态：当处于运行状态的线程失去所占用的资源后，便进入阻塞状态。 线程调用sleep()方法主动放弃所占用的处理器资源； 线程调用了一个阻塞式IO方法，在该方法返回之前，该线程被阻塞； 线程试图获得一个同步监视器，但该同步监视器正被其他线程所持有； 线程在等待某个通知(notify)； 程序调用了线程的suspend()方法将该线程挂起。 死亡状态：run()方法或者call()执行完、线程抛出一个未捕获的Exception或Error或者调用该线程的stop()方法（不推荐，容易死锁）。 ps：yield方法释放本次执行权，但不会阻塞当前线程；wait方法释放执行权，释放锁，所以wait方法必须在锁里面；sleep方法释放执行权，不释放锁；notify方法不释放执行权，也不释放锁。 线程通信线程通信的方式 共享内存：通过写-读内存中的公共区域进行隐式通信（Java的堆内存）。 消息传递：通过发送消息来显示传递（生产者-消费者模式）。 原子性、可见性和有序性 原子性：即一个操作或者多个操作要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 可见性：当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：程序执行的顺序按照代码的先后顺序执行，即不会进行重排序。 ThreadLocalThreadLocal为每一个使用该变量的线程都提供了一个该变量的副本，每一个线程都可以改变自己的副本而不会其他线程的副本相冲突。ThreadLocal自身不会保存这些特定的数据资源，而是由每个线程自己来管理。每个Thread对象都有一个ThreadLocal.ThreadLocalMap类型的名为threadLocals的实例变量，它保存了ThreadLocal设置给这个线程的数据。当通过ThreadLocal的set(data)方法来设置数据的时候，ThreadLocal会首先获取当前线程的引用，然后通过该引用获取当前线程持有的threadLocals，最后，以当前ThreadLocal的ThreadLocalHashCode作为key，将要设置的数据设置到当前线程。 volatile 当把变量声明为volatile后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。同时volatile变量不会被缓存在寄存器或者其它处理器不可见的地方。 原理是使用lock前缀使得本CPU的Cache写入内存，该写入操作会同时引起其它CPU或内核无效化其Cache。因为该变量需要同步到内存，意味着所有之前的操作都已经执行完成，这样便形成了指令重排序无法越过内存屏障的效果。 Locksynchronized可重入的实现每个锁对象关联一个监视器和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任意线程都可以获得该锁并调用相应方法。当一个线程请求成功后，JVM会记下持有的线程，并将计数器设置为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。 ReentrantLock、ReentrantReadWriteLock和synchronized的区别 ReentrantLock的tryLock方法可以尝试获取锁并指定等待时间，然后可以进行判断，获取到锁可以干什么，获取不到又会干什么。 ReentrantLock可以指定为公平锁（默认非公平，ReentrantLock的构造方法中传入true时为公平锁）。 ReentrantLock可以同时绑定多个Condition对象。 ReentrantReadWriteLock是读写锁，读写分离，读多写少用这个锁效率高（读读共享，写写互斥，读写互斥）。 StampedLock(1.8)：读写锁的改进版本。读写锁虽然分离了读和写的功能，使得读读之间可以完全并发。但是读写之间还是会冲突。读锁会完全阻塞写锁，它使用的是悲观的锁策略。而StampedLock则提供了一种乐观的锁策略。 无锁并发 非阻塞同步，即基于冲突检测的乐观并发策略；通俗上说，就是先进行操作，如果没有其他线程争用共享数据，那么就让操作成功，如果产生了冲突，就采取其他补偿措施（最常用的就是不断重试，直到成功为止）。 CAS(比较并交换)：该指令需要三个操作数，分别是内存位置（Java中可以简单的理解为变量的内存地址，用V表示）、旧的预期值（用A表示）、和新值（用B表示）。当且仅当V的值符合旧的预期值A时，处理器才用新值B更新V的值，否则不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述处理过程是一个原子操作。 CAS自己的理解：例如i++时，将i的值复制一份作为旧值，然后取出i并加1为新值，判断旧值是否等于i，如果等于将新值赋值给i，判断和赋值为原子操作。 ABA问题：如果在复制后比较前，先被修改为B，又被修改回A，那么CAS操作就会认为它没有被修改过（并不影响并发程序的正确性）。 锁优化Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。 偏向锁引入偏向锁是为了在无多线程竞争的情况下减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在Mark Word中记录ThreadID的时候依赖一次CAS原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS原子指令的性能消耗）。轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。 加锁 访问Mark Word中偏向锁的标识是否设置成01(可偏向状态)。 如果为可偏向状态，则检查当前线程ID是否等于Mark Word中记录的线程ID，如果是进入步骤5，否则进入步骤3。 如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功（之前没用线程竞争过该锁），则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。 执行同步代码。 解锁偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 轻量级锁加锁 在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为01状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为Displaced Mark Word。 虚拟机将使用CAS操作将对象的Mark Word更新为指向当前线程的栈帧的指针，如果这个更新操作成功了执行步骤3，否则执行步骤4。 线程获取该对象的锁，并且对象的Mark Word的锁标志位（Mark Word的最后2bit）更新为00，即表示处于轻量级锁定状态。 虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是说明当前线程已经拥有了这个对象的锁，就可以直接进入同步块继续执行，否则说明该对象已经被其它线程抢占。这就表明有两个以上的线程争用同一个锁，那轻量级锁就不在有效，要膨胀为重量级锁，锁标志的状态值变为10，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 解锁 通过CAS操作尝试将线程中复制的Displaced Mark Word对象替换当前的Mark Word。 如果替换成功，整个同步过程就结束了。 如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀），那就要在释放锁的同时，唤醒被挂起的线程。 自旋锁自适应自旋 互斥同步最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大压力。同时，虚拟机的开发团队也主要到在许多应用共享数据的锁定状态只会持续很短的一段时间，为了这段时间挂起和恢复线程并不值得。如果物理机上有一个以上的处理器，能让两个或以上的线程同时并行执行，就可以让后面的请求锁的线程执行一个忙循环（自旋）。 在JDK1.6中引入自适应的自旋锁，自适应意味着自旋的时间不在固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机会认为这次自旋也有可能获得成功，进而允许自旋等待持续相对更长的时间。 当线程在获取轻量级锁的过程中执行CAS操作失败时，是要通过自旋来获取重量级锁的，而不是直接挂起当前线程。问题在于，自旋是需要消耗CPU的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，白白浪费CPU资源。解决这个问题最简单的办法就是指定自旋的次数，例如让其循环10次，如果还没获取到锁就进入阻塞状态。所以在JDK1.6中引入了自适应的自旋锁，可以让自旋的时间不再固定，而是你由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 java.util.concurrent包并发集合 ConcurrentLinkedQueue：非阻塞的无界安全队列，不允许null元素，可以看做线程安全LinkedList； BlockingQueue：阻塞队列 ArrayBlockingQueue：有界阻塞队列。 LinkedBlockingQueue：无界阻塞队列。 LinkedBlockingDeque：无界阻塞双向队列。 DelayQueue：无界阻塞队列，只有在延迟期满时才能从中提取元素。 PriorityBlockingQueue：无界阻塞队列，与类PriorityQueue相同的顺序规则，并且提供了阻塞获取操作。 SynchronousQueue：没有缓冲的队列，每个插入操作必须等待另一个线程的对应移除操作 ，反之亦然。 LinkedTransferQueue(1.7)：如果有消费者，就直接给消费者，如果没有消费者就阻塞。 ConcurrentMap：ConcurrentMap内部结构和Map相同，但ConcurrentMap是线程安全的。他将数据分为多个segment，默认是16个，然后每次操作对一个segment加锁，降低锁竞争。1.8改为通过CAS+重量级锁来实现。 putIfAbsent(K key, V value)：仅当集合中没有key相对应的值时才插入。 remove(K key, V value)：仅当集合中存在key相对应的值时才移除。 replace(K key, V oldValue, V newValue)：仅当集合中存在key相对应的值为oldValue时才替换为newValue。 replace(K key, V value)：仅当集合中存在key相对应的值时才替换为value。 CopyOnWriteArrayList：写时复制，当需要向一个容器添加元素时，不直接向当前容器添加，而是先将当前容器进行Copy，然后向Copy出来的容器中添加，添加完成后，将原容器的引用指向新容器。这样就可以对CopyOnWrite容器进行并发的读，而不需要加锁。该容器实现了读写分离。但是他牺牲了写的性能。 同步器 CountDownLatch：提供一个计数器，当计数器为0时，所有线程才会释放资源。可以用来监听某些初始化操作，等初始化完毕后，通知主线程继续工作。 CyclicBarrier：使用屏障点来阻塞一组线程，当该组线程有没有到达屏障点的线程时其他线程会等待该线程到达。 Semaphore(信号量)：锁只允许一个线程访问同一个资源，而信号量确可以同时指定多个线程访问某一个资源。 Exchanger：在两个线程的同步点之间实行数据的交换。 线程池 Executor接口是线程池的顶层接口，里面只有一个execute方法，接受一个Runnable任务，并执行。 ExecutorService是Executor的子接口，该接口提供的submit方法可以提交Callable任务。同时提供了对线程池生命周期进行管理的方法： shutdown()：将执行平缓的关闭过程；即不再接受新的任务，同时等待已提交的任务执行完成（包括那些还未开始执行的任务）。 shutdownNow()：将执行粗暴的关闭过程，即它将尝试取消所有运行中任务，并且不再启动尚未开始执行的任务。 AbstractExecutorService：实现了线程池的一些公共方法。 ThreadPoolExecutor：用来构建基本的自定义线程池。 ForkJoinPool(1.7)：用来把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。 ScheduledThreadPoolExecutor：用来开启延迟与周期任务。 scheduleAtFixedRate(Runnable, 0, 100, TimeUnit.MILLISECONDS)：初始化延迟0ms开始执行，每隔100ms重新执行一次任务（当我们要执行的任务大于我们指定的执行间隔时，并不会在指定间隔时开辟一个新的线程并发执行这个任务。而是等待该线程执行完毕）。 scheduleWithFixedDelay(Runnable, 0, 100, TimeUnit.MILLISECONDS)：初始化时延时0ms开始执行，本次执行结束后延迟100ms开始下次执行。 schedule(Runnable, 100, TimeUnit.MILLISECONDS)：100ms后执行一次本任务。 线程池队列：基本的任务排列方法有3种，无界阻塞队列、有界阻塞队列和同步移交（即没有缓冲的队列）。 线程池的饱和策略：当有界队列满了且线程池已经达到最大线程数的时候，对新来的任务执行的策略。 中止策略（AbortPolicy）：默认的饱和策略，抛出RejectedExecutionException。 抛弃策略（DiscardPolicy）：抛弃新来的任务。 抛弃最旧的（DiscardOldestPolicy）：抛弃下一个将被执行的任务，然后尝试重新提交新的任务。 调用者运行（CallerRunsPolicy）：将任务回退给调用者。 ScheduledExecutorService executorService = Executors.newScheduledThreadPool(5); ExecutorService pool = Executors.newFixedThreadPool(5); // 自定义线程池 ThreadPoolExecutor pool = new ThreadPoolExecutor( 1, // 初始化时线程池里的线程数 2, // 线程池中的线程最大数 60, // 线程执行完后被回收的时间值 TimeUnit.SECONDS, // 线程执行完后被回收的时间单位（s） new ArrayBlockingQueue(3) // 指定一种队列，存放当线程满的时候存放添加进来的线程 ); Future接口：一般用来接受Callable执行完成后的返回值。FutureTask是该接口的实现类。12345678910111213141516171819FutureTask&lt;Integer&gt; task = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() &#123;//使用Callable接口作为构造参数 public Integer call() throws InterruptedException &#123; TimeUnit.MICROSECONDS.sleep(500); return 10000; &#125;&#125;);new Thread(task).start();System.out.println(task.get());/***************************************************************************/ExecutorService service = Executors.newFixedThreadPool(5);Future&lt;Integer&gt; future = service.submit(new Callable&lt;Integer&gt;() &#123;//使用Callable接口作为构造参数 public Integer call() throws InterruptedException &#123; TimeUnit.MICROSECONDS.sleep(50000); return 100; &#125;&#125;);System.out.println(future.isDone());System.out.println(future.get());service.shutdown(); 死锁123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo &#123; privat static String A = \"A\"; private static String B = \"B\"; public static void main(String[] args) &#123; new DeadLockDemo().deadLock(); &#125; private void deadLock() &#123; Thread t1 = new Thread(new Runnable() &#123; @Override publicvoid run() &#123; synchronized (A) &#123; try &#123; Thread.currentThread().sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (B) &#123; System.out.println(\"1\"); &#125; &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override publicvoid run() &#123; synchronized (B) &#123; synchronized (A) &#123; System.out.println(\"2\"); &#125; &#125; &#125; &#125;); t1.start(); t2.start(); &#125;&#125; 避免死锁的几个常见方法。 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。","categories":[],"tags":[{"name":"Java高级特性","slug":"Java高级特性","permalink":"http://yoursite.com/tags/Java高级特性/"}]},{"title":"Java克隆与排序","slug":"Java基础之克隆与排序","date":"2017-08-12T02:43:25.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/08/12/Java基础之克隆与排序/","link":"","permalink":"http://yoursite.com/2017/08/12/Java基础之克隆与排序/","excerpt":"克隆接口(Cloneable)浅拷贝 实现Cloneable接口； 覆盖Object中protected类型的clone方法。","text":"克隆接口(Cloneable)浅拷贝 实现Cloneable接口； 覆盖Object中protected类型的clone方法。 深拷贝当被拷贝的对象里有指向其他对象的引用时，不会拷贝被指向的对象，只是简单的拷贝了一下该引用。所以需要自己在clone方法中进行深度拷贝。1234567891011121314151617class A implements Cloneable &#123; public Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125;public class testDeepClone implements Cloneable &#123; public int num = 0; public String str = \"default\"; public A a; @Override public Object clone() throws CloneNotSupportedException &#123; testDeepClone o = (testDeepClone) super.clone(); o.str = new String(this.str); o.a = (A) a.clone(); return o; &#125;&#125; ps：也可以使用对象的序列化和反序列化来实现深度克隆。 排序接口Comparable接口 Comparable接口只包含compareTo(T)方法，该方法可以给两个对象排序。如果该对象小于、等于或大于指定对象，则分别返回负整数、零或正整数。 实现此接口的对象列表和数组可以通过Collections.sort和Arrays.sort进行自动排序。 强烈推荐（不是必需的）使自然排序与equals一致。即(x.compareTo(y) == 0) == (x.equals(y))。 Comparator接口根据compare(T o1, T o2)第一个参数小于、等于或大于第二个参数分别返回负整数、零或正整数。 Collections.sort(list, new Comparator&lt;Integer&gt;() { @Override public int compare(Integer o1, Integer o2) { return o1 - o2; } });","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Maven基础","slug":"其它之Maven基础","date":"2017-07-04T13:52:29.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/07/04/其它之Maven基础/","link":"","permalink":"http://yoursite.com/2017/07/04/其它之Maven基础/","excerpt":"Pom.xml详解 | Maven插件所有插件","text":"Pom.xml详解 | Maven插件所有插件 maven基本命令 mvn install -DskipTests：编译maven项目将其放到本地创库中并忽略测试。 mvn deploy：发布命令，将打包的文件发布到私服上。 mvn dependency:tree：查看包依赖树。 mvn tomcat7:run 使用tomcat7运行项目（需要配置tomcat7插件）。 依赖范围 compile：该jar包会进入项目包，默认。 provide：编译时存在，项目打包时不存在，一般用在jsp、servlet等包上，因为Tomcat有默认有这些包。 runtime：编译时不存在，测试和项目打包时存在，一般用在jdbc驱动包上。 test：编译时不需要，项目打包时也不存在，一般用在Junit上。 SpringBoot迭代发布JAR瘦身配置默认情况下，插件spring-boot-maven-plugin会把整个项目打包成一个可运行的Jar包（即所谓的Flat Jar），导致了这个Jar包很大（通常有几十M）。如今迭代发布时常有的事情，每次都上传一个如此庞大的文件，会浪费很多时间，有些时候上传的过程中还会出错。造成Jar包很大的根本原因就是依赖第三方的jar很多，很大，下面我们就把第三方的JAR与项目代码分离，第三方的JAR把移除到lib文件夹中，即可实现为我们的可执行JAR瘦身，配置如下：12345678910111213141516171819202122232425262728293031323334353637383940&lt;!-- 负责将不变的jar包拷贝到target/lib目录下，除了第一次一般被注释掉 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;type&gt;jar&lt;/type&gt; &lt;includeTypes&gt;jar&lt;/includeTypes&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib&lt;/outputDirectory&gt; &lt;excludeGroupIds&gt;com.citycloud&lt;/excludeGroupIds&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;com.citycloud&lt;/groupId&gt; &lt;artifactId&gt;umale-internal-api&lt;/artifactId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 然后到target目录下，执行命令：java -Dloader.path=./lib -jar ***.jar，即可把项目JAR跑起来！ Maven修改版本号 运行mvn versions:set -DoldVersion=* -DnewVersion=1.0.1-SNAPSHOT -DprocessAllModules=true -DallowSnapshots=true命令将版本号修改为1.0.1-SNAPSHOT。 如果修改失败可以运行mvn versions:revert命令回退版本号。 如果修改成功可以运行mvn versions:commit命令确认版本，即会删除修改版本所产生的backup文件。 修改某个模块的版本号：mvn versions:set -DnewVersion=1.0.1-SNAPSHOT -DprocessAllModules=true -DallowSnapshots=true。 修改指定模块的版本号：mvn versions:set -DgroupId=${groupId} -DartifactId=${artifact} -DoldVersion=* -DnewVersion=1.0.2-SNAPSHOT -DallowSnapshots=true。 Mavne远程仓库修改setting.xml文件里面的mirror节点url指向远程仓库的地址。这样设置之后你的所有项目都有作用。123456&lt;mirror&gt; &lt;id&gt;central_mirror&lt;/id&gt; &lt;name&gt;internal central_mirror epository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; 如果不修改setting.xml，也可以在项目的pom.xml上加入。 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;oschinaRepository&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"Git的安装和使用","slug":"其它之Git安装和使用","date":"2017-06-30T02:44:31.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/30/其它之Git安装和使用/","link":"","permalink":"http://yoursite.com/2017/06/30/其它之Git安装和使用/","excerpt":"Hexo配置重装hexo时，直接从Git上克隆下源码然后直接执行npm install –save hexo-deployer-git命令就好。","text":"Hexo配置重装hexo时，直接从Git上克隆下源码然后直接执行npm install –save hexo-deployer-git命令就好。 将目录初始化为git创库：git init 设置name和email： git config user.name “fengbo” git config user.email “2540889969@qq.com“ 设置key：ssh-keygen -t rsa -C “2540889969@qq.com“ 测试是否成功：ssh git@github.com 如果出现You’ve successfully authenticated, but GitHub does not provide shell access 。这就表示已成功连上github。 从远程GitHub上将项目克隆下来：git clone https://github.com/fengbo4213/myapp.git 添加远程访问地址：git remote add origin https://github.com/fengbo4213/myapp.git 修改远程访问地址：git remote set-url origin https://github.com/fengbo4213/myapp.git 提交修改： git pull git add 文件名 git commit -m “添加注释” git push origin master git push -f origin master：强制推送到远程 分支管理 git branch &lt;新分支名字&gt;：在本地电脑新建一个分支 git push origin &lt;新分支名字&gt;：将新分支发布在github上 git checkout &lt;新分支名字&gt;：切换到你的新分支 git checkout -b 本地分支名 origin/远程分支名：拉取远程分支并同时创建对应的本地分支 git branch：查看所有已存在的分支 git branch -a：查看所有已存在的分支，包括远程分支 git merge &lt;分支名字&gt;：将当前分支合并该分支上 git branch -d &lt;分支名字&gt;：删除该分支 git reset ：将当前分支重设到指定或者HEAD （默认，如果不指定commit，默认是HEAD） 分支冲突：当合并分支冲突时，可以使用git status查看冲突的文件，同时会在冲突的文件中显示。这时需要手动修改该文件，然后使用git add &lt;冲突的文件名&gt;标记冲突已经解决。然后使用git commit命令提交即可。 远程仓库管理git remote -v：查看远程仓库git remote show origin：查看origin仓库的详细信息git remote rename 新名 旧名：重命名远程仓库git remote rm 名称：移除一个远程仓库 丢弃本地修改git checkout .：本地所有修改的。没有的提交的，都返回到原来的状态git clean -xdf .：删除本地没有提交的文件git reset –hard HASH：返回到某个节点，不保留修改git reset –soft HASH：返回到某个节点，保留修改 删除Git和本地的文件：git rm -rf .idea 删除Git中的文件：git rm -rf –cached .idea","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"Redis基础","slug":"其它之Redis基础","date":"2017-06-25T09:35:46.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/25/其它之Redis基础/","link":"","permalink":"http://yoursite.com/2017/06/25/其它之Redis基础/","excerpt":"redis配置文件解析，Redis是一种基于键值对（key-value）的NoSQL数据库。Redis中的值可以是由string（字符串）、hash（哈希）、list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、HyperLogLog、GEO（地理信息定位）等多种数据结构和算法组成。Redis使用了单线程架构和I/O多路复用模型来实现高性能的内存数据库服务。因为Redis是单线程来处理命令，所以一条命令从客户端到服务器端不会被立即执行，所有命令都会进入一个队列中，然后被逐个执行。","text":"redis配置文件解析，Redis是一种基于键值对（key-value）的NoSQL数据库。Redis中的值可以是由string（字符串）、hash（哈希）、list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、HyperLogLog、GEO（地理信息定位）等多种数据结构和算法组成。Redis使用了单线程架构和I/O多路复用模型来实现高性能的内存数据库服务。因为Redis是单线程来处理命令，所以一条命令从客户端到服务器端不会被立即执行，所有命令都会进入一个队列中，然后被逐个执行。 五种数据结构String类型字符串类型实际可以是字符串（简单的字符串、JSON、XML）、数字（整数、浮点数）、二进制（图片、视频、音频），但是最大值不能超过512M。 set key value：给给定的key赋值。 get key：获取存储在key中的值。 del key：删除存储在给定的key中的值。 数字类型的String incr key：使数字类型字符自增1。 值不是整数，返回错误。 值是整数，返回自增后的结果。 键不存在，按照值为0自增，返回结果为1。 incrby key num：使数字类型的字符增num。 decr key：使数字类型字符自减1。 decrby key num：使数字类型的字符减num。 incrbyfloat key num：使数字类型的字符加浮点数num。 String类型的应用(Redis开发与运维2.2.3) 缓存功能 1234567891011121314UserInfo getUserInfo(long id)&#123; userRedisKey = \"user:info:\" + id value = redis.get(userRedisKey); UserInfo userInfo; if (value != null) &#123; userInfo = deserialize(value); &#125; else &#123; userInfo = mysql.get(id); if (userInfo != null) redis.setex(userRedisKey, 3600, serialize(userInfo)); &#125; return userInfo; &#125; 计数 1234long incrVideoCounter(long id) &#123; key = \"video:playCount:\" + id; return redis.incr(key);&#125; 共享Session 限速：很多应用出于安全的考虑，会在每次进行登录时，让用户输入手机验证码，从而确定是否是用户本人。但是为了短信接口不被频繁访问，会限制用户每分钟获取验证码的频率，例如一分钟不能超过5次123456789phoneNum = \"138xxxxxxxx\";key = \"shortMsg:limit:\" + phoneNum;// SET key value EX 60 NXisExists = redis.set(key,1,\"EX 60\",\"NX\");if(isExists != null || redis.incr(key) &lt;=5)&#123; // 通过&#125;else&#123; // 限速&#125; Hash类型Hash类型可以很方便的映射关系型数据库。也可以用来做缓存功能，要注意过期时间的问题，Hash是统一过期。 hset key sub-key value：向散列表中插入一个键值对。 hget key sub-key：根据key和sub-key从散列表中获取元素。 hgetall key：获取散列表包含的所有键值对。 hlen key：获取散列表中的元素个数。 hdel key sub-key：删除散列表中的元素。 hmget key key1 key2：同时获取key1和key2中的值 hmset key key1 val1 key2 val2：同时set多个键值对。 List类型列表类型可重复，可以通过索引获取元素，可以从两端压入或者弹出原素，即可以用来当做栈和队列。List还具备分页查询的功能。 lpush/rpush key value：从列表左边/右边压入一个元素。 lpop/rpop key：从列表左边/右边弹出一个元素。 llen key：获取列表中的元素个数。 lrange key 0 -1：遍历列表。 lindex key 1：根据下标获取队列中的元素。 ltrim key start end：对列表进行修剪，只保留从start偏移量到end偏移量范围内的元素，其中start和end也会被保留。 blpop/brpop key：阻塞去列表左边/右边的元素。 rpoplpush source-key dest-key：从source的右端弹出元素插入到dest左端，并向用户返回该元素。 brpoplpush source-key dest-key timeout：从source的右端弹出元素插入到dest左端，并向用户返回该元素。如果当前source为空，那么在timeout秒内阻塞等待可弹出的元素。 集合类型集合类型也可以保存多个字符串元素，但和列表不同的是，集合中元素不可重复，并且集合汇总的元素时无序的，不可以使用索引获取元素。同时集合除了增删改查还可以进行取交集、并集和差集等运算。经典的场景是用来给用户添加标签。 sadd key value：向集合中插入一个元素。 spop key：随机移除并返回集合中的一个元素。 sismember key value：检查给定元素是否存在于集合中。 srem key value：如果给定的与元素存在于集合中，就从集合中删除该元素。 scard key：获取集合中的元素个数。 smembers key：遍历集合中里面的所有元素。 有序集合有序集合和散列一样都用于存储键值对，有序集合的键被称为成员(member)，相当于集合中value，每个成员都是各不相同的，而有序集合的值被称为分值(score)，分值必须为浮点数。有序集合即可以通过成员访问元素，又可以通过分值的排列顺序访问元素。 zadd key score member：向集合中插入键为member值为score的键值对。 zcard key：返回集合中包含的元素数量。 zincrby key num member：将member成员的分值加num。 zcount key min max：返回分值介于min和max之间的成员的数量。 zrank key member：返回成员在集合中的排名。 zscore key member：返回成员的分值。 zrange key 0 -1：显示集合里面所有的member。 zrange key 0 -1 withscores：显示集合里面所有的member和score。 zrangebyscore key 0 10：获取有序集合在给定分值范围内的所有member。 zrem key value：如果member存在于集合中就删除该集合。 Bitmaps可以用来实现布隆过滤器。 过期时间设置 ttl key：查看给定键距离过期还有多少秒。 pttl key：查看给定键距离过期还有多少毫秒。 expire key time：让给定键在指定的秒数后过期。 expireat key time：将给定键的过期时间设置为给定的UNIX时间戳。 pexpire key time：让给定键在指定的毫秒数后过期。 pexpireat key time：将一个毫秒精度的UNIX时间戳设置为给定键的过期时间。 当key到达过期时间有两种方法删除失效主键：1）消极方法，在主键被访问时如果发现它已经失效，就删除它；2）积极方法，周期性的从设置了失效时间的主键中选择一部分失效的主键删除。 persist key：移除键的过期时间。 对于字符串类型键，执行set命令会去掉过期时间，这个问题很容易在开发中被忽视。 setex命令作为set+expire的组合，不但是原子执行，同时减少了一次网络通讯的时间。 客户端管理命令 client list：查看和服务端相连的所有客户端连接信息。 client getName/setName：设置获取当前客户端的名称。 client kill ip:port：杀掉指定ip和端口的客户端。 client pause timeout(毫秒)：阻塞客户端timeout毫秒。 monitor：用于监控Redis正在执行的命令，并记录了详细的时间戳。 其它一些命令 type key：查看键的数据类型。 rename key newkey：重命名key。 randomkey：随机返回一个key。 Redis持久化RDB持久化RDB持久化是把当前进程数据生成快照保存到硬盘的过程，如果系统崩溃，用户将丢失最近一次生成快照之后的数据。所以RDB不适合实时持久化。触发RDB持久化过程分为手动触发和自动触发。 手动触发：手动调用bgsave命令，Redis进程执行fork操作创建子进程进行RDB持久化操作。 自动触发： 使用save相关配置，即在配置文件中配置”save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。 如果从节点执行全量复制操作，主节点自动生成RDB文件并发送给从节点。 执行debug reload命令重新加载Redis时，会触发save操作。 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。 AOF持久化以独立日志的方式记录每次写命令，重启时在重新执行AOF中的命令达到恢复数据的目的。配置文件中使用appendonly yes配置打开AOP持久化。 所有的写入命令会追加到aof_buf缓冲区中。 缓冲区根据对应的策略向硬盘做同步操作。 appendfsync everysec：由专门的线程每秒写入磁盘一次。 appendfsync always：命令写入aof_buf后调用系统fsync操作同步到AOF文件。 appendfsync no：同步硬盘操作由操作系统负责，通常同步周期最长30秒。 随着AOF文件越来越大，需要定期对AOF文件进行重写，以压缩文件。 auto-aof-rewrite-percentage 100和auto-aof-rewrite-min-size 64mb：表示当AOP体积大于64M并且体积比上一次重写后的体积大了至少一倍(100%)时Redis将执行重写AOP文件操作。 当Redis重启时，可以加载AOF文件进行数据恢复。 Redis复制复制命令 slaveof ip port：建立主从复制，以ip为主自己为从。也可以配置在配置文件中。 slaveof no one：断开与主节点的复制关系并晋升为主节点。 一主一从结构 当应用写命令并发量高且需要持久化时，可以只在从节点开启AOF，这样既保证数据安全性同时避免了持久化对主节点的性能干扰。 但是需要注意当主节点关闭持久化功能时，如果主节点脱机要避免自动重启操作。因为主节点之前没有开启持久化功能，重启后数据集为空，这时候继续复制主节点数据会导致从节点数据清空。 应该先断开与从节点与主节点的复制关系，在重启主节点。 一主多从结构一主多从结构使得应用端可以利用多个从节点实现读写分离。对于读占比比较大的场景，可以把读命令发送到从节点来分担主节点压力。 树状主从结构树状主从结构使得从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下复制。通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量。 Redis主从复制Redis主从复制是单向的，只能从主节点复制数据到从节点。Redis主从复制分为全量复制和部分复制，全量复制一般发生在主从第一次建立复制时，主节点会直接将RDB文件丢过去，需要注意RDB文件过大的问题；部分复制一般是当从节点挂了一段时间，如果主节点的复制积压缓冲区内存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。 Redis集群数据分布分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点的问题，即根据数据分区规则把数据集划分到多个节点上，每个节点负责整体数据的一个子集。常见的分区规则有哈希分区和顺序分区两种。Redis Cluster使用的是哈希分区。 哈希分区：数据离散好、数据分布业务无关、无法顺序访问。 顺序分区：离散读易倾斜、数据分布业务相关、可顺序访问。 常见的哈希分区规则 节点取余分区：使用特定的数据，如Redis的键或用户ID，再根据节点数量N使用公式：hash（key）%N计算出哈希值，用来决定数据映射到哪一个节点上。这种方案存在一个问题：当节点数量变化时，如扩容或收缩节点，数据节点映射关系需要重新计算，会导致数据的重新迁移。 一致性哈希分区：为系统中每个节点分配一个token，范围一般在0~2^32，这些token构成一个哈希环。数据读写执行节点查找操作时，先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。 虚拟槽分区：使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个范围一般远远大于节点数，比如Redis Cluster槽范围是0~16383。每一个实例负责维护一部分槽以及槽所映射的键值数据，所以动态扩展时只需要将部分槽的数据重新Hash即可。 Redis阻塞因为Redis是单线程架构，所有的读写操作都在一条主线程上完成，阻塞就成为影响Redis效率的关键性因素。当Redis阻塞时，线上应用服务应该是最先感知到的，这时应用方会收到大量Redis超时异常，比如Jedis客户端会抛出JedisConnectionException。常见的做法是在应用方加入异常统计并通过邮件/微信/短信报警，以便及时发现通知问题。 阻塞的原因 内在原因：包括不合理的使用API或数据结构、CPU饱和、持久化阻塞等。 慢查询分析：可以通过slowlog get [n]命令来查询慢查询列表中的数据。线上建议设置慢查询为1毫秒（默认是10毫秒，即将配置slowlog-log-slower-than为1000）以便及时发现毫秒级以上的命令。 发现大对象：使用redis-cli -h {ip} -p {port} –bigkeys命令。 CPU饱和：单线程的Redis处理命令时只能使用一个CPU。而CPU饱和是指Redis把单核CPU使用率跑到接近100%。可以使用redis-cli –stat来实时查看每秒的QPS，如果只有几百或几千OPS的Redis实例就接近CPU饱和是很不正常的，有可能使用了高算法复杂度的命令。 持久化阻塞：对于开启了持久化功能的Redis节点，需要排查是否是持久化导致的阻塞。例如fork阻塞、AOF刷盘阻塞、HugePage写操作阻塞等。 外在原因：包括CPU竞争、内存交换、网络问题等。 CPU竞争：Redis是CPU密集型应用，不建议和其他多核CPU密集型服务部署在一起。部署Redis时为了充分利用多核CPU，通常一台机器部署多个实例。常见的一种优化时把Redis进程绑定到CPU上，用于降低CPU频换上下文切换的开销。当Redis父进程创建子进程进行RDB/AOF重写时，如果做了CPU绑定，会与父进程共享使用一个CPU。子进程重写时对单核CPU使用率通常在90%以上，父进程与子进程将产生激烈CPU竞争，极大影响Redis稳定性。因此对于开启了持久化或参与复制的主节点不建议绑定CPU。 Redis保证高性能的一个重要前提是所有的数据在内存中。如果操作系统把Redis使用的部分内存换出到硬盘，由于内存与硬盘读写速度差几个数量级，会导致发生交换后的Redis性能急剧下降。 Redis常见的性能问题都有哪些 Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。 Redis内存管理查看内存消耗内存消耗分为进程自身消耗和子进程消耗。Redis进程消耗主要包括自身内存、对象内存、缓冲内存和内存碎片，子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。可通过执行info memory命令获取内存相关指标。 used_memory：Redis分配器分配的内存总量，也就是内部存储的所有数据内存占用量。 used_memory_human：以可读格式返回used_memory。 used_memory_rss：从操作系统角度显示Redis进程占用的物理内存总量。 Redis内存回收机制 删除过期的键对象：Redis所有的键都可以设置过期属性，内部保存在过期字典中。由于进程内保存大量的键，维护每个键精准的过期删除机制会导致大量的CPU消耗，因此Redis采用惰性删除和定时任务删除机制实现过期键的内存回收。 惰性删除：当客户端读取带有超时属性的键时，如果已经超过键设置的超时时间，会执行删除操作并返回空。但是单独用这种方式存在内存泄露的问题，当过期键一直没有访问将无法得到及时删除，从而导致内存不能及时释放。 定时任务删除：Redis内部维护一个定时任务，默认每秒运行10次（通过配置hz控制）。定时任务中删除过期键逻辑采用了自适应算法，根据键的过期比例、使用快慢两种速率模式回收键。 内存溢出控制策略：当Redis所用内存达到maxmemory上限时会触发相应的溢出控制策略。具体策略受maxmemory-policy参数控制，Redis支持6种数据淘汰策略。 noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error OOM command not allowed when used memory），此时Redis只响应读操作。 volatile-lru：根据LRU（最近最少使用）算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。 allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除所有键，直到腾出足够空间为止。 volatile-random：随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 Redis使用Redis更新缓存Redis更新缓存时一般会先更新数据库，然后在删除缓存。否则如果在删除缓存后还没有来得及更新数据库，其他用户访问了该数据会重新生成脏缓存。 Redis分布式锁使用setnx来抢夺锁，抢到后，使用expire给锁加一个过期时间防止锁忘记释放。使用set的参数可以将set和expire合并为一条指令。具体实现方式参考Dubbo如何保证幂等性。 缓存7大今典问题缓存失效表现：如果大量数据同时过期，很多缓存数据访问都会miss，进而穿透到DB，DB的压力就会明显上升，由于DB的性能较差，只在缓存的1%~2%以下，这样请求的慢查率会明显上升。原因：数据定时批量加载到缓存中、新业务上线进行缓存预热等。解决：过期时间=Base时间+随机时间。 缓存穿透表现：缓存命中率下降，DB压力上升。原因：用户查询一个DB中不存在的Key，导致每次查询都会穿透到DB。解决： 查询不存在的数据时，第一次查DB，虽然没查到结果返回NULL，仍然记录这个key到缓存，只是这个key对应的value是一个特殊设置的值。 构建一个布隆过滤器缓存过滤器，记录全量数据，这样访问数据时，可以直接通过布隆过滤器判断这个key是否存在，如果不存在直接返回即可，根本无需查缓存和DB。 缓存雪崩表现：部分缓存节点不可用，导致整个缓存体系甚至甚至服务系统不可用的情况。原因： 缓存不进行rehash时产生的雪崩，一般是由于较多缓存节点不可用，请求穿透导致DB也过载不可用，最终整个系统雪崩不可用的。 缓存支持rehash时产生的雪崩，则大多跟流量洪峰有关，流量洪峰到达，引发部分缓存节点过载Crash，然后因rehash扩散到其他缓存节点，最终整个缓存体系异常。解决： 业务DB的访问增加读写开关，当发现DB请求变慢、阻塞，慢请求超过阀值时，就会关闭读开关，部分或所有读DB的请求进行failfast立即返回，待DB恢复后再打开读开关。 对缓存增加多个副本，缓存异常或请求miss后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务。 对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。 数据不一致表现：同一份数据，可能会同时存在DB和缓存之中。那就有可能发生，DB和缓存的数据不一致。如果缓存有多个副本，多个缓存副本里的数据也可能会发生不一致现象。原因： 缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和DB的数据不一致。 缓存rehash时，某个缓存机器反复异常，多次上下线，更新请求多次rehash。这样，一份数据存在多个节点，且每次rehash只更新某个节点，导致一些缓存节点产生脏数据。解决： cache更新失败后，可以进行重试，如果重试失败，则将失败的key写入队列机服务，待缓存访问恢复后，将这些key从缓存删除。这些key在再次被查询时，重新从DB加载，从而保证数据的一致性。 缓存时间适当调短，让缓存数据及早过期后，然后从DB重新加载，确保数据的最终一致性。 不采用rehash漂移策略，而采用缓存分层策略，尽量避免脏数据产生。 并发竞争表现：在高并发访问场景，一旦缓存访问没有找到数据，大量请求就会并发查询DB，导致DB压力大增的现象。原因：多个进程/线程中，有大量并发请求获取相同的数据，而这个数据key因为正好过期、被剔除等各种原因在缓存中不存在，这些进程/线程之间没有任何协调，然后一起并发查询DB，请求那个相同的key，最终导致DB压力大增。解决： 使用全局锁。即当缓存请求miss后，先尝试加全局锁，只有加全局锁成功的线程，才可以到DB去加载数据。其他进程/线程在读取缓存数据miss时，如果发现这个key有全局锁，就进行等待，待之前的线程将数据从 DB回种到缓存后，再从缓存获取。 对缓存数据保持多个备份，即便其中一个备份中的数据过期或被剔除了，还可以访问其他备份，从而减少数据并发竞争的情况。 Hot key现象：在突发事件发生时，大量用户同时去访问这个突发热点信息，这个突发热点信息所在的缓存节点就很容易出现过载和卡顿现象，甚至会被Crash。原因：数十万的访问请求同一个key，流量集中打在一个缓存节点机器，这个缓存机器很容易被打到物理网卡、带宽、CPU的极限，从而导致缓存访问变慢、卡顿。解决： 可以将这些热key进行分散处理，比如一个热key名字叫hotkey，可以被分散为hotkey#1、hotkey#2、hotkey#n，这n个key分散存在多个缓存节点，然后client端请求时，随机访问其中某个后缀的hotkey，这样就可以把热key的请求打散，避免一个缓存节点过载。 可以key的名字不变，对缓存提前进行多副本+多级结合的缓存架构设计。 如果热key较多，还可以通过监控体系对缓存实时监控，通过快速扩容来减少热key的冲击。 业务端可以使用本地缓存，将这些热key记录在本地缓存，来减少对远程缓存的冲击。 Big key现象：缓存访问时，部分Key的Value过大，读写、加载易超时的。解决： 将大key分拆为多个key，尽量减少大key的存在。 由于大key一旦穿透到DB，加载耗时很大，所以可以对这些大key进行特殊照顾，比如设置较长的过期时间，比如缓存内部在淘汰key时，同等条件下，尽量不淘汰这些大key。","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"Listener和filter","slug":"JavaWeb-listener和filter","date":"2017-06-22T10:53:24.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2017/06/22/JavaWeb-listener和filter/","link":"","permalink":"http://yoursite.com/2017/06/22/JavaWeb-listener和filter/","excerpt":"Listener特点：1、是一个接口；2、需要注册，例如注册在按钮上；3、在特殊事件发生时调用。","text":"Listener特点：1、是一个接口；2、需要注册，例如注册在按钮上；3、在特殊事件发生时调用。 JavaWeb中的监听器：8个 事件源：三大域 ServletContext 生命周期监听：ServletContextListener，有两个方法，一个出生时调用，一个在死亡时调用。 属性监听：ServletContextAttributeListener，三个方法，一个添加时调用，一个替换时调用，一个移除时调用。 HttpSession：类似 ServletRequest：类似 感知监听：1、添加到JavaBean上；2、不需要在web.xml中注册 HttpSessionBindingListener：有两个方法，一个是该JavaBean被session绑定的时候调用，一个是该JavaBean被session解除绑定时调用。 HttpSessionActivationListener（JavaBean需要同时实现序列化接口）：有两个方法，和Session绑定之后，一个Session钝化时调用，一个Session活化时调用（钝化和活化见Cookie和Session）。 Filter 1、实现Filter接口；2、在web.xml中配置 三个方法 init(FilterConfig)：在Filter创建之后； destroy()：在Filter销毁之前执行； doFilter(ServletRequest, ServletResponse, FilterChain)：每次过滤时都会执行。 Filter会在服务器启动时创建，在服务器关闭时销毁。Filter是单例的！ FilterConfig：与Servlet类似 getInitParameter：获取初始化参数； getFilterName：获取过滤器名称； getServletContext：获取application。 FilterChain doFilter(ServletRequest, ServletRespanse)：放行，即调用目标Servlet 四种拦截方式：请求（默认）、转发、包含、错误 1234&lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt;&lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt;&lt;dispatcher&gt;INCLUDE&lt;/dispatcher&gt;&lt;dispatcher&gt;ERROR&lt;/dispatcher&gt; 控制多个过滤器的执行顺序：的配置顺序决定了过滤器的执行顺序。 12345678910111213141516171819202122&lt;!-- filter配置 --&gt;&lt;filter&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;filter-class&gt; cn.edu.uibe.webdev.MyFilter &lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;developer&lt;/param-name&gt; &lt;param-value&gt;TongQiang&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;!-- 针对一个Servlet做过滤 --&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;servlet-name&gt;MyServlet&lt;/servlet-name&gt;&lt;/filter-mapping&gt;&lt;!-- 针对URL Pattern做过滤 --&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/book/*&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt;&lt;!-- 默认 --&gt;&lt;/filter-mapping&gt;","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"Cookie和Session","slug":"JavaWeb-Cookie和Session","date":"2017-06-22T10:53:21.000Z","updated":"2021-07-03T01:30:27.664Z","comments":true,"path":"2017/06/22/JavaWeb-Cookie和Session/","link":"","permalink":"http://yoursite.com/2017/06/22/JavaWeb-Cookie和Session/","excerpt":"Cookie对象添加和获取 使用response.addCookie()方法向浏览器保存Cookie 使用request.getCookeis()方法返回一个Cookie数组 Http协议规定 一个Cookie最大4kb 一个服务器最多向一个浏览器保存20个Cookie 一个浏览器最多可以保存300个Cookie","text":"Cookie对象添加和获取 使用response.addCookie()方法向浏览器保存Cookie 使用request.getCookeis()方法返回一个Cookie数组 Http协议规定 一个Cookie最大4kb 一个服务器最多向一个浏览器保存20个Cookie 一个浏览器最多可以保存300个Cookie Cookie的年龄（setMaxAge(时间)) maxAge &gt; 0：关闭浏览器时，将cookie保存到硬盘上 maxAge = 0：浏览器马上删除该cookie maxAge &lt; 0：关闭浏览器就删除cookie Cookie的path Cookie的路径并不是设置这个Cookie在客户端的保存路径 Cookie的path决定当浏览器访问服务器时带哪些Cookie，如果服务器的路径包含某个Cookie的路径，该Cookie就会被带回。 Cookie的domain（域） domain用来指定cookie的域名，当多个二级域名共享cookie时使用。 例如：www.baidu.com、zhidao.baidu.com、tieba.baidu.com如果想共享Cookie 设置domain为：cookie.setDomain(“.baidu.com”); 设置path为：cookie.setPath(“/“); HttpSession原理 request.getSession()：获取Cookie中的sessionID 如果sessionID不存在，创建session，把session保存起来，将sessionID保存到Cookie中 如果sessionID存在，如果没有找到同上 如果找到了，就不会再创建了 getSession(false)：如果session不存在，不创建session而是返回null getSession(true)和getSession()一样正常创建 session的方法 域方法：getAttribute()、setAttribute()和removeAttribute()方法 getId()：获取sessionID invalidate()：让session失效 isNew()：查看session是否是新的 session之URL重写，当用户禁用cookie时，可以在URL路径后添加一个sessionId参数（localhost?JSESSIONID=&lt;%=session.getId()%&gt;），request.getSession()方法在cookie中无法找到sessionId时会自动去URL中寻找sessionId。 response.encodeURL(String url)会自动判断浏览器是否禁用了cookie，如果禁用了会自动添加sessionId到URL中。 Session序列化：可以在服务器中配置，当服务器关闭时将session写入磁盘上，等服务器再次启动时写回来。Session的钝化和活化：如果服务器中session太多，内存不够可以将长时间没使用的session写入磁盘中，即session钝化。当再次需要使用该session时，会将session从文件中读出来，即session活化。","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"Servlet和JSP","slug":"JavaWeb-servlet和jsp","date":"2017-06-22T10:52:20.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/22/JavaWeb-servlet和jsp/","link":"","permalink":"http://yoursite.com/2017/06/22/JavaWeb-servlet和jsp/","excerpt":"Servlet","text":"Servlet Servlet是一个供其他Java程序（Servlet引擎）调用的Java类，没有main方法，它不能独立运行，它的运行完全由容器（Servlet引擎）来控制和调度。Servlet是在第一次访问是初始化的，但是可以在web.xml配置成在服务器启动的时候初始化，即添加1配置。 web.xml文件中的Servlet配置的顺序是有先后的，一般我们设置好，此时请求来到会交给不同的servlet来处理。 Servlet是单例的。针对客户端的多次Servlet请求，通常情况下，服务器只会创建一个Servlet实例对象，也就是说Servlet实例对象一旦创建，它就会驻留在内存中，为后续的其它请求服务，直至web容器退出，servlet实例对象才会销毁。 在Servlet的整个生命周期内，Servlet的init方法只被调用一次。而对一个Servlet的每次访问请求都导致Servlet引擎调用一次Servlet的service方法。对于每次HTTP请求，Servlet引擎都会创建一个新的HttpServletRequest请求对象和一个新的HttpServletResponse响应对象，然后将这两个对象作为参数传递给它调用的Servlet的service()方法，service方法再根据请求方式分别调用doXXX方法。 Servlet接口，顶级接口（有5个方法，其中前三个是生命周期方法） init(ServletConfig config)：在Servlet创建之后马上执行； service(ServletRequest req, ServletResponse res)：每次处理请求都会调用该方法； destroy()：Servlet被销毁前调用该方法。 getServletConfig()：获取Servlet的配置信息，返回一个ServletConfig对象。即和web.xml中的servlet配置相对应，Tomcat在解析web.xml时将web.xml中的servlet配置信息保存到一个ServletConfig对象中。 getServletName()：获取Servlet的name。 getServletContext()：获取ServletContext对象 getInitParameter(String name)：根据名称或者初始化参数 getInitParameterNames()：获取所有的初始化参数的名称 getServletInfo()：获取Servlet信息。 GenericServlet：实现Servlet接口的抽象类HttpServlet：继承了GenericServlet抽象类（主要使用该类） 主要覆盖doGet和doPost方法，如果没有覆盖这两个方法，确请求该方法会返回405（表示不支持该访问方式） ServletContext 一个项目中只有一个ServletContext对象（application域对象） 在服务器启动时创建，在服务器关闭时销毁 获取初始化参数（Servlet也可以初始化参数，但是一个Servlet只能获取自己的初始化参数，不能获取别人的） getInitParameter(String name)：得到初始化参数（和Servlet初始化参数不同，这个是根据里面的获取） 获取资源相关方法 getRealPath(“/index.jsp”)：获取真实的路径，即磁盘路径 getResourceAsStream(“/index.jsp”)：返回一个InputStream对象 getResourcePaths(“/WEB-INF”)：获取WEB-INF下所有文件夹和文件的路径 Servlet三大域：1. request：仅在当前请求中有效。常用于服务器间同一请求不同页面之间的参数传递，常应用于表单的控件值传递。1234request.setAttribute();request.getAttribute();request.removeAttribute();request.getParameter();//接受从表单传递过来的数据 2. session：服务器会为每个会话创建一个session对象用户打开浏览器会话开始，直到关闭浏览器会话才会结束。一次会话期间只会创建一个session对象。备注： session是服务器端对象，保存在服务器端。并且服务器可以将创建session后产生的sessionid通过一个cookie返回给客户端，以便下次验证。（session底层依赖于cookie）12345HttpSession session = request.getSession();//&lt;%session.serAttribute(“name”,”admin”)%&gt;session.setAttribute();session.getAttribute();session.removeAttribute(); 3. Application（ServletContext）:所有的用户都可以取得此信息，此信息在整个服务器上被保留。ServletContext在服务器启动时创建，在服务器关闭时销毁，一个JavaWeb应用只创建一个ServletContext对象。123ServletContext app = this.getServletContext();app.setAttribute(“name”, “kaixuan”); //设置一个值进去app.getAttribute(“name”); //获取键值对 Servlet之间的跳转：1. 转发(Forward):12RequestDispatcher d = request.getRequestDispatcher(\"forward.jsp\"); d.forward(request, response); 在MVC模式中，都是用Servlet来处理用户请求，把结果通过request.setAttribute()放到request中，然后forward到JSP中显示。在forward之前尽量不要使用out.println()。当使用forward跳转时，地址栏不会发生改变。 2. 重定向(Redirect)：重定向是利用服务器返回的状态码来实现的。客户端请求服务器是，服务器会返回一个状态码。服务器端通过HttpServletResponse的setStatus(int statuss)方法设置状态码。自动刷新(Refresh)：自动刷新不断可以实现一段时间调转到其他页面，还可以实现一段时间自动刷新。12response.setHeader(\"Refresh\",\"1000; URL=http://localhost:8080/example.html\");response.setRefresh(\"http://localhost:8080/example.html\"); JSPJsp多一个域（pageContext）它的有效范围只在当前jsp页面。WEB开发中实现会话跟踪：session、cookie、地址重写和隐藏域Jsp原理：当服务器上的一个jsp页面第一次被请求执行时，服务器上的jsp引擎将这个jsp页面转译成一个Servlet文件，再将这个java文件编译生成字节码文件。然后通过字节码文件响应用户请求。JSP九大内置对象分为四类 输入输出对象：out对象、response对象、request对象 out对象：用于页面输出，javax.servlet.jsp.JspWriter request对象：得到用户请求，javax.servlet.http.HttpServletRequest response对象：服务器向客户端的回应信息，javax.servlet.http.HttpServletResponse 通信控制对象：pageContext对象、session对象、application对象 pageContext对象：pageContext域，JSP的页面容器，javax.servlet.jsp.PageContext session对象：保存用户信息，javax.servlet.http.HttpSession application对象：保存所有用户共有信息，javax.servlet.ServletContext Servlet对象：page对象、config对象 page对象：当前页面转换后的Servlet类的实例 config对象：获取初始化参数，javax.servlet.ServletConfig 错误处理对象：exception对象 out和response区别：JspWriter对象不是直接将数据输出到页面，而是将数据先刷新到response的缓冲区，然后等待out内置对象满足一定的条件后才会调用PrintWriter对象的print系列方法把out内置对象的缓冲区中的内容输出到浏览器。out内置对象调用PrintWriter对象的print系列方法输出缓冲区中内容的条件 设置page指令的buffer属性关闭了out对象的缓存功能。 写入到out对象中的内容充满了out对象的缓冲区。 整个JSP页面结束。 EL表达式和JSTL EL表达式主要用来查找作用域中的数据，并对其执行简单的操作。 用美元符号$定界，内容包含在花括号{}中。例：${requestScope.name} JSTL（c标签） jsp语法 &lt;%! %&gt;之间声明变量和方法。这些变量和方法在整个JSP页面都有效。jsp引擎在将jsp页面转译成java文件时，将这些变量作为类的成员变量、方法。 &lt;% %&gt;之间插入java程序片，程序片中的变量被称为jsp页面的局部变量。因为生成java文件是，将各个程序片的这些变量作为类中某个方法的变量。 &lt;%= %&gt;之间插入一个表达式，不可以插入语句。 &lt;%@ page %&gt;定义整个jsp页面的一些属性和这些属性的值。例：&lt;% page contentType=”text/html;charest=UTF-8” pageEncoding=”UTF-8”/页面编码/ import=”java.util.*” %&gt; &lt;%@ include file=”文件的名字” %&gt;静态包含，在jsp页面整体嵌入一个文件，在编译阶段执行。 &lt;jsp:include page=”文件的名字” /&gt; 动态包含，在请求处理阶段执行。 &lt;%@ taglib uri=”c” prefix=”http://java.sun.com/jsp/jstl/core&quot; %&gt;Uri用来指定标签库的存放位置，prefix用来指定标签库所使用的前缀。","categories":[],"tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/tags/JavaWeb/"}]},{"title":"Java注解","slug":"Java基础之注解","date":"2017-06-22T09:00:25.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/22/Java基础之注解/","link":"","permalink":"http://yoursite.com/2017/06/22/Java基础之注解/","excerpt":"Java的5个基本的注解： @Override：告诉编辑器检查这个方法，保证父类要包含一个被该方法重写的方法； @Deprecated：表示某个程序元素（类、方法等）已过时； @SuppressWarnings：抑制编辑器警告，会一直做用于该程序元素的所有子元素； @SafeVarargs(Java7新增)：抑制“堆污染”警告； 堆污染：将一个不带泛型的对象付给一个带泛型的变量时，往往就会发生“堆污染”； Java7会对“堆污染”产生警告。 @Functionallnterface(Java8新增)：用来指定某个接口必须是函数式接口。 Java8规定如果一个接口中有且只有一个抽象方法（可以包含多个默认方法和static方法），那么该接口就是函数式接口。","text":"Java的5个基本的注解： @Override：告诉编辑器检查这个方法，保证父类要包含一个被该方法重写的方法； @Deprecated：表示某个程序元素（类、方法等）已过时； @SuppressWarnings：抑制编辑器警告，会一直做用于该程序元素的所有子元素； @SafeVarargs(Java7新增)：抑制“堆污染”警告； 堆污染：将一个不带泛型的对象付给一个带泛型的变量时，往往就会发生“堆污染”； Java7会对“堆污染”产生警告。 @Functionallnterface(Java8新增)：用来指定某个接口必须是函数式接口。 Java8规定如果一个接口中有且只有一个抽象方法（可以包含多个默认方法和static方法），那么该接口就是函数式接口。 java.lang.annotation包下提供了5个Meta Annotation（元注解） @Repeatable专门用于定义Java8中新增的重复注解； @Retention：指定被修饰的Annotation的生命周期； @Retention(RetentionPolicy.SOURCE)：注解仅存在于源码中，在Class字节码文件中不包含； @Retention(RetentionPolicy.CLASS)：默认的保留策略，注解会在Class字节码文件中存在，但运行时无法获得； @Retention(RetentionPolicy.RUNTIME)：注解在Class字节码文件中存在，且运行时可见。即在运行时可以通过反射获取到该注解。 @Target：用于指定被修饰的Annotation可以修饰那些程序单元； @Target(ElementType.TYPE)：接口、类、枚举、注解； @Target(ElementType.FIELD)：字段、枚举的常量； @Target(ElementType.METHOD)：方法； @Target(ElementType.PARAMETER)：方法参数； @Target(ElementType.CONSTRUCTOR)：构造函数； @Target(ElementType.LOCAL_VARIABLE)：局部变量； @Target(ElementType.ANNOTATION_TYPE)：注解； @Target(ElementType.PACKAGE)：包。 @Dncumented：指定被修饰的Annotation类将被javadoc工具提取成文档； @Inherited：指定被它修饰的Annotation将具有继承性。 自定义注解1234567891011121314151617181920212223242526@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@interface UseCase &#123; int id(); String description() default \"no description\";&#125;class PasswordUtils &#123; @UseCase(id = 11) public boolean validatePassword() &#123; return false; &#125; @UseCase(id = 12, description = \"description\") public boolean validatePassword2() &#123; return true; &#125;&#125;public class Demo &#123; public static void main(String[] args) &#123; // 通过反射获取类上（不包含父类的，包含私有）的所有方法 Method[] methods = PasswordUtils.class.getDeclaredMethods(); for (Method method : methods) &#123; UseCase useCase = method.getAnnotation(UseCase.class); System.out.println(useCase.id() + \":\" + useCase.description()); &#125; &#125;&#125; 定义Annotation：定义新的Annotation类型使用@interface关键字； 在默认情况下，Annotation可用于修饰任何程序元素，包括类、接口、方法等。 提取Annotation中的信息：Java 5在java.lang.reflect包（反射API）下新增了AnnotationElement接口。在该接口中getAnnotation方法指定类型的注解对象。如果被注解的方法上没有该类型的注解，返回null。","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Java序列化","slug":"Java基础之序列化","date":"2017-06-22T06:08:37.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/22/Java基础之序列化/","link":"","permalink":"http://yoursite.com/2017/06/22/Java基础之序列化/","excerpt":"序列化ID问题 Java的序列化是通过在运行时判断类的serialVersionUID来验证版本的一致性的。在进行反序列化时，JVM会把传来的字节流中的serialVersionUID与本地相应类的serialVersionUID进行比较。如果相同就认为是一致的，可以进行反序列化，否则抛出序列化版本不一致异常。 如果没有特殊需求，就是用默认的 1L 就可以，这样可以确保代码一致时反序列化成功。但是有些时候，通过改变序列化ID可以用来限制某些用户的使用。既当client需要一个从server端生成的对象时，如果server端希望client端进行版本升级，就可以改变自己的serialVersionUID来强迫client端进行升级。","text":"序列化ID问题 Java的序列化是通过在运行时判断类的serialVersionUID来验证版本的一致性的。在进行反序列化时，JVM会把传来的字节流中的serialVersionUID与本地相应类的serialVersionUID进行比较。如果相同就认为是一致的，可以进行反序列化，否则抛出序列化版本不一致异常。 如果没有特殊需求，就是用默认的 1L 就可以，这样可以确保代码一致时反序列化成功。但是有些时候，通过改变序列化ID可以用来限制某些用户的使用。既当client需要一个从server端生成的对象时，如果server端希望client端进行版本升级，就可以改变自己的serialVersionUID来强迫client端进行升级。 静态变量序列化序列化保存的是对象的状态，静态变量属于类的状态，因此，序列化并不保存静态变量。 transient关键字在变量前加上该关键字，可以阻止该变量被序列化到文件中。在反序列化后，该变量被设置为初始值，如 int 型的是 0，对象型的是 null。 父类的序列化 子类实现了序列化接口，父类没有实现序列化接口。如果父类没有空参的构造方法，会报java.io.InvalidClassException异常。 在父类没有实现Serializable接口时，虚拟机是不会序列化父对象的，而一个Java对象的构造必须先有父对象，才有子对象，反序列化也不例外。所以反序列化时，为了构造父对象，只能调用父类的无参构造函数作为默认的父对象。 因此当我们取父对象的变量值时，它的值是调用父类无参构造函数后的值。如果你考虑到这种序列化的情况，在父类无参构造函数中对变量进行初始化，否则的话，父类变量值都是默认声明的值，如int型的默认是0，String型的默认是null。 如果父类实现序列化，子类自动实现序列化，不需要显式实现Serializable接口。 序列化存储规则 Java序列化机制为了节省磁盘空间，具有特定的存储规则，即当写入文件的为同一对象时，并不会再将对象的内容进行存储，而只是只存储一份引用。 反序列化时，恢复引用关系即可。 如果想再次写入，可以在writeObject()之前调用out.reset()方法，这个方法的作用是清除流中保存的写入对象的记录。 123456789101112131415161718192021222324252627ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(\"result.obj\"));Demo demo = new Demo();demo.a = 1;// 试图将对象两次写入文件out.writeObject(Demo);out.flush();demo.a = 2;System.out.println(new File(\"result.obj\").length());// 清除流中保存的写入对象的记录，加入该行代码后t2.a结果是2// out.reset();out.writeObject(demo);out.close();System.out.println(new File(\"result.obj\").length());ObjectInputStream oin = new ObjectInputStream(new FileInputStream(\"result.obj\"));// 从文件依次读出两个文件Demo t1 = (Demo) oin.readObject();Demo t2 = (Demo) oin.readObject();oin.close(); //判断两个引用是否指向同一个对象System.out.println(t1 == t2);// trueSystem.out.println(t1.a);System.out.println(t2.a); 对敏感字段进行加密 在序列化过程中，虚拟机会试图调用对象里的writeObject和readObject方法，进行用户自定义的序列化和反序列化，如果没有这样的方法，则默认调用是ObjectOutputStream的defaultWriteObject方法以及ObjectInputStream的defaultReadObject方法。 用户自定义的writeObject和readObject方法允许用户控制序列化的过程，比如可以在序列化的过程中动态改变序列化的数值。基于这个原理，可以在实际应用中得到使用，用于敏感字段的加密工作。 123456789101112131415161718192021222324252627282930313233343536public class Demo implements Serializable &#123; private static final long serialVersionUID = 1L; private String password = \"pass\"; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; private void writeObject(ObjectOutputStream out) throws IOException &#123; PutField putFields = out.putFields(); System.out.println(\"原密码:\" + password); password = \"encryption\";//模拟加密 putFields.put(\"password\", password); System.out.println(\"加密后的密码\" + password); out.writeFields(); &#125; private void readObject(ObjectInputStream in) throws ClassNotFoundException, IOException &#123; GetField readFields = in.readFields(); Object object = readFields.get(\"password\", \"\"); System.out.println(\"要解密的字符串:\" + object.toString()); password = \"pass\";//模拟解密,需要获得本地的密钥 &#125; public static void main(String[] args) throws Exception &#123; ObjectOutputStream out = new ObjectOutputStream( new FileOutputStream(\"result.obj\")); out.writeObject(new Demo()); out.close(); ObjectInputStream oin = new ObjectInputStream(new FileInputStream( \"result.obj\")); Demo t = (Demo) oin.readObject(); System.out.println(\"解密后的字符串:\" + t.getPassword()); oin.close(); &#125;&#125; 参考文章Java 序列化的高级认识","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Java枚举","slug":"Java基础之枚举","date":"2017-06-22T05:04:13.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/22/Java基础之枚举/","link":"","permalink":"http://yoursite.com/2017/06/22/Java基础之枚举/","excerpt":"test 枚举和普通类的区别 枚举可以实现接口，但是枚举默认继承了java.lang.Enum类，故而不能继承其他类。 枚举默认被final修饰，故而不能派生子类。 枚举构造器默认使用private修饰，如果显示添加也只能使用private修饰。 枚举类的所有实例必须在第一行显示列出，否则该枚举无法在被实例。这些实例默认使用public static fianl修饰。 建议枚举类的成员变量都使用private final修饰。 类内部的枚举默认被static final修饰。","text":"test 枚举和普通类的区别 枚举可以实现接口，但是枚举默认继承了java.lang.Enum类，故而不能继承其他类。 枚举默认被final修饰，故而不能派生子类。 枚举构造器默认使用private修饰，如果显示添加也只能使用private修饰。 枚举类的所有实例必须在第一行显示列出，否则该枚举无法在被实例。这些实例默认使用public static fianl修饰。 建议枚举类的成员变量都使用private final修饰。 类内部的枚举默认被static final修饰。 自定义枚举实现接口的枚举类12345678910111213141516171819202122interface D &#123;void info();&#125;public enum Demo implements D &#123; MALE(1), WOMAN(2); private final int type; Demo(int type) &#123;this.type = type;&#125; public int getValue() &#123;return type;&#125; @Override public void info() &#123; System.out.println(\"info\"); &#125; public static void main(String[] args) &#123; System.out.println(Demo.MALE.getValue()); Demo.WOMAN.info(); //遍历枚举 for (Demo d : Demo.values()) &#123; System.out.println(d.getValue() + \", ordinal \" + d.ordinal()); &#125; &#125;&#125; 类似匿名内部类方式实现接口的枚举类1234567891011121314151617public enum Demo implements D &#123; MALE(1) &#123; @Override public void info() &#123; System.out.println(\"MALE枚举实现接口\"); &#125; &#125;, WOMAN(2) &#123; @Override public void info() &#123; System.out.println(\"FAMALE枚举实现接口\"); &#125; &#125;; private final int type; Demo(int type) &#123;this.type = type;&#125; public int getValue() &#123;return type;&#125;&#125; 包含抽象方法的枚举类12345678910111213141516171819public enum Demo &#123; MALE(1) &#123; @Override public void info() &#123; System.out.println(\"MALE枚举实现接口\"); &#125; &#125;, WOMAN(2) &#123; @Override public void info() &#123; System.out.println(\"FAMALE枚举实现接口\"); &#125; &#125;; private final int type; Demo(int type) &#123;this.type = type;&#125; public int getValue() &#123;return type;&#125; public abstract void info();&#125;","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Java内部类","slug":"Java基础之内部类","date":"2017-06-22T02:09:31.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/22/Java基础之内部类/","link":"","permalink":"http://yoursite.com/2017/06/22/Java基础之内部类/","excerpt":"非静态内部内与静态内部类// 构建一个静态内部类实例 Outer.Inner in = new Outer.Inner(); // 方法静态内部类的静态方法 Outer.Inner.静态方法(); // 构建一个非静态内部类 Outer.Inner in = new Outer().new Inner(); 非静态内部类：相当于一个成员函数的位置。可以使用任意访问控制符，如public、protected、private等。 静态内部类：相当于外部内。 非静态内部类不能存在任何static的变量和方法，但是可以定义常量。因为非静态内部类是要依赖于外部类的实例，而静态变量和方法是不依赖对象的，仅于类相关。即在加载静态域时，根本没有外部类。常量是编译器就可以确定的，放在常量池中。","text":"非静态内部内与静态内部类// 构建一个静态内部类实例 Outer.Inner in = new Outer.Inner(); // 方法静态内部类的静态方法 Outer.Inner.静态方法(); // 构建一个非静态内部类 Outer.Inner in = new Outer().new Inner(); 非静态内部类：相当于一个成员函数的位置。可以使用任意访问控制符，如public、protected、private等。 静态内部类：相当于外部内。 非静态内部类不能存在任何static的变量和方法，但是可以定义常量。因为非静态内部类是要依赖于外部类的实例，而静态变量和方法是不依赖对象的，仅于类相关。即在加载静态域时，根本没有外部类。常量是编译器就可以确定的，放在常量池中。 非静态内部类持有外部内的引用(外部内名.this)，这个引用消耗了时间和空间。因此除非必要不使用非静态内部类。12345678910111213141516public class Outer &#123; int num = 3; class Inner &#123; int num = 4; void show() &#123; int num = 5; System.out.println(\"A...\" + num); System.out.println(\"B...\" + this.num); System.out.println(\"C...\" + Outer.this.num); &#125; &#125; public static void main(String[] args) throws UnsupportedEncodingException &#123; Inner in = new Outer().new Inner(); in.show(); &#125;&#125; 局部内部类和匿名内部类 只能访问方法中final类型的局部变量（1.8后可以访问非final的局部变量，其实1.8默认添加了final）。 当方法被调用运行完毕后，局部变量就消亡了。但内部类可能还存在。此时就会出现内部类访问一个不存在的局部变量。 使用final修饰不仅会保持对象的引用不会改变，而且编译器还会维持这个对象的在回调方法中的生命周期。 局部内部类并不是直接调用方法传进来的参数，而是内部类将传进来的参数通过自己的构造器备份到自己的内部，自己内部的方法调用的实际是自己的属性，而不是外部类方法的参数。 局部内部类就像方法中的局部变量一样，不能有public、protected、private、static等修饰符。","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"Java关键字","slug":"Java基础之Java关键字","date":"2017-06-21T05:56:21.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"2017/06/21/Java基础之Java关键字/","link":"","permalink":"http://yoursite.com/2017/06/21/Java基础之Java关键字/","excerpt":"常见关键字if else switch case for do while try catch finally null break continue return throw throws void boolean true false char byte short int long float double class interface enum abstract import extends implements super this package new public protected default private volatile synchronized 保留字(goto const)","text":"常见关键字if else switch case for do while try catch finally null break continue return throw throws void boolean true false char byte short int long float double class interface enum abstract import extends implements super this package new public protected default private volatile synchronized 保留字(goto const) 不常见关键字 strictfp：精确浮点，让浮点运算更加精确，不会因为不同的硬件平台所执行的结果不一致。 assert：断言。 native：该关键字修饰的方法是一个原生态方法，方法对应的实现不是当前文件，而是在用其他语言（如C和C++）实现的文件中。Java语言本身不能对操作系统底层进行访问和操作，但是通过JNI接口调用其他语言来实现对底层的访问。 transient：在变量前加上该关键字，可以阻止该变量被序列化到文件中。在反序列化后，该变量被设置为初始值，如 int 型的是 0，对象型的是 null。 static关键字static修饰属性 即静态变量，静态变量被所有对象共享，在内存中只有一个副本，在类被初次加载时被初始化。 初始化顺序按照定义的顺序进行初始化。 静态变量一般会被作为GC的root节点。即静态变量基本上不会被回收，所以很容易引入内存泄漏，特别是修饰List、Map等集合时要特别注意。 static是不允许用来修饰局部变量。 static修饰方法：即静态方法，静态方法不依赖任何对象就可以访问。类的构造器默认是静态方法。static修饰内部类：静态内部类等于外部类。static代码块：static代码块会在类加载的时候，按照顺序执行一次。 final关键字final变量 凡是对成员变量或者局部变量声明为final的都叫作final变量，final变量是只读的。 final变量经常和static关键字一起使用，作为常量。 在能够通过编译的前提下，无论局部变量声明时带不带final关键字修饰，对其访问的效率都一样。因为在字节码里没有体现局部变量的final与否。 final方法 方法前面加上final关键字，代表这个方法不可以被子类的方法重写。如果你认为一个方法的功能已经足够完整了，子类中不需要改变的话，你可以声明此方法为final。 final方法比非final方法要快，因为在编译的时候已经静态绑定了，不需要在运行时再动态绑定。 final类：使用final来修饰的类叫作final类。final类通常功能是完整的，它们不能被继承。Java中有许多类是final的，譬如String, Interger以及其他包装类。 关于final的一些需要注意的点 final关键字容易与finalize()方法搞混，后者是在Object类中定义的方法，是在垃圾回收之前被JVM调用的方法。 接口中声明的所有变量都是public static final的。 final和abstract这两个关键字是反相关的，final类就不可能是abstract的。 将类、方法、变量声明为final能够提高性能，这样JVM就有机会进行优化。 对于集合对象声明为final指的是引用不能被更改，但是你可以向其中增加，删除或者改变内容。 instanceof关键字该关键字用于判断对象是否是某个类或者是其子类的实例。 instanceof关键字和Class类的isInstance(Object)方法对比class InstanceofDemo { public static void main(String[] args) { Object hello = &quot;Hello&quot;; System.out.println(hello instanceof Object); // true System.out.println(hello instanceof String); // true // Object hello = &quot;Hello&quot;;中的hello变量编译时类型是Object类，但实际是String。因此hello instanceof Math可以编译通过。 System.out.println(hello instanceof Math); // false // String实现了Comparable接口 System.out.println(hello instanceof Comparable);// true System.out.println(Object.class.isInstance(hello)); System.out.println(String.class.isInstance(hello)); System.out.println(Math.class.isInstance(hello)); System.out.println(Comparable.class.isInstance(hello)); String a = &quot;Hello&quot;; // System.out.println(a instanceof Math); // 编译错误 System.out.println(Math.class.isInstance(a)); // 编译通过 false } }","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"MySQL基础","slug":"其它之MySQL基础","date":"2017-05-31T15:37:58.000Z","updated":"2021-10-30T09:35:55.395Z","comments":true,"path":"2017/05/31/其它之MySQL基础/","link":"","permalink":"http://yoursite.com/2017/05/31/其它之MySQL基础/","excerpt":"数据库基础数据库定义 数据库（数据真正存储的地方）是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合。 数据库实例（对数据进行操作的管理系统）是程序，是位于用户和操作系统之间的一层数据管理软件，用户对数据库的任何操作，包括数据库定义，数据查询，数据维护，数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道。","text":"数据库基础数据库定义 数据库（数据真正存储的地方）是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合。 数据库实例（对数据进行操作的管理系统）是程序，是位于用户和操作系统之间的一层数据管理软件，用户对数据库的任何操作，包括数据库定义，数据查询，数据维护，数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道。 一些关于数据库的基本概念 OLTP(联机事务处理Online Transaction Processing)：表示事务性非常高的系统，一般都是高可用的在线系统，以小的事务以及小的查询为主，评估其系统的时候，一般看其每秒执行的Transaction以及Execute SQL的数量。 OLAP(联机分析处理Online Analytical Processing)：有的时候也叫DSS决策支持系统，就是我们说的数据仓库。在这样的系统中，语句的执行量不是考核标准，因为一条语句的执行时间可能会非常长，读取的数据也非常多。所以，在这样的系统中，考核的标准往往是磁盘子系统的吞吐量（带宽），如能达到多少MB/s的流量。 ETL(Extraction-Transformation-Loading)：即数据抽取（Extract）、转换（Transform）、装载（Load）的过程，它是构建数据仓库的重要环节。 数据库三范式第一范式（1NF）：字段具有原子性,不可再分。第二范式（2NF）要求数据库表中的每个实例或行必须可以被惟一地区分。第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息. 数据库设计规范 构建数据库时尽量不使用MySQL的枚举类型（网上也有说应该使用枚举类型的），如果是确定表达是与否语义则使用tinyint(1)，如果是（-1、0、1、2）就可表示则使用tinyint(2)，如果还有更多语义项个人还是习惯使用枚举（Java枚举，数据库存储字符串），不确定这个习惯是否好。tinyint(1)和tinyint(2)在数据库层面上没有什么不同存储范围都是-128-127，但是Mybatis Plus自动生成实体类时会将前者映射成布尔类型，后者映射成Integer。 注意MySQL关键字，碰到简单的英文很可能是MySQL关键字时尽量加一个前缀（表名）。 主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名。 钱一般在存储时转成分而不是元为单位。 分数是存储为字符串还是decimal好？在Mybatis Plus的自动生成中decimal会自动映射成Java的BigDecimal。 varchar是可变长字符串，不预先分配存储空间，长度不要超过5000，如果存储长度大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。如果存储的字符串长度几乎相等（手机号、身份证号），使用char定长字符串类型。 varchar使用额外的1到2字节存储长度，列小于255使用1字节保存长度，大于255使用2字节保存，varchar保留字符串末尾的空格。 数据库的ACID特性 原子性：指事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生。 一致性：事务不能破坏关系数据的完整性以及业务逻辑上的一致性（转账例子）。 隔离性：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。 持久性：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。 MySQL基础MySQL存储引擎MySQL和其他数据库的最重要区别就是插件式的表存储引擎。用户可以很方便的根据具体的应用建立不同的存储引擎表。下面是一些具体的存储引擎： InnoDB存储引擎：支持事物（1.2开始支持全文索引），其设计目标主要面向在线事物处理（OLTP）的应用。 MyISAM存储引擎：不支持事物、表锁设计，支持全文索引，主要面向一下OLAP数据库应用。 NDB存储引擎：一个集群存储引擎，数据全部放到内存中，因此主键查找的速度极快。 Memory存储引擎：将表中的数据存放到内存中。 Archive存储引擎：只支持INSERT和SELECT操作，非常适合存储归档数据，如日志信息。 Federated存储引擎：并不存放数据，只是指向一台远程MySQL数据库服务器上的表。 Maria存储引擎：最新设计用来取代MyISAM存储引擎的。 MySQL中的数据类型整数 MySQL数据类型 含义（有符号） 范围 tinyint(m) 1个字节 范围(-128~127) smallint(m) 2个字节 范围(-32768~32767) mediumint(m) 3个字节 范围(-8388608~8388607) int(m) 4个字节 范围(-2147483648~2147483647) bigint(m) 8个字节 范围(+-9.22*10的18次方) 浮点数：设一个字段定义为float(5,3)，如果插入一个数123.45678,实际数据库里存的是123.457，但总个数还以实际为准，即6位。 MySQL数据类型 含义 float(m,d) 单精度浮点型 8位精度(4字节) m总个数，d小数位 double(m,d) 双精度浮点型 16位精度(8字节) m总个数，d小数位 日期和时间: 若定义一个字段为timestamp，这个字段里的时间数据会随其他字段修改的时候自动刷新，所以这个数据类型的字段可以存放这条记录最后被修改的时间。 MySQL数据类型 含义 date 日期 ‘2015-11-2’ time 时间 ‘12:25:36’ datetime 日期时间 ‘2015-11-2 22:06:44’ timestamp 自动存储记录修改时间 字符串类型 MySQL数据类型 含义 char(n) 固定长度，最多255个字符 varchar(n) 固定长度，最多65535个字符 tinytext 可变长度，最多255个字符 text 可变长度，最多65535个字符 mediumtext 可变长度，最多2的24次方-1个字符 longtext 可变长度，最多2的32次方-1个字符 char(n) 若存入字符数小于n，则以空格补于其后，查询之时再将空格去掉。所以char类型存储的字符串末尾不能有空格，varchar不限于此。 char(n) 固定长度，char(4)不管是存入几个字符，都将占用4个字节，varchar是存入的实际字符数+1个字节（n&lt;=255）或2个字节(n&gt;255)，所以varchar(4),存入3个字符将占用4个字节。 char类型的字符串检索速度要比varchar类型的快。 varchar可指定n，text不能指定，内部存储varchar是存入的实际字符数+1个字节（n&lt;=255）或2个字节(n&gt;255)，text是实际字符数+2个字节。 text类型不能有默认值。 varchar可直接创建索引，text创建索引要指定前多少个字符。varchar查询速度快于text,在都创建索引的情况下，text的索引似乎不起作用。 二进制(可用来存储图片、音乐等)：tinyblob、blob、mediumblob、longblob BLOB和TEXT存储方式不同，TEXT以文本方式存储，英文存储区分大小写，而Blob是以二进制方式存储，不分大小写。 BLOB存储的数据只能整体读出。 TEXT可以指定字符集，BLOB不用指定字符集。 MySQL一些知识点 查询正在执行的事务：SELECT * FROM information_schema.INNODB_TRX MySQL大数据分页：SELECT * FROM table WHERE id &gt;= (SELECT id FROM table LIMIT 1000000, 1) LIMIT 10; MySQL管理 创建用户：CREATE USER ‘username‘@’host’ IDENTIFIED BY ‘password’; host为%表示任意主机可用。 授权：grant all privileges on leasehold.* to ‘leasehold‘@’%’ identified by ‘!@#leaseholdqwe’;; privileges表示用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL 撤销权限：REVOKE privilege ON databasename.tablename FROM ‘username‘@’host’; 修改密码： update user set authentication_string=password(‘新密码’) where user=’username’; alter user ‘username‘@’host’ identified by ‘新密码’; flush privileges; root忘记密码后修改密码： 打开DOS窗口，转到mysql\\bin目录。 输入mysqld –skip-grant-tables。–skip-grant-tables的意思是启动MySQL服务的时候跳过权限表认证。 再开一个DOS窗口（因为刚才那个DOS窗口已经不能动了），转到mysql\\bin目录。 输入mysql回车，如果成功，将出现MySQL提示符 &gt;。 连接权限数据库： use mysql;。 改密码：update user set password=password(“123”) where user=”root”;（别忘了最后加分号） 。 刷新权限（必须步骤）：flush privileges;。 注销系统，再进入，使用用户名root和刚才设置的新密码123登录。 MySQL索引MySQL索引管理 查询索引的大致情况：SELECT table_name,index_name,stat_name,stat_value,stat_description FROM mysql.innodb_index_stats WHERE table_name = ‘orders’ and index_name = ‘PRIMARY’; 查询使用过的索引，如果数据库运行时间比较长，而且索引的创建时间也比较久，索引还没有被使用过，就应该删除该索引。SELECT * FROM sys.schema_unused_indexes WHERE object_schema != ‘performance_schema’; B树和B+树索引 B树是一种平衡的多叉树，在B-树中查找给定关键字的方法是，首先把根结点取来，在根结点所包含的关键字K1,…,Kn查找给定的关键字（可用顺序查找或二分查找法），若找到等于给定值的关键字，则查找成功；否则，一定可以确定要查找的关键字在Ki与Ki+1之间，Pi为指向子树根节点的指针，此时取指针Pi所指的结点继续查找，直至找到，或指针Pi为空时查找失败。 B+树是应数据库所需而出现的一种B树的变形树。B+树让内结点只作索引使用，去掉了其中指向data record的指针， 使得每个结点中能存放更多的key，树的层高能进一步被压缩, 使得检索的时间更短。 联合索引具体可以参考联合索引（复合索引）在B+树上的结构。 MySQL面试相关InnoDB的事务隔离级别 InnoDB通过MVVC（多版本并发控制）隔离掉脏读。InnoDB在插入数据时会生成快照以便在事务失败后回滚，读取时会读取快照，这样不加锁也不会出现脏读。 脏读：事务T2读取到事务T1修改了但是还未提交的数据，之后事务T1又回滚其更新操作，导致事务T2读到的是脏数据。 InnoDB通过行锁隔离掉不可重复读。既共享锁（读锁）锁住的数据互斥锁（写锁）不能访问。 不可重复读：事务T1读取某个数据后，事务T2对其做了修改，当事务T1再次读该数据时得到与前一次不同的值。 InnoDB通过间隙锁（Gap锁）隔离掉幻读。Gap锁锁住的是一个范围，不包含记录本身。 虚读（幻读）：事务T1读取在读取某范围数据时，事务T2又插入一条数据，当事务T1再次数据这个范围数据时发现不一样了，出现了一些”幻影行”。 更新丢失：两事务同时更新，一个失败回滚覆盖另一个事务的更新。或事务1执行更新操作，在事务1结束前事务2也更新，则事务1的更新结果被事务2的覆盖了。InnoDB可以隔离掉脏读、不可重复读和幻读，但是需要注意业务层面的更新丢失。 SQL优化 数据量大这个问题没啥银弹，需要根据业务的不同采取不同的方法。我的话一般会先看一下慢查询，然后explain一下，主要是看看有没有走索引，如果没有考虑一下怎么能走，或者考虑一下能不能加一个。一般能解决大部分问题。 更多数据的单表查询可以分库分表，我们之前有根据日期进行分表，也有根据是否结案来分表的。不过这个只针对历史数据可以和正在使用的数据分开的情况。 还有就是多表查询、报表之类的可以通过定时任务统计生成一种中间表。然后去查中间表。问题在于实时性不强。 还有就是canal，阿里开源的一个中间件。 如果数据量更大或者是大表之间的连表操作，可以考虑上中间件，根据业务的不同使用不同的中间件，es或MyCat等。 尽量不使用数据库提供的函数，一个有可能产生兼容问题，还有就是可能引发性能问题，之前碰到过一个使用函数在SQL中格式化日期并判断大小的，去掉这个函数在业务中处理速度提升了10多倍。原因是该函数导致索引失效，不管时间多短都会进行全表扫描。 在MySQL查询中，当查询条件左右两侧类型不匹配的时候会发生隐式转换，可能导致查询无法使用索引。数据库字段是数字，查询条件是字符串时会走索引；数据库字段是字符串，查询条件是数字时不会走索引。 当只要一行数据时使用LIMIT 1：当你查询表的有些时候，你已经知道结果只会有一条结果，但因为你可能需要去fetch游标，或是你需要检查返回的记录数。在这种情况下，加上LIMIT 1可以增加性能。这样一样，MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据。 避免SELECT *：从数据库里读出越多的数据，那么查询就会变得越慢。并且，如果你的数据库服务器和WEB服务器是两台独立的服务器的话，这还会增加网络传输的负载。 PROCEDURE ANALYSE()会让MySQL帮你去分析你的字段和其实际的数据，并会给你一些有用的建议。只有表中有实际的数据，这些建议才会变得有用，因为要做一些大的决定是需要有数据作为基础的。 分库分表 步骤：根据容量（当前容量和增长量）评估分库或分表个数 -&gt; 选key（均匀）-&gt; 分表规则（hash或range等）-&gt; 执行（一般双写）-&gt; 扩容问题（尽量减少数据的移动）。 分库分表思路 美团点评分布式ID生成系统 MySQL各个版本特性5.5 - 2010-12-03 InnoDB作为默认存储引擎。 以插件形式实现支持半同步复制。默认的MySQL通过异步模式进行复制，主库写入binlog之后，从库不一定能够被读取并处理，因为写入成功只是说明在主库上成功。而半同步复制则是当一次写入操作进行之后，只有主库和至少一个半同步从库上都完成了写入之后，用户才会收到已成功的信息。 5.6 - 2013-02-05 InnoDB支持全文索引。 多线程复制。 加入全局事务ID（GTID）。 5.7 - 2015-10-21 增强的多线程复制。 多源复制，即将多个主库的数据归并到一个从库的实例上。 支持JSON数据类型。 MySQL注意时区问题 MySQL的时区默认是CST格式， 但是Spark默认的是GMT格式，因此直接使用Spark读取MySQL的时间时，会被转为GMT格式。","categories":[],"tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"知识点总结","slug":"一些知识点的总结","date":"1919-02-06T00:11:16.000Z","updated":"2021-07-03T01:30:27.668Z","comments":true,"path":"1919/02/06/一些知识点的总结/","link":"","permalink":"http://yoursite.com/1919/02/06/一些知识点的总结/","excerpt":"总结自己会的知识点和接下来需要学习的东西。","text":"总结自己会的知识点和接下来需要学习的东西。 学习规划自己的知识优先级英语+数据结构与算法+高等数学 –&gt; 操作系统和计算机网络 –&gt; 网络编程（Web服务器）+Netty+Java基础和JVM+Spring全家桶Web编程。 2019技术规划 - 2019/04/02 结合慕课网的Java读源码之Netty深入剖析阅读Netty整体代码。 结合Unix网络编程卷一和传智播客的Linux系统编程视频学习netty-transport-native-epoll模块的代码。 结合HTTP权威指南阅读Netty对HTTP协议的基础实现代码，例如HTTP编解码器等。 基础部分数据结构 时间复杂度与空间复杂度的计算；逻辑结构（集合、线性、树形、图形）；存储结构（顺序存储–&gt;数组、链式存储–&gt;链表、索引存储和Hash存储）。 线性结构：线性表；操作受限的线性表（栈和队列）；特殊矩阵的压缩存储。 树形结构：满二叉树和完全二叉树；二叉树的遍历（先中后层）和线索二叉；二叉排序（查找）树和平衡二叉树；红黑树；哈夫曼树和哈夫曼编码。 图形结构：无向图、有向图和网络；图的表示方法（邻接矩阵和邻接表）；图的遍历（深度优先搜索和广度优先搜索）；最小生成树；最短路径问题；拓扑排序；关键路径。 图的深度优先搜索类似树的先序遍历，广度优先遍历类似树的层序遍历。 数据查找：顺序查找、折半查找和分块（索引）查找；B树和B+树；散列函数的构造和Hash冲突的解决。 排序算法：插入排序（直接插入、折半插入、希尔排序）；交换排序（冒泡排序和快速排序）；选择排序（简单选择和堆排序）；归并排序；基数排序；外部排序（多路归并排序）。 操作系统 进程管理：即CPU管理。进程的切换（状态和转换、PCB）；进程同步与数据共享；用户级线程与内核级线程。 内存管理：内存分配（分页、分段）；逻辑地址与物理地址；虚拟内存与页面置换算法。 文件管理：文件逻辑结构和目录的实现；磁盘管理与磁盘调度算法。 计算机网络 链路层：交换机（MAC地址表）；以太网协议；ARP协议。 网际层：路由器（路由表），路由选择算法；IPv4、IPv6和移动IP。 传输层：TCP协议；三次握手四次挥手；保证可靠性（超时重传、滑动窗口）；流量控制和拥塞窗口。 Java开发部分Java基础 Java数据结构：HashMap –&gt; LinkedHashMap –&gt; TreeMap –&gt; ConcurrentHashMap（段锁、CAS）。 Java并发编程：wait()和sleep(long)区别；volatile原理；ThreadLocal原理；同步器（CountDownLatch）；synchronized和Lock的区别（可中断锁、tryLock、多个Condition、公平锁）；锁升级（偏向锁、轻量级锁、锁自旋）；乐观锁（CAS）。 Java虚拟机：GCRoot（静态变量和常量等所引用的变量）；Java虚拟机内存划分；Java虚拟机类加载机制（双亲委派模式）；判断对象是否死亡（引用计数和可达性分析）；Java内存模型。 设计模式：单例、工厂、生产者消费者；代理、迭代器、装饰者；策略和模板方法。 开发框架 Spring：IoC（循环依赖）；AOP（动态代理和CGLIB）；Spring事务（什么时候使用编程实事务、事务隔离级别、事务的传播级别）；Spring MVC（请求过程）；SpringBoot（依赖优于配置）。 Dubbo：服务治理和服务发现过程；软负载均衡算法（默认是基于权重的随机算法）；Dubbo健壮性（注册中心挂了）；Dubbo重连问题；Dubbo保证幂等性原理。 Netty：NIO编程（和BIO的区别、epoll机制、水平触发和边缘触发）；TCP拆包粘包（特殊分隔符–&gt;换行符、消息头携带消息体长度）；TCP长连接（心跳机制确认客户端是否存活）。 数据库 MySQL：索引原理（B树、B+树）；隔离掉脏读（MVCC）、不可重复读（行锁）和幻读（Gap锁）。 Redis：五种数据类型；过期删除策略；两种持久化方式；内存溢出的控制策略；Redis事务；实现分布式锁。","categories":[],"tags":[]}]}